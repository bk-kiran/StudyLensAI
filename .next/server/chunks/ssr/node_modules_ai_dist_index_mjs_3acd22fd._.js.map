{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/index.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/index.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/invalid-argument-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/invalid-stream-part-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/invalid-tool-arguments-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/mcp-client-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-image-generated-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-object-generated-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-output-specified-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-such-tool-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/tool-call-repair-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/tool-execution-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/invalid-data-content-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/invalid-message-role-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/message-conversion-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/download-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/retry-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/prepare-headers.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/text-stream/create-text-stream-response.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/write-to-server-response.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/text-stream/pipe-text-stream-to-response.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/call-completion-api.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/ui-message-stream-parts.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/consume-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/process-text-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/chat.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/serial-job-executor.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/convert-file-list-to-file-ui-parts.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/default-chat-transport.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/process-ui-message-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/merge-objects.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/parse-partial-json.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/fix-json.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/get-tool-invocations.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/should-resubmit-messages.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/convert-to-model-messages.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/transform-text-to-ui-message-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui/text-stream-chat-transport.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/handle-ui-message-stream-finish.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/create-ui-message-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/json-to-sse-transform-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/ui-message-stream-headers.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/create-ui-message-stream-response.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/ui-message-stream/pipe-ui-message-stream-to-response.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/cosine-similarity.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/data-url.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/is-deep-equal-data.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/simulate-readable-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/retry-with-exponential-backoff.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/prepare-retries.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/assemble-operation-name.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/get-base-telemetry-attributes.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/get-tracer.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/noop-tracer.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/record-span.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/select-telemetry-attributes.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/embed/embed.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/split-array.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/embed/embed-many.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/detect-media-type.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/generated-file.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-image/generate-image.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-object/generate-object.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/extract-content-text.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/convert-to-language-model-prompt.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/download.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/data-content.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/split-data-url.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/prepare-call-settings.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/resolve-language-model.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/standardize-prompt.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/message.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/types/provider-metadata.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/types/json-value.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/content-part.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/tool-result-content.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/wrap-gateway-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/telemetry/stringify-for-telemetry.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-object/output-strategy.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/async-iterable-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-object/validate-object-generation-input.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-object/stream-object.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/create-resolvable-promise.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/create-stitchable-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/delayed-promise.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/now.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-speech-generated-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-speech/generated-audio-file.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-speech/generate-speech.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/generate-text.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/as-array.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/prompt/prepare-tools-and-tool-choice.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/is-non-empty-object.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/types/usage.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/as-content.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/parse-tool-call.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/step-result.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/stop-condition.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/to-response-messages.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/output.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/smooth-stream.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/stream-text.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/generate-text/run-tools-transformation.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/middleware/default-settings-middleware.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/util/get-potential-start-index.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/middleware/extract-reasoning-middleware.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/middleware/simulate-streaming-middleware.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/middleware/wrap-language-model.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/registry/custom-provider.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/registry/no-such-provider-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/registry/provider-registry.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/mcp/mcp-client.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/tool.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/mcp/mcp-sse-transport.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/mcp/json-rpc-message.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/mcp/types.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/tool/mcp/mcp-transport.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/src/error/no-transcript-generated-error.ts","file:///Users/kirannew/StudyLens%20AI/node_modules/ai/core/transcribe/transcribe.ts"],"sourcesContent":["// re-exports:\nexport {\n  asSchema,\n  createIdGenerator,\n  generateId,\n  jsonSchema,\n  type Schema,\n  type IdGenerator,\n} from '@ai-sdk/provider-utils';\n\n// directory exports\nexport * from './error';\nexport * from './text-stream';\nexport * from './ui';\nexport * from './ui-message-stream';\nexport * from './util';\n\n// directory exports from /core\nexport * from '../core/';\n","export {\n  AISDKError,\n  APICallError,\n  EmptyResponseBodyError,\n  InvalidPromptError,\n  InvalidResponseDataError,\n  JSONParseError,\n  LoadAPIKeyError,\n  NoContentGeneratedError,\n  NoSuchModelError,\n  TypeValidationError,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport { InvalidArgumentError } from './invalid-argument-error';\nexport { InvalidStreamPartError } from './invalid-stream-part-error';\nexport { InvalidToolArgumentsError } from './invalid-tool-arguments-error';\nexport { MCPClientError } from './mcp-client-error';\nexport { NoImageGeneratedError } from './no-image-generated-error';\nexport { NoObjectGeneratedError } from './no-object-generated-error';\nexport { NoOutputSpecifiedError } from './no-output-specified-error';\nexport { NoSuchToolError } from './no-such-tool-error';\nexport { ToolCallRepairError } from './tool-call-repair-error';\nexport { ToolExecutionError } from './tool-execution-error';\n\nexport { InvalidDataContentError } from '../../core/prompt/invalid-data-content-error';\nexport { InvalidMessageRoleError } from '../../core/prompt/invalid-message-role-error';\nexport { MessageConversionError } from '../../core/prompt/message-conversion-error';\nexport { DownloadError } from '../util/download-error';\nexport { RetryError } from '../util/retry-error';\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidArgumentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidArgumentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly parameter: string;\n  readonly value: unknown;\n\n  constructor({\n    parameter,\n    value,\n    message,\n  }: {\n    parameter: string;\n    value: unknown;\n    message: string;\n  }) {\n    super({\n      name,\n      message: `Invalid argument for parameter ${parameter}: ${message}`,\n    });\n\n    this.parameter = parameter;\n    this.value = value;\n  }\n\n  static isInstance(error: unknown): error is InvalidArgumentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { SingleRequestTextStreamPart } from '../../core/generate-text/run-tools-transformation';\n\nconst name = 'AI_InvalidStreamPartError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidStreamPartError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly chunk: SingleRequestTextStreamPart<any>;\n\n  constructor({\n    chunk,\n    message,\n  }: {\n    chunk: SingleRequestTextStreamPart<any>;\n    message: string;\n  }) {\n    super({ name, message });\n\n    this.chunk = chunk;\n  }\n\n  static isInstance(error: unknown): error is InvalidStreamPartError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError, getErrorMessage } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidToolArgumentsError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidToolArgumentsError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly toolName: string;\n  readonly toolArgs: string;\n\n  constructor({\n    toolArgs,\n    toolName,\n    cause,\n    message = `Invalid arguments for tool ${toolName}: ${getErrorMessage(\n      cause,\n    )}`,\n  }: {\n    message?: string;\n    toolArgs: string;\n    toolName: string;\n    cause: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.toolArgs = toolArgs;\n    this.toolName = toolName;\n  }\n\n  static isInstance(error: unknown): error is InvalidToolArgumentsError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_MCPClientError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * An error occurred with the MCP client.\n */\nexport class MCPClientError extends AISDKError {\n  private readonly [symbol] = true;\n\n  constructor({\n    name = 'MCPClientError',\n    message,\n    cause,\n  }: {\n    name?: string;\n    message: string;\n    cause?: unknown;\n  }) {\n    super({ name, message, cause });\n  }\n\n  static isInstance(error: unknown): error is MCPClientError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { ImageModelResponseMetadata } from '../../core/types/image-model-response-metadata';\n\nconst name = 'AI_NoImageGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no image could be generated. This can have multiple causes:\n\n- The model failed to generate a response.\n- The model generated a response that could not be parsed.\n */\nexport class NoImageGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  /**\nThe response metadata for each call.\n   */\n  readonly responses: Array<ImageModelResponseMetadata> | undefined;\n\n  constructor({\n    message = 'No image generated.',\n    cause,\n    responses,\n  }: {\n    message?: string;\n    cause?: Error;\n    responses?: Array<ImageModelResponseMetadata>;\n  }) {\n    super({ name, message, cause });\n\n    this.responses = responses;\n  }\n\n  static isInstance(error: unknown): error is NoImageGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { FinishReason } from '../../core/types/language-model';\nimport { LanguageModelResponseMetadata } from '../../core/types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../../core/types/usage';\n\nconst name = 'AI_NoObjectGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no object could be generated. This can have several causes:\n\n- The model failed to generate a response.\n- The model generated a response that could not be parsed.\n- The model generated a response that could not be validated against the schema.\n\nThe error contains the following properties:\n\n- `text`: The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n */\nexport class NoObjectGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  /**\n  The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n   */\n  readonly text: string | undefined;\n\n  /**\n  The response metadata.\n   */\n  readonly response: LanguageModelResponseMetadata | undefined;\n\n  /**\n  The usage of the model.\n   */\n  readonly usage: LanguageModelUsage | undefined;\n\n  /**\n  Reason why the model finished generating a response.\n   */\n  readonly finishReason: FinishReason | undefined;\n\n  constructor({\n    message = 'No object generated.',\n    cause,\n    text,\n    response,\n    usage,\n    finishReason,\n  }: {\n    message?: string;\n    cause?: Error;\n    text?: string;\n    response: LanguageModelResponseMetadata;\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  }) {\n    super({ name, message, cause });\n\n    this.text = text;\n    this.response = response;\n    this.usage = usage;\n    this.finishReason = finishReason;\n  }\n\n  static isInstance(error: unknown): error is NoObjectGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n\nexport function verifyNoObjectGeneratedError(\n  error: unknown,\n  expected: {\n    message: string;\n    response: LanguageModelResponseMetadata & {\n      body?: string;\n    };\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  },\n) {\n  expect(NoObjectGeneratedError.isInstance(error)).toBeTruthy();\n  const noObjectGeneratedError = error as NoObjectGeneratedError;\n  expect(noObjectGeneratedError.message).toEqual(expected.message);\n  expect(noObjectGeneratedError.response).toEqual(expected.response);\n  expect(noObjectGeneratedError.usage).toEqual(expected.usage);\n  expect(noObjectGeneratedError.finishReason).toEqual(expected.finishReason);\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoOutputSpecifiedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no output type is specified and output-related methods are called.\n */\nexport class NoOutputSpecifiedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  constructor({ message = 'No output specified.' }: { message?: string } = {}) {\n    super({ name, message });\n  }\n\n  static isInstance(error: unknown): error is NoOutputSpecifiedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoSuchToolError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class NoSuchToolError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly toolName: string;\n  readonly availableTools: string[] | undefined;\n\n  constructor({\n    toolName,\n    availableTools = undefined,\n    message = `Model tried to call unavailable tool '${toolName}'. ${\n      availableTools === undefined\n        ? 'No tools are available.'\n        : `Available tools: ${availableTools.join(', ')}.`\n    }`,\n  }: {\n    toolName: string;\n    availableTools?: string[] | undefined;\n    message?: string;\n  }) {\n    super({ name, message });\n\n    this.toolName = toolName;\n    this.availableTools = availableTools;\n  }\n\n  static isInstance(error: unknown): error is NoSuchToolError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError, getErrorMessage } from '@ai-sdk/provider';\nimport { InvalidToolArgumentsError } from './invalid-tool-arguments-error';\nimport { NoSuchToolError } from './no-such-tool-error';\n\nconst name = 'AI_ToolCallRepairError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class ToolCallRepairError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly originalError: NoSuchToolError | InvalidToolArgumentsError;\n\n  constructor({\n    cause,\n    originalError,\n    message = `Error repairing tool call: ${getErrorMessage(cause)}`,\n  }: {\n    message?: string;\n    cause: unknown;\n    originalError: NoSuchToolError | InvalidToolArgumentsError;\n  }) {\n    super({ name, message, cause });\n    this.originalError = originalError;\n  }\n\n  static isInstance(error: unknown): error is ToolCallRepairError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError, getErrorMessage, JSONValue } from '@ai-sdk/provider';\n\nconst name = 'AI_ToolExecutionError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class ToolExecutionError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly toolName: string;\n  readonly toolArgs: JSONValue | unknown;\n  readonly toolCallId: string;\n\n  constructor({\n    toolArgs,\n    toolName,\n    toolCallId,\n    cause,\n    message = `Error executing tool ${toolName}: ${getErrorMessage(cause)}`,\n  }: {\n    message?: string;\n    toolArgs: JSONValue | unknown;\n    toolName: string;\n    toolCallId: string;\n    cause: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.toolArgs = toolArgs;\n    this.toolName = toolName;\n    this.toolCallId = toolCallId;\n  }\n\n  static isInstance(error: unknown): error is ToolExecutionError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidDataContentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidDataContentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly content: unknown;\n\n  constructor({\n    content,\n    cause,\n    message = `Invalid data content. Expected a base64 string, Uint8Array, ArrayBuffer, or Buffer, but got ${typeof content}.`,\n  }: {\n    content: unknown;\n    cause?: unknown;\n    message?: string;\n  }) {\n    super({ name, message, cause });\n\n    this.content = content;\n  }\n\n  static isInstance(error: unknown): error is InvalidDataContentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidMessageRoleError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidMessageRoleError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly role: string;\n\n  constructor({\n    role,\n    message = `Invalid message role: '${role}'. Must be one of: \"system\", \"user\", \"assistant\", \"tool\".`,\n  }: {\n    role: string;\n    message?: string;\n  }) {\n    super({ name, message });\n\n    this.role = role;\n  }\n\n  static isInstance(error: unknown): error is InvalidMessageRoleError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { UIMessage } from '../../src/ui/ui-messages';\n\nconst name = 'AI_MessageConversionError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class MessageConversionError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly originalMessage: Omit<UIMessage, 'id'>;\n\n  constructor({\n    originalMessage,\n    message,\n  }: {\n    originalMessage: Omit<UIMessage, 'id'>;\n    message: string;\n  }) {\n    super({ name, message });\n\n    this.originalMessage = originalMessage;\n  }\n\n  static isInstance(error: unknown): error is MessageConversionError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_DownloadError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class DownloadError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly url: string;\n  readonly statusCode?: number;\n  readonly statusText?: string;\n\n  constructor({\n    url,\n    statusCode,\n    statusText,\n    cause,\n    message = cause == null\n      ? `Failed to download ${url}: ${statusCode} ${statusText}`\n      : `Failed to download ${url}: ${cause}`,\n  }: {\n    url: string;\n    statusCode?: number;\n    statusText?: string;\n    message?: string;\n    cause?: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.url = url;\n    this.statusCode = statusCode;\n    this.statusText = statusText;\n  }\n\n  static isInstance(error: unknown): error is DownloadError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_RetryError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport type RetryErrorReason =\n  | 'maxRetriesExceeded'\n  | 'errorNotRetryable'\n  | 'abort';\n\nexport class RetryError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  // note: property order determines debugging output\n  readonly reason: RetryErrorReason;\n  readonly lastError: unknown;\n  readonly errors: Array<unknown>;\n\n  constructor({\n    message,\n    reason,\n    errors,\n  }: {\n    message: string;\n    reason: RetryErrorReason;\n    errors: Array<unknown>;\n  }) {\n    super({ name, message });\n\n    this.reason = reason;\n    this.errors = errors;\n\n    // separate our last error to make debugging via log easier:\n    this.lastError = errors[errors.length - 1];\n  }\n\n  static isInstance(error: unknown): error is RetryError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","export function prepareHeaders(\n  headers: HeadersInit | undefined,\n  defaultHeaders: Record<string, string>,\n): Headers {\n  const responseHeaders = new Headers(headers ?? {});\n\n  for (const [key, value] of Object.entries(defaultHeaders)) {\n    if (!responseHeaders.has(key)) {\n      responseHeaders.set(key, value);\n    }\n  }\n\n  return responseHeaders;\n}\n","import { prepareHeaders } from '../util/prepare-headers';\n\nexport function createTextStreamResponse({\n  status,\n  statusText,\n  headers,\n  textStream,\n}: ResponseInit & {\n  textStream: ReadableStream<string>;\n}): Response {\n  return new Response(textStream.pipeThrough(new TextEncoderStream()), {\n    status: status ?? 200,\n    statusText,\n    headers: prepareHeaders(headers, {\n      'content-type': 'text/plain; charset=utf-8',\n    }),\n  });\n}\n","import { ServerResponse } from 'node:http';\n\n/**\n * Writes the content of a stream to a server response.\n */\nexport function writeToServerResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  stream,\n}: {\n  response: ServerResponse;\n  status?: number;\n  statusText?: string;\n  headers?: Record<string, string | number | string[]>;\n  stream: ReadableStream<Uint8Array>;\n}): void {\n  response.writeHead(status ?? 200, statusText, headers);\n\n  const reader = stream.getReader();\n  const read = async () => {\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n        response.write(value);\n      }\n    } catch (error) {\n      throw error;\n    } finally {\n      response.end();\n    }\n  };\n\n  read();\n}\n","import { ServerResponse } from 'node:http';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { writeToServerResponse } from '../util/write-to-server-response';\n\nexport function pipeTextStreamToResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  textStream,\n}: {\n  response: ServerResponse;\n  textStream: ReadableStream<string>;\n} & ResponseInit): void {\n  writeToServerResponse({\n    response,\n    status,\n    statusText,\n    headers: Object.fromEntries(\n      prepareHeaders(headers, {\n        'content-type': 'text/plain; charset=utf-8',\n      }).entries(),\n    ),\n    stream: textStream.pipeThrough(new TextEncoderStream()),\n  });\n}\n","import { parseJsonEventStream, ParseResult } from '@ai-sdk/provider-utils';\nimport {\n  UIMessageStreamPart,\n  uiMessageStreamPartSchema,\n} from '../ui-message-stream/ui-message-stream-parts';\nimport { consumeStream } from '../util/consume-stream';\nimport { processTextStream } from './process-text-stream';\nimport { UIDataTypes } from './ui-messages';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => fetch;\n\nexport async function callCompletionApi({\n  api,\n  prompt,\n  credentials,\n  headers,\n  body,\n  streamProtocol = 'data',\n  setCompletion,\n  setLoading,\n  setError,\n  setAbortController,\n  onFinish,\n  onError,\n  fetch = getOriginalFetch(),\n}: {\n  api: string;\n  prompt: string;\n  credentials: RequestCredentials | undefined;\n  headers: HeadersInit | undefined;\n  body: Record<string, any>;\n  streamProtocol: 'data' | 'text' | undefined;\n  setCompletion: (completion: string) => void;\n  setLoading: (loading: boolean) => void;\n  setError: (error: Error | undefined) => void;\n  setAbortController: (abortController: AbortController | null) => void;\n  onFinish: ((prompt: string, completion: string) => void) | undefined;\n  onError: ((error: Error) => void) | undefined;\n  fetch: ReturnType<typeof getOriginalFetch> | undefined;\n}) {\n  try {\n    setLoading(true);\n    setError(undefined);\n\n    const abortController = new AbortController();\n    setAbortController(abortController);\n\n    // Empty the completion immediately.\n    setCompletion('');\n\n    const response = await fetch(api, {\n      method: 'POST',\n      body: JSON.stringify({\n        prompt,\n        ...body,\n      }),\n      credentials,\n      headers: {\n        'Content-Type': 'application/json',\n        ...headers,\n      },\n      signal: abortController.signal,\n    }).catch(err => {\n      throw err;\n    });\n\n    if (!response.ok) {\n      throw new Error(\n        (await response.text()) ?? 'Failed to fetch the chat response.',\n      );\n    }\n\n    if (!response.body) {\n      throw new Error('The response body is empty.');\n    }\n\n    let result = '';\n\n    switch (streamProtocol) {\n      case 'text': {\n        await processTextStream({\n          stream: response.body,\n          onTextPart: chunk => {\n            result += chunk;\n            setCompletion(result);\n          },\n        });\n        break;\n      }\n      case 'data': {\n        await consumeStream({\n          stream: parseJsonEventStream({\n            stream: response.body,\n            schema: uiMessageStreamPartSchema,\n          }).pipeThrough(\n            new TransformStream<\n              ParseResult<UIMessageStreamPart>,\n              UIMessageStreamPart\n            >({\n              async transform(part) {\n                if (!part.success) {\n                  throw part.error;\n                }\n\n                const streamPart = part.value;\n                if (streamPart.type === 'text') {\n                  result += streamPart.text;\n                  setCompletion(result);\n                } else if (streamPart.type === 'error') {\n                  throw new Error(streamPart.errorText);\n                }\n              },\n            }),\n          ),\n          onError: error => {\n            throw error;\n          },\n        });\n        break;\n      }\n      default: {\n        const exhaustiveCheck: never = streamProtocol;\n        throw new Error(`Unknown stream protocol: ${exhaustiveCheck}`);\n      }\n    }\n\n    if (onFinish) {\n      onFinish(prompt, result);\n    }\n\n    setAbortController(null);\n    return result;\n  } catch (err) {\n    // Ignore abort errors as they are expected.\n    if ((err as any).name === 'AbortError') {\n      setAbortController(null);\n      return null;\n    }\n\n    if (err instanceof Error) {\n      if (onError) {\n        onError(err);\n      }\n    }\n\n    setError(err as Error);\n  } finally {\n    setLoading(false);\n  }\n}\n","import { z } from 'zod';\nimport { ValueOf } from '../util/value-of';\nimport {\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  UIDataTypes,\n  UIMessage,\n} from '../ui/ui-messages';\nimport { ProviderMetadata } from '../../core/types/provider-metadata';\n\nexport const uiMessageStreamPartSchema = z.union([\n  z.object({\n    type: z.literal('text'),\n    text: z.string(),\n  }),\n  z.object({\n    type: z.literal('error'),\n    errorText: z.string(),\n  }),\n  z.object({\n    type: z.literal('tool-call-streaming-start'),\n    toolCallId: z.string(),\n    toolName: z.string(),\n  }),\n  z.object({\n    type: z.literal('tool-call-delta'),\n    toolCallId: z.string(),\n    argsTextDelta: z.string(),\n  }),\n  z.object({\n    type: z.literal('tool-call'),\n    toolCallId: z.string(),\n    toolName: z.string(),\n    args: z.unknown(),\n  }),\n  z.object({\n    type: z.literal('tool-result'),\n    toolCallId: z.string(),\n    result: z.unknown(),\n    providerMetadata: z.any().optional(),\n  }),\n  z.object({\n    type: z.literal('reasoning'),\n    text: z.string(),\n    providerMetadata: z.record(z.any()).optional(),\n  }),\n  z.object({\n    type: z.literal('source-url'),\n    sourceId: z.string(),\n    url: z.string(),\n    title: z.string().optional(),\n    providerMetadata: z.any().optional(), // Use z.any() for generic metadata\n  }),\n  z.object({\n    type: z.literal('source-document'),\n    sourceId: z.string(),\n    mediaType: z.string(),\n    title: z.string(),\n    filename: z.string().optional(),\n    providerMetadata: z.any().optional(), // Use z.any() for generic metadata\n  }),\n  z.object({\n    type: z.literal('file'),\n    url: z.string(),\n    mediaType: z.string(),\n  }),\n  z.object({\n    type: z.string().startsWith('data-'),\n    id: z.string().optional(),\n    data: z.unknown(),\n  }),\n  z.object({\n    type: z.literal('metadata'),\n    value: z.object({ metadata: z.unknown() }),\n  }),\n  z.object({\n    type: z.literal('start-step'),\n    metadata: z.unknown().optional(),\n  }),\n  z.object({\n    type: z.literal('finish-step'),\n    metadata: z.unknown().optional(),\n  }),\n  z.object({\n    type: z.literal('start'),\n    messageId: z.string().optional(),\n    metadata: z.unknown().optional(),\n  }),\n  z.object({\n    type: z.literal('finish'),\n    metadata: z.unknown().optional(),\n  }),\n  z.object({\n    type: z.literal('reasoning-part-finish'),\n  }),\n]);\n\nexport type DataUIMessageStreamPart<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n  };\n}>;\n\nexport type UIMessageStreamPart<\n  METADATA = unknown,\n  DATA_TYPES extends UIDataTypes = UIDataTypes,\n> =\n  | {\n      type: 'text';\n      text: string;\n    }\n  | {\n      type: 'error';\n      errorText: string;\n    }\n  | {\n      type: 'tool-call';\n      toolCallId: string;\n      toolName: string;\n      args: unknown;\n    }\n  | {\n      type: 'tool-result';\n      toolCallId: string;\n      result: unknown;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'tool-call-streaming-start';\n      toolCallId: string;\n      toolName: string;\n    }\n  | {\n      type: 'tool-call-delta';\n      toolCallId: string;\n      argsTextDelta: string;\n    }\n  | {\n      type: 'reasoning';\n      text: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'source-url';\n      sourceId: string;\n      url: string;\n      title?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'source-document';\n      sourceId: string;\n      mediaType: string;\n      title: string;\n      filename?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'file';\n      url: string;\n      mediaType: string;\n    }\n  | DataUIMessageStreamPart<DATA_TYPES>\n  | {\n      type: 'metadata';\n      metadata: METADATA;\n    }\n  | {\n      type: 'start-step';\n      metadata?: METADATA;\n    }\n  | {\n      type: 'finish-step';\n      metadata?: METADATA;\n    }\n  | {\n      type: 'start';\n      messageId?: string;\n      metadata?: METADATA;\n    }\n  | {\n      type: 'finish';\n      metadata?: METADATA;\n    }\n  | {\n      type: 'reasoning-part-finish';\n    };\n\nexport function isDataUIMessageStreamPart(\n  part: UIMessageStreamPart,\n): part is DataUIMessageStreamPart<UIDataTypes> {\n  return part.type.startsWith('data-');\n}\n\nexport type InferUIMessageStreamPart<T extends UIMessage> = UIMessageStreamPart<\n  InferUIMessageMetadata<T>,\n  InferUIMessageData<T>\n>;\n","/**\n * Consumes a ReadableStream until it's fully read.\n *\n * This function reads the stream chunk by chunk until the stream is exhausted.\n * It doesn't process or return the data from the stream; it simply ensures\n * that the entire stream is read.\n *\n * @param {ReadableStream} stream - The ReadableStream to be consumed.\n * @returns {Promise<void>} A promise that resolves when the stream is fully consumed.\n */\nexport async function consumeStream({\n  stream,\n  onError,\n}: {\n  stream: ReadableStream;\n  onError?: (error: unknown) => void;\n}): Promise<void> {\n  const reader = stream.getReader();\n  try {\n    while (true) {\n      const { done } = await reader.read();\n      if (done) break;\n    }\n  } catch (error) {\n    onError?.(error);\n  } finally {\n    reader.releaseLock();\n  }\n}\n","export async function processTextStream({\n  stream,\n  onTextPart,\n}: {\n  stream: ReadableStream<Uint8Array>;\n  onTextPart: (chunk: string) => Promise<void> | void;\n}): Promise<void> {\n  const reader = stream.pipeThrough(new TextDecoderStream()).getReader();\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    await onTextPart(value);\n  }\n}\n","import {\n  generateId as generateIdFunc,\n  IdGenerator,\n  StandardSchemaV1,\n  ToolCall,\n  Validator,\n} from '@ai-sdk/provider-utils';\nimport { consumeStream } from '../util/consume-stream';\nimport { SerialJobExecutor } from '../util/serial-job-executor';\nimport { ChatTransport } from './chat-transport';\nimport { convertFileListToFileUIParts } from './convert-file-list-to-file-ui-parts';\nimport { DefaultChatTransport } from './default-chat-transport';\nimport {\n  createStreamingUIMessageState,\n  processUIMessageStream,\n  StreamingUIMessageState,\n} from './process-ui-message-stream';\nimport {\n  isAssistantMessageWithCompletedToolCalls,\n  shouldResubmitMessages,\n} from './should-resubmit-messages';\nimport type {\n  CreateUIMessage,\n  FileUIPart,\n  InferUIDataParts,\n  ToolInvocationUIPart,\n  UIDataPartSchemas,\n  UIDataTypes,\n  UIMessage,\n} from './ui-messages';\n\nexport type ChatRequestOptions = {\n  /**\n  Additional headers that should be to be passed to the API endpoint.\n   */\n  headers?: Record<string, string> | Headers;\n\n  /**\n  Additional body JSON properties that should be sent to the API endpoint.\n   */\n  body?: object; // TODO JSONStringifyable\n\n  metadata?: unknown;\n};\n\nexport type ChatStatus = 'submitted' | 'streaming' | 'ready' | 'error';\n\ntype ActiveResponse<UI_MESSAGE extends UIMessage> = {\n  state: StreamingUIMessageState<UI_MESSAGE>;\n  abortController: AbortController | undefined;\n};\n\nexport interface ChatState<MESSAGE_METADATA, DATA_TYPES extends UIDataTypes> {\n  status: ChatStatus;\n\n  error: Error | undefined;\n\n  messages: UIMessage<MESSAGE_METADATA, DATA_TYPES>[];\n  pushMessage: (message: UIMessage<MESSAGE_METADATA, DATA_TYPES>) => void;\n  popMessage: () => void;\n  replaceMessage: (\n    index: number,\n    message: UIMessage<MESSAGE_METADATA, DATA_TYPES>,\n  ) => void;\n\n  snapshot: <T>(thing: T) => T;\n}\n\nexport interface ChatInit<\n  MESSAGE_METADATA = unknown,\n  UI_DATA_PART_SCHEMAS extends UIDataPartSchemas = UIDataPartSchemas,\n> {\n  /**\n   * A unique identifier for the chat. If not provided, a random one will be\n   * generated.\n   */\n  id?: string;\n\n  messageMetadataSchema?:\n    | Validator<MESSAGE_METADATA>\n    | StandardSchemaV1<MESSAGE_METADATA>;\n  dataPartSchemas?: UI_DATA_PART_SCHEMAS;\n\n  messages?: UIMessage<\n    MESSAGE_METADATA,\n    InferUIDataParts<UI_DATA_PART_SCHEMAS>\n  >[];\n\n  /**\n   * A way to provide a function that is going to be used for ids for messages and the chat.\n   * If not provided the default AI SDK `generateId` is used.\n   */\n  generateId?: IdGenerator;\n\n  transport?: ChatTransport<\n    NoInfer<MESSAGE_METADATA>,\n    NoInfer<InferUIDataParts<UI_DATA_PART_SCHEMAS>>\n  >;\n\n  maxSteps?: number;\n\n  /**\n   * Callback function to be called when an error is encountered.\n   */\n  onError?: (error: Error) => void;\n\n  /**\n  Optional callback function that is invoked when a tool call is received.\n  Intended for automatic client-side tool execution.\n\n  You can optionally return a result for the tool call,\n  either synchronously or asynchronously.\n     */\n  onToolCall?: ({\n    toolCall,\n  }: {\n    toolCall: ToolCall<string, unknown>;\n  }) => void | Promise<unknown> | unknown;\n\n  /**\n   * Optional callback function that is called when the assistant message is finished streaming.\n   *\n   * @param message The message that was streamed.\n   */\n  onFinish?: (options: {\n    message: UIMessage<\n      NoInfer<MESSAGE_METADATA>,\n      NoInfer<InferUIDataParts<UI_DATA_PART_SCHEMAS>>\n    >;\n  }) => void;\n}\n\nexport abstract class AbstractChat<\n  MESSAGE_METADATA = unknown,\n  UI_DATA_PART_SCHEMAS extends UIDataPartSchemas = UIDataPartSchemas,\n> {\n  readonly id: string;\n  readonly generateId: IdGenerator;\n\n  protected state: ChatState<\n    MESSAGE_METADATA,\n    InferUIDataParts<UI_DATA_PART_SCHEMAS>\n  >;\n\n  private messageMetadataSchema:\n    | Validator<MESSAGE_METADATA>\n    | StandardSchemaV1<MESSAGE_METADATA>\n    | undefined;\n  private dataPartSchemas: UI_DATA_PART_SCHEMAS | undefined;\n  private readonly transport: ChatTransport<\n    MESSAGE_METADATA,\n    InferUIDataParts<UI_DATA_PART_SCHEMAS>\n  >;\n  private maxSteps: number;\n  private onError?: ChatInit<MESSAGE_METADATA, UI_DATA_PART_SCHEMAS>['onError'];\n  private onToolCall?: ChatInit<\n    MESSAGE_METADATA,\n    UI_DATA_PART_SCHEMAS\n  >['onToolCall'];\n  private onFinish?: ChatInit<\n    MESSAGE_METADATA,\n    UI_DATA_PART_SCHEMAS\n  >['onFinish'];\n\n  private activeResponse:\n    | ActiveResponse<\n        UIMessage<MESSAGE_METADATA, InferUIDataParts<UI_DATA_PART_SCHEMAS>>\n      >\n    | undefined = undefined;\n  private jobExecutor = new SerialJobExecutor();\n\n  constructor({\n    generateId = generateIdFunc,\n    id = generateId(),\n    transport = new DefaultChatTransport(),\n    maxSteps = 1,\n    messageMetadataSchema,\n    dataPartSchemas,\n    state,\n    onError,\n    onToolCall,\n    onFinish,\n  }: Omit<ChatInit<MESSAGE_METADATA, UI_DATA_PART_SCHEMAS>, 'messages'> & {\n    state: ChatState<MESSAGE_METADATA, InferUIDataParts<UI_DATA_PART_SCHEMAS>>;\n  }) {\n    this.id = id;\n    this.maxSteps = maxSteps;\n    this.transport = transport;\n    this.generateId = generateId;\n    this.messageMetadataSchema = messageMetadataSchema;\n    this.dataPartSchemas = dataPartSchemas;\n    this.state = state;\n    this.onError = onError;\n    this.onToolCall = onToolCall;\n    this.onFinish = onFinish;\n  }\n\n  /**\n   * Hook status:\n   *\n   * - `submitted`: The message has been sent to the API and we're awaiting the start of the response stream.\n   * - `streaming`: The response is actively streaming in from the API, receiving chunks of data.\n   * - `ready`: The full response has been received and processed; a new user message can be submitted.\n   * - `error`: An error occurred during the API request, preventing successful completion.\n   */\n  get status(): ChatStatus {\n    return this.state.status;\n  }\n\n  protected setStatus({\n    status,\n    error,\n  }: {\n    status: ChatStatus;\n    error?: Error;\n  }) {\n    if (this.status === status) return;\n\n    this.state.status = status;\n    this.state.error = error;\n  }\n\n  get error() {\n    return this.state.error;\n  }\n\n  get messages(): UIMessage<\n    MESSAGE_METADATA,\n    InferUIDataParts<UI_DATA_PART_SCHEMAS>\n  >[] {\n    return this.state.messages;\n  }\n\n  get lastMessage():\n    | UIMessage<MESSAGE_METADATA, InferUIDataParts<UI_DATA_PART_SCHEMAS>>\n    | undefined {\n    return this.state.messages[this.state.messages.length - 1];\n  }\n\n  set messages(\n    messages: UIMessage<\n      MESSAGE_METADATA,\n      InferUIDataParts<UI_DATA_PART_SCHEMAS>\n    >[],\n  ) {\n    this.state.messages = messages;\n  }\n\n  removeAssistantResponse = () => {\n    const lastMessage = this.state.messages[this.state.messages.length - 1];\n\n    if (lastMessage == null) {\n      throw new Error('Cannot remove assistant response from empty chat');\n    }\n\n    if (lastMessage.role !== 'assistant') {\n      throw new Error('Last message is not an assistant message');\n    }\n\n    this.state.popMessage();\n  };\n\n  /**\n   * Append a user message to the chat list. This triggers the API call to fetch\n   * the assistant's response.\n   */\n  sendMessage = async (\n    message:\n      | (CreateUIMessage<\n          MESSAGE_METADATA,\n          InferUIDataParts<UI_DATA_PART_SCHEMAS>\n        > & { text?: never; files?: never })\n      | {\n          text: string;\n          files?: FileList | FileUIPart[];\n          metadata?: MESSAGE_METADATA;\n          parts?: never;\n        }\n      | {\n          files: FileList | FileUIPart[];\n          metadata?: MESSAGE_METADATA;\n          parts?: never;\n        },\n    options: ChatRequestOptions = {},\n  ): Promise<void> => {\n    let uiMessage: CreateUIMessage<\n      MESSAGE_METADATA,\n      InferUIDataParts<UI_DATA_PART_SCHEMAS>\n    >;\n\n    if ('text' in message || 'files' in message) {\n      const fileParts = Array.isArray(message.files)\n        ? message.files\n        : await convertFileListToFileUIParts(message.files);\n\n      uiMessage = {\n        parts: [\n          ...fileParts,\n          ...('text' in message && message.text != null\n            ? [{ type: 'text' as const, text: message.text }]\n            : []),\n        ],\n      };\n    } else {\n      uiMessage = message;\n    }\n\n    this.state.pushMessage({\n      ...uiMessage,\n      id: uiMessage.id ?? this.generateId(),\n      role: uiMessage.role ?? 'user',\n    });\n\n    await this.triggerRequest({ requestType: 'generate', ...options });\n  };\n\n  /**\n   * Regenerate the last assistant message.\n   */\n  reload = async (options: ChatRequestOptions = {}): Promise<void> => {\n    // TODO stop any ongoing request\n    if (this.lastMessage === undefined) {\n      return;\n    }\n\n    if (this.lastMessage.role === 'assistant') {\n      this.state.popMessage();\n    }\n\n    await this.triggerRequest({ requestType: 'generate', ...options });\n  };\n\n  /**\n   * Resume an ongoing chat generation stream. This does not resume an aborted generation.\n   */\n  experimental_resume = async (\n    options: ChatRequestOptions = {},\n  ): Promise<void> => {\n    await this.triggerRequest({ requestType: 'resume', ...options });\n  };\n\n  addToolResult = async ({\n    toolCallId,\n    result,\n  }: {\n    toolCallId: string;\n    result: unknown;\n  }) => {\n    this.jobExecutor.run(async () => {\n      updateToolCallResult({\n        messages: this.state.messages,\n        toolCallId,\n        toolResult: result,\n      });\n\n      this.messages = this.state.messages;\n\n      // when the request is ongoing, the auto-submit will be triggered after the request is finished\n      if (this.status === 'submitted' || this.status === 'streaming') {\n        return;\n      }\n\n      // auto-submit when all tool calls in the last assistant message have results:\n      const lastMessage = this.lastMessage;\n      if (isAssistantMessageWithCompletedToolCalls(lastMessage)) {\n        // we do not await this call to avoid a deadlock in the serial job executor; triggerRequest also uses the job executor internally.\n        this.triggerRequest({\n          requestType: 'generate',\n        });\n      }\n    });\n  };\n\n  /**\n   * Abort the current request immediately, keep the generated tokens if any.\n   */\n  stop = async () => {\n    if (this.status !== 'streaming' && this.status !== 'submitted') return;\n\n    if (this.activeResponse?.abortController) {\n      this.activeResponse.abortController.abort();\n      this.activeResponse.abortController = undefined;\n    }\n  };\n\n  private async triggerRequest({\n    requestType,\n    metadata,\n    headers,\n    body,\n  }: {\n    requestType: 'generate' | 'resume';\n  } & ChatRequestOptions) {\n    this.setStatus({ status: 'submitted', error: undefined });\n\n    const messageCount = this.state.messages.length;\n    const lastMessage = this.lastMessage;\n    const maxStep =\n      lastMessage?.parts.filter(part => part.type === 'step-start').length ?? 0; // TODO: should this be 1?\n\n    try {\n      const activeResponse = {\n        state: createStreamingUIMessageState({\n          lastMessage: this.state.snapshot(lastMessage),\n          newMessageId: this.generateId(),\n        }),\n        abortController: new AbortController(),\n      };\n\n      this.activeResponse = activeResponse;\n\n      const stream = await this.transport.submitMessages({\n        chatId: this.id,\n        messages: this.state.messages,\n        abortSignal: activeResponse.abortController.signal,\n        metadata,\n        headers,\n        body,\n        requestType,\n      });\n\n      const runUpdateMessageJob = (\n        job: (options: {\n          state: StreamingUIMessageState<\n            UIMessage<MESSAGE_METADATA, InferUIDataParts<UI_DATA_PART_SCHEMAS>>\n          >;\n          write: () => void;\n        }) => Promise<void>,\n      ) =>\n        // serialize the job execution to avoid race conditions:\n        this.jobExecutor.run(() =>\n          job({\n            state: activeResponse.state,\n            write: () => {\n              // streaming is set on first write (before it should be \"submitted\")\n              this.setStatus({ status: 'streaming' });\n\n              const replaceLastMessage =\n                activeResponse.state.message.id === this.lastMessage?.id;\n\n              if (replaceLastMessage) {\n                this.state.replaceMessage(\n                  this.state.messages.length - 1,\n                  activeResponse.state.message,\n                );\n              } else {\n                this.state.pushMessage(activeResponse.state.message);\n              }\n            },\n          }),\n        );\n\n      await consumeStream({\n        stream: processUIMessageStream({\n          stream,\n          onToolCall: this.onToolCall,\n          messageMetadataSchema: this.messageMetadataSchema,\n          dataPartSchemas: this.dataPartSchemas,\n          runUpdateMessageJob,\n        }),\n        onError: error => {\n          throw error;\n        },\n      });\n\n      this.onFinish?.({ message: activeResponse.state.message });\n\n      this.setStatus({ status: 'ready' });\n    } catch (err) {\n      console.error(err);\n\n      // Ignore abort errors as they are expected.\n      if ((err as any).name === 'AbortError') {\n        this.setStatus({ status: 'ready' });\n        return null;\n      }\n\n      if (this.onError && err instanceof Error) {\n        this.onError(err);\n      }\n\n      this.setStatus({ status: 'error', error: err as Error });\n    } finally {\n      this.activeResponse = undefined;\n    }\n\n    // auto-submit when all tool calls in the last assistant message have results\n    // and assistant has not answered yet\n    if (\n      shouldResubmitMessages({\n        originalMaxToolInvocationStep: maxStep,\n        originalMessageCount: messageCount,\n        maxSteps: this.maxSteps,\n        messages: this.state.messages,\n      })\n    ) {\n      await this.triggerRequest({\n        requestType,\n        metadata,\n        headers,\n        body,\n      });\n    }\n  }\n}\n\n/**\n * Updates the result of a specific tool invocation in the last message of the given messages array.\n *\n * @param {object} params - The parameters object.\n * @param {UIMessage[]} params.messages - An array of messages, from which the last one is updated.\n * @param {string} params.toolCallId - The unique identifier for the tool invocation to update.\n * @param {unknown} params.toolResult - The result object to attach to the tool invocation.\n * @returns {void} This function does not return anything.\n */\nfunction updateToolCallResult({\n  messages,\n  toolCallId,\n  toolResult: result,\n}: {\n  messages: UIMessage[];\n  toolCallId: string;\n  toolResult: unknown;\n}) {\n  const lastMessage = messages[messages.length - 1];\n\n  const invocationPart = lastMessage.parts.find(\n    (part): part is ToolInvocationUIPart =>\n      part.type === 'tool-invocation' &&\n      part.toolInvocation.toolCallId === toolCallId,\n  );\n\n  if (invocationPart == null) {\n    return;\n  }\n\n  invocationPart.toolInvocation = {\n    ...invocationPart.toolInvocation,\n    state: 'result' as const,\n    result,\n  };\n}\n","import { Job } from './job';\n\nexport class SerialJobExecutor {\n  private queue: Array<Job> = [];\n  private isProcessing = false;\n\n  private async processQueue() {\n    if (this.isProcessing) {\n      return;\n    }\n\n    this.isProcessing = true;\n\n    while (this.queue.length > 0) {\n      await this.queue[0]();\n      this.queue.shift();\n    }\n\n    this.isProcessing = false;\n  }\n\n  async run(job: Job): Promise<void> {\n    return new Promise<void>((resolve, reject) => {\n      this.queue.push(async () => {\n        try {\n          await job();\n          resolve();\n        } catch (error) {\n          reject(error);\n        }\n      });\n\n      void this.processQueue();\n    });\n  }\n}\n","import { FileUIPart } from './ui-messages';\n\nexport async function convertFileListToFileUIParts(\n  files: FileList | undefined,\n): Promise<Array<FileUIPart>> {\n  if (files == null) {\n    return [];\n  }\n\n  // React-native doesn't have a FileList global:\n  if (!globalThis.FileList || !(files instanceof globalThis.FileList)) {\n    throw new Error('FileList is not supported in the current environment');\n  }\n\n  return Promise.all(\n    Array.from(files).map(async file => {\n      const { name, type } = file;\n\n      const dataUrl = await new Promise<string>((resolve, reject) => {\n        const reader = new FileReader();\n        reader.onload = readerEvent => {\n          resolve(readerEvent.target?.result as string);\n        };\n        reader.onerror = error => reject(error);\n        reader.readAsDataURL(file);\n      });\n\n      return {\n        type: 'file',\n        mediaType: type,\n        filename: name,\n        url: dataUrl,\n      };\n    }),\n  );\n}\n","import {\n  FetchFunction,\n  parseJsonEventStream,\n  ParseResult,\n} from '@ai-sdk/provider-utils';\nimport {\n  UIMessageStreamPart,\n  uiMessageStreamPartSchema,\n} from '../ui-message-stream/ui-message-stream-parts';\nimport { ChatTransport } from './chat-transport';\nimport { PrepareRequest } from './prepare-request';\nimport { UIDataTypes } from './ui-messages';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => fetch;\n\nasync function fetchUIMessageStream({\n  api,\n  body,\n  credentials,\n  headers,\n  abortSignal,\n  fetch = getOriginalFetch(),\n  requestType = 'generate',\n}: {\n  api: string;\n  body: Record<string, any>;\n  credentials: RequestCredentials | undefined;\n  headers: HeadersInit | undefined;\n  abortSignal: AbortSignal | undefined;\n  fetch: ReturnType<typeof getOriginalFetch> | undefined;\n  requestType?: 'generate' | 'resume';\n}): Promise<ReadableStream<UIMessageStreamPart>> {\n  const response =\n    requestType === 'resume'\n      ? await fetch(`${api}?id=${body.id}`, {\n          method: 'GET',\n          headers: {\n            'Content-Type': 'application/json',\n            ...headers,\n          },\n          signal: abortSignal,\n          credentials,\n        })\n      : await fetch(api, {\n          method: 'POST',\n          body: JSON.stringify(body),\n          headers: {\n            'Content-Type': 'application/json',\n            ...headers,\n          },\n          signal: abortSignal,\n          credentials,\n        });\n\n  if (!response.ok) {\n    throw new Error(\n      (await response.text()) ?? 'Failed to fetch the chat response.',\n    );\n  }\n\n  if (!response.body) {\n    throw new Error('The response body is empty.');\n  }\n\n  return parseJsonEventStream({\n    stream: response.body,\n    schema: uiMessageStreamPartSchema,\n  }).pipeThrough(\n    new TransformStream<ParseResult<UIMessageStreamPart>, UIMessageStreamPart>({\n      async transform(part, controller) {\n        if (!part.success) {\n          throw part.error;\n        }\n        controller.enqueue(part.value);\n      },\n    }),\n  );\n}\n\nexport class DefaultChatTransport<\n  MESSAGE_METADATA,\n  DATA_TYPES extends UIDataTypes,\n> implements ChatTransport<MESSAGE_METADATA, DATA_TYPES>\n{\n  private api: string;\n  private credentials?: RequestCredentials;\n  private headers?: Record<string, string> | Headers;\n  private body?: object;\n  private fetch?: FetchFunction;\n  private prepareRequest?: PrepareRequest<MESSAGE_METADATA, DATA_TYPES>;\n\n  constructor({\n    api = '/api/chat',\n    credentials,\n    headers,\n    body,\n    fetch,\n    prepareRequest,\n  }: {\n    api?: string;\n\n    /**\n     * The credentials mode to be used for the fetch request.\n     * Possible values are: 'omit', 'same-origin', 'include'.\n     * Defaults to 'same-origin'.\n     */\n    credentials?: RequestCredentials;\n\n    /**\n     * HTTP headers to be sent with the API request.\n     */\n    headers?: Record<string, string> | Headers;\n\n    /**\n     * Extra body object to be sent with the API request.\n     * @example\n     * Send a `sessionId` to the API along with the messages.\n     * ```js\n     * useChat({\n     *   body: {\n     *     sessionId: '123',\n     *   }\n     * })\n     * ```\n     */\n    body?: object;\n\n    /**\n  Custom fetch implementation. You can use it as a middleware to intercept requests,\n  or to provide a custom fetch implementation for e.g. testing.\n      */\n    fetch?: FetchFunction;\n\n    /**\n     * When a function is provided, it will be used\n     * to prepare the request body for the chat API. This can be useful for\n     * customizing the request body based on the messages and data in the chat.\n     *\n     * @param id The id of the chat.\n     * @param messages The current messages in the chat.\n     * @param requestBody The request body object passed in the chat request.\n     */\n    prepareRequest?: PrepareRequest<MESSAGE_METADATA, DATA_TYPES>;\n  } = {}) {\n    this.api = api;\n    this.credentials = credentials;\n    this.headers = headers;\n    this.body = body;\n    this.fetch = fetch;\n    this.prepareRequest = prepareRequest;\n  }\n\n  submitMessages({\n    chatId,\n    messages,\n    abortSignal,\n    metadata,\n    headers,\n    body,\n    requestType,\n  }: Parameters<\n    ChatTransport<MESSAGE_METADATA, DATA_TYPES>['submitMessages']\n  >[0]) {\n    const preparedRequest = this.prepareRequest?.({\n      id: chatId,\n      messages,\n      body: { ...this.body, ...body },\n      headers: { ...this.headers, ...headers },\n      credentials: this.credentials,\n      requestMetadata: metadata,\n    });\n\n    return fetchUIMessageStream({\n      api: this.api,\n      body:\n        preparedRequest?.body !== undefined\n          ? preparedRequest.body\n          : { ...this.body, ...body, id: chatId, messages },\n      headers:\n        preparedRequest?.headers !== undefined\n          ? preparedRequest.headers\n          : { ...this.headers, ...headers },\n      credentials: preparedRequest?.credentials ?? this.credentials,\n      abortSignal,\n      fetch: this.fetch,\n      requestType,\n    });\n  }\n}\n","import {\n  StandardSchemaV1,\n  ToolCall,\n  validateTypes,\n  Validator,\n} from '@ai-sdk/provider-utils';\nimport {\n  InferUIMessageStreamPart,\n  isDataUIMessageStreamPart,\n  UIMessageStreamPart,\n} from '../ui-message-stream/ui-message-stream-parts';\nimport { mergeObjects } from '../util/merge-objects';\nimport { parsePartialJson } from '../util/parse-partial-json';\nimport { getToolInvocations } from './get-tool-invocations';\nimport type {\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  ReasoningUIPart,\n  TextUIPart,\n  ToolInvocation,\n  ToolInvocationUIPart,\n  UIDataTypes,\n  UIDataTypesToSchemas,\n  UIMessage,\n  UIMessagePart,\n} from './ui-messages';\n\nexport type StreamingUIMessageState<UI_MESSAGE extends UIMessage> = {\n  message: UI_MESSAGE;\n  activeTextPart: TextUIPart | undefined;\n  activeReasoningPart: ReasoningUIPart | undefined;\n  partialToolCalls: Record<\n    string,\n    { text: string; index: number; toolName: string }\n  >;\n};\n\nexport function createStreamingUIMessageState<\n  MESSAGE_METADATA = unknown,\n  UI_DATA_TYPES extends UIDataTypes = UIDataTypes,\n>({\n  lastMessage,\n  newMessageId = '',\n}: {\n  lastMessage?: UIMessage<MESSAGE_METADATA, UI_DATA_TYPES>;\n  newMessageId?: string;\n} = {}): StreamingUIMessageState<UIMessage<MESSAGE_METADATA, UI_DATA_TYPES>> {\n  const isContinuation = lastMessage?.role === 'assistant';\n\n  const message: UIMessage<MESSAGE_METADATA, UI_DATA_TYPES> = isContinuation\n    ? lastMessage\n    : {\n        id: newMessageId,\n        metadata: {} as MESSAGE_METADATA,\n        role: 'assistant',\n        parts: [],\n      };\n\n  return {\n    message,\n    activeTextPart: undefined,\n    activeReasoningPart: undefined,\n    partialToolCalls: {},\n  };\n}\n\nexport function processUIMessageStream<UI_MESSAGE extends UIMessage>({\n  stream,\n  onToolCall,\n  messageMetadataSchema,\n  dataPartSchemas,\n  runUpdateMessageJob,\n}: {\n  // input stream is not fully typed yet:\n  stream: ReadableStream<UIMessageStreamPart>;\n  messageMetadataSchema?:\n    | Validator<InferUIMessageMetadata<UI_MESSAGE>>\n    | StandardSchemaV1<InferUIMessageMetadata<UI_MESSAGE>>;\n  dataPartSchemas?: UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>;\n  onToolCall?: (options: {\n    toolCall: ToolCall<string, unknown>;\n  }) => void | Promise<unknown> | unknown;\n  runUpdateMessageJob: (\n    job: (options: {\n      state: StreamingUIMessageState<\n        UIMessage<\n          InferUIMessageMetadata<UI_MESSAGE>,\n          InferUIMessageData<UI_MESSAGE>\n        >\n      >;\n      write: () => void;\n    }) => Promise<void>,\n  ) => Promise<void>;\n}): ReadableStream<InferUIMessageStreamPart<UI_MESSAGE>> {\n  return stream.pipeThrough(\n    new TransformStream<\n      UIMessageStreamPart,\n      InferUIMessageStreamPart<UI_MESSAGE>\n    >({\n      async transform(part, controller) {\n        await runUpdateMessageJob(async ({ state, write }) => {\n          function updateToolInvocationPart(\n            toolCallId: string,\n            invocation: ToolInvocation,\n          ) {\n            const part = state.message.parts.find(\n              part =>\n                isToolInvocationUIPart(part) &&\n                part.toolInvocation.toolCallId === toolCallId,\n            ) as ToolInvocationUIPart | undefined;\n\n            if (part != null) {\n              part.toolInvocation = invocation;\n            } else {\n              state.message.parts.push({\n                type: 'tool-invocation',\n                toolInvocation: invocation,\n              });\n            }\n          }\n\n          async function updateMessageMetadata(metadata: unknown) {\n            if (metadata != null) {\n              const mergedMetadata =\n                state.message.metadata != null\n                  ? mergeObjects(state.message.metadata, metadata)\n                  : metadata;\n\n              if (messageMetadataSchema != null) {\n                await validateTypes({\n                  value: mergedMetadata,\n                  schema: messageMetadataSchema,\n                });\n              }\n\n              state.message.metadata =\n                mergedMetadata as InferUIMessageMetadata<UI_MESSAGE>;\n            }\n          }\n\n          switch (part.type) {\n            case 'text': {\n              if (state.activeTextPart == null) {\n                state.activeTextPart = {\n                  type: 'text',\n                  text: part.text,\n                };\n                state.message.parts.push(state.activeTextPart);\n              } else {\n                state.activeTextPart.text += part.text;\n              }\n\n              write();\n              break;\n            }\n\n            case 'reasoning': {\n              if (state.activeReasoningPart == null) {\n                state.activeReasoningPart = {\n                  type: 'reasoning',\n                  text: part.text,\n                  providerMetadata: part.providerMetadata,\n                };\n                state.message.parts.push(state.activeReasoningPart);\n              } else {\n                state.activeReasoningPart.text += part.text;\n                state.activeReasoningPart.providerMetadata =\n                  part.providerMetadata;\n              }\n\n              write();\n              break;\n            }\n\n            case 'reasoning-part-finish': {\n              if (state.activeReasoningPart != null) {\n                state.activeReasoningPart = undefined;\n              }\n              break;\n            }\n\n            case 'file': {\n              state.message.parts.push({\n                type: 'file',\n                mediaType: part.mediaType,\n                url: part.url,\n              });\n\n              write();\n              break;\n            }\n\n            case 'source-url': {\n              state.message.parts.push({\n                type: 'source-url',\n                sourceId: part.sourceId,\n                url: part.url,\n                title: part.title,\n                providerMetadata: part.providerMetadata,\n              });\n\n              write();\n              break;\n            }\n\n            case 'source-document': {\n              state.message.parts.push({\n                type: 'source-document',\n                sourceId: part.sourceId,\n                mediaType: part.mediaType,\n                title: part.title,\n                filename: part.filename,\n                providerMetadata: part.providerMetadata,\n              });\n\n              write();\n              break;\n            }\n\n            case 'tool-call-streaming-start': {\n              const toolInvocations = getToolInvocations(state.message);\n\n              // add the partial tool call to the map\n              state.partialToolCalls[part.toolCallId] = {\n                text: '',\n                toolName: part.toolName,\n                index: toolInvocations.length,\n              };\n\n              updateToolInvocationPart(part.toolCallId, {\n                state: 'partial-call',\n                toolCallId: part.toolCallId,\n                toolName: part.toolName,\n                args: undefined,\n              } as const);\n\n              write();\n              break;\n            }\n\n            case 'tool-call-delta': {\n              const partialToolCall = state.partialToolCalls[part.toolCallId];\n\n              partialToolCall.text += part.argsTextDelta;\n\n              const { value: partialArgs } = await parsePartialJson(\n                partialToolCall.text,\n              );\n\n              updateToolInvocationPart(part.toolCallId, {\n                state: 'partial-call',\n                toolCallId: part.toolCallId,\n                toolName: partialToolCall.toolName,\n                args: partialArgs,\n              } as const);\n\n              write();\n              break;\n            }\n\n            case 'tool-call': {\n              updateToolInvocationPart(part.toolCallId, {\n                state: 'call',\n                toolCallId: part.toolCallId,\n                toolName: part.toolName,\n                args: part.args,\n              } as const);\n\n              write();\n\n              // invoke the onToolCall callback if it exists. This is blocking.\n              // In the future we should make this non-blocking, which\n              // requires additional state management for error handling etc.\n              if (onToolCall) {\n                const result = await onToolCall({\n                  toolCall: part,\n                });\n                if (result != null) {\n                  updateToolInvocationPart(part.toolCallId, {\n                    state: 'result',\n                    toolCallId: part.toolCallId,\n                    toolName: part.toolName,\n                    args: part.args,\n                    result,\n                  } as const);\n\n                  write();\n                }\n              }\n              break;\n            }\n\n            case 'tool-result': {\n              const toolInvocations = getToolInvocations(state.message);\n\n              if (toolInvocations == null) {\n                throw new Error('tool_result must be preceded by a tool_call');\n              }\n\n              // find if there is any tool invocation with the same toolCallId\n              // and replace it with the result\n              const toolInvocationIndex = toolInvocations.findIndex(\n                invocation => invocation.toolCallId === part.toolCallId,\n              );\n\n              if (toolInvocationIndex === -1) {\n                throw new Error(\n                  'tool_result must be preceded by a tool_call with the same toolCallId',\n                );\n              }\n\n              updateToolInvocationPart(part.toolCallId, {\n                ...toolInvocations[toolInvocationIndex],\n                state: 'result' as const,\n                result: part.result,\n              } as const);\n\n              write();\n              break;\n            }\n\n            case 'start-step': {\n              // add a step boundary part to the message\n              state.message.parts.push({ type: 'step-start' });\n\n              await updateMessageMetadata(part.metadata);\n              write();\n              break;\n            }\n\n            case 'finish-step': {\n              // reset the current text and reasoning parts\n              state.activeTextPart = undefined;\n              state.activeReasoningPart = undefined;\n\n              await updateMessageMetadata(part.metadata);\n              if (part.metadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'start': {\n              if (part.messageId != null) {\n                state.message.id = part.messageId;\n              }\n\n              await updateMessageMetadata(part.metadata);\n\n              if (part.messageId != null || part.metadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'finish': {\n              await updateMessageMetadata(part.metadata);\n              if (part.metadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'metadata': {\n              await updateMessageMetadata(part.metadata);\n              if (part.metadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'error': {\n              throw new Error(part.errorText);\n            }\n\n            default: {\n              if (isDataUIMessageStreamPart(part)) {\n                // TODO improve type safety\n                const existingPart: any =\n                  part.id != null\n                    ? state.message.parts.find(\n                        (partArg: any) =>\n                          part.type === partArg.type && part.id === partArg.id,\n                      )\n                    : undefined;\n\n                if (existingPart != null) {\n                  // TODO improve type safety\n                  existingPart.data =\n                    isObject(existingPart.data) && isObject(part.data)\n                      ? mergeObjects(existingPart.data, part.data)\n                      : part.data;\n                } else {\n                  // TODO improve type safety\n                  state.message.parts.push(part as any);\n                }\n                write();\n              }\n            }\n          }\n\n          controller.enqueue(part as InferUIMessageStreamPart<UI_MESSAGE>);\n        });\n      },\n    }),\n  );\n}\n\n// helper function to narrow the type of a UIMessagePart\nfunction isToolInvocationUIPart(\n  part: UIMessagePart<any>,\n): part is ToolInvocationUIPart {\n  return part.type === 'tool-invocation';\n}\n\nfunction isObject(value: unknown): value is object {\n  return typeof value === 'object' && value !== null;\n}\n","/**\n * Deeply merges two objects together.\n * - Properties from the `overrides` object override those in the `base` object with the same key.\n * - For nested objects, the merge is performed recursively (deep merge).\n * - Arrays are replaced, not merged.\n * - Primitive values are replaced.\n * - If both `base` and `overrides` are undefined, returns undefined.\n * - If one of `base` or `overrides` is undefined, returns the other.\n *\n * @param base The target object to merge into\n * @param overrides The source object to merge from\n * @returns A new object with the merged properties, or undefined if both inputs are undefined\n */\nexport function mergeObjects<T extends object, U extends object>(\n  base: T | undefined,\n  overrides: U | undefined,\n): (T & U) | T | U | undefined {\n  // If both inputs are undefined, return undefined\n  if (base === undefined && overrides === undefined) {\n    return undefined;\n  }\n\n  // If target is undefined, return source\n  if (base === undefined) {\n    return overrides;\n  }\n\n  // If source is undefined, return target\n  if (overrides === undefined) {\n    return base;\n  }\n\n  // Create a new object to avoid mutating the inputs\n  const result = { ...base } as T & U;\n\n  // Iterate through all keys in the source object\n  for (const key in overrides) {\n    if (Object.prototype.hasOwnProperty.call(overrides, key)) {\n      const overridesValue = overrides[key];\n\n      // Skip if the overrides value is undefined\n      if (overridesValue === undefined) continue;\n\n      // Get the base value if it exists\n      const baseValue =\n        key in base ? base[key as unknown as keyof T] : undefined;\n\n      // Check if both values are objects that can be deeply merged\n      const isSourceObject =\n        overridesValue !== null &&\n        typeof overridesValue === 'object' &&\n        !Array.isArray(overridesValue) &&\n        !(overridesValue instanceof Date) &&\n        !(overridesValue instanceof RegExp);\n\n      const isTargetObject =\n        baseValue !== null &&\n        baseValue !== undefined &&\n        typeof baseValue === 'object' &&\n        !Array.isArray(baseValue) &&\n        !(baseValue instanceof Date) &&\n        !(baseValue instanceof RegExp);\n\n      // If both values are mergeable objects, merge them recursively\n      if (isSourceObject && isTargetObject) {\n        result[key as keyof (T & U)] = mergeObjects(\n          baseValue as object,\n          overridesValue as object,\n        ) as any;\n      } else {\n        // For primitives, arrays, or when one value is not a mergeable object,\n        // simply override with the source value\n        result[key as keyof (T & U)] = overridesValue as any;\n      }\n    }\n  }\n\n  return result;\n}\n","import { JSONValue } from '@ai-sdk/provider';\nimport { safeParseJSON } from '@ai-sdk/provider-utils';\nimport { fixJson } from './fix-json';\n\nexport async function parsePartialJson(jsonText: string | undefined): Promise<{\n  value: JSONValue | undefined;\n  state:\n    | 'undefined-input'\n    | 'successful-parse'\n    | 'repaired-parse'\n    | 'failed-parse';\n}> {\n  if (jsonText === undefined) {\n    return { value: undefined, state: 'undefined-input' };\n  }\n\n  let result = await safeParseJSON({ text: jsonText });\n\n  if (result.success) {\n    return { value: result.value, state: 'successful-parse' };\n  }\n\n  result = await safeParseJSON({ text: fixJson(jsonText) });\n\n  if (result.success) {\n    return { value: result.value, state: 'repaired-parse' };\n  }\n\n  return { value: undefined, state: 'failed-parse' };\n}\n","type State =\n  | 'ROOT'\n  | 'FINISH'\n  | 'INSIDE_STRING'\n  | 'INSIDE_STRING_ESCAPE'\n  | 'INSIDE_LITERAL'\n  | 'INSIDE_NUMBER'\n  | 'INSIDE_OBJECT_START'\n  | 'INSIDE_OBJECT_KEY'\n  | 'INSIDE_OBJECT_AFTER_KEY'\n  | 'INSIDE_OBJECT_BEFORE_VALUE'\n  | 'INSIDE_OBJECT_AFTER_VALUE'\n  | 'INSIDE_OBJECT_AFTER_COMMA'\n  | 'INSIDE_ARRAY_START'\n  | 'INSIDE_ARRAY_AFTER_VALUE'\n  | 'INSIDE_ARRAY_AFTER_COMMA';\n\n// Implemented as a scanner with additional fixing\n// that performs a single linear time scan pass over the partial JSON.\n//\n// The states should ideally match relevant states from the JSON spec:\n// https://www.json.org/json-en.html\n//\n// Please note that invalid JSON is not considered/covered, because it\n// is assumed that the resulting JSON will be processed by a standard\n// JSON parser that will detect any invalid JSON.\nexport function fixJson(input: string): string {\n  const stack: State[] = ['ROOT'];\n  let lastValidIndex = -1;\n  let literalStart: number | null = null;\n\n  function processValueStart(char: string, i: number, swapState: State) {\n    {\n      switch (char) {\n        case '\"': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_STRING');\n          break;\n        }\n\n        case 'f':\n        case 't':\n        case 'n': {\n          lastValidIndex = i;\n          literalStart = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_LITERAL');\n          break;\n        }\n\n        case '-': {\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n        case '0':\n        case '1':\n        case '2':\n        case '3':\n        case '4':\n        case '5':\n        case '6':\n        case '7':\n        case '8':\n        case '9': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n\n        case '{': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_OBJECT_START');\n          break;\n        }\n\n        case '[': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_ARRAY_START');\n          break;\n        }\n      }\n    }\n  }\n\n  function processAfterObjectValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_OBJECT_AFTER_COMMA');\n        break;\n      }\n      case '}': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  function processAfterArrayValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_ARRAY_AFTER_COMMA');\n        break;\n      }\n      case ']': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  for (let i = 0; i < input.length; i++) {\n    const char = input[i];\n    const currentState = stack[stack.length - 1];\n\n    switch (currentState) {\n      case 'ROOT':\n        processValueStart(char, i, 'FINISH');\n        break;\n\n      case 'INSIDE_OBJECT_START': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n          case '}': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_COMMA': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_AFTER_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_KEY': {\n        switch (char) {\n          case ':': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_BEFORE_VALUE');\n\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_BEFORE_VALUE': {\n        processValueStart(char, i, 'INSIDE_OBJECT_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        processAfterObjectValue(char, i);\n        break;\n      }\n\n      case 'INSIDE_STRING': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            lastValidIndex = i;\n            break;\n          }\n\n          case '\\\\': {\n            stack.push('INSIDE_STRING_ESCAPE');\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START': {\n        switch (char) {\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        switch (char) {\n          case ',': {\n            stack.pop();\n            stack.push('INSIDE_ARRAY_AFTER_COMMA');\n            break;\n          }\n\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_COMMA': {\n        processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_STRING_ESCAPE': {\n        stack.pop();\n        lastValidIndex = i;\n\n        break;\n      }\n\n      case 'INSIDE_NUMBER': {\n        switch (char) {\n          case '0':\n          case '1':\n          case '2':\n          case '3':\n          case '4':\n          case '5':\n          case '6':\n          case '7':\n          case '8':\n          case '9': {\n            lastValidIndex = i;\n            break;\n          }\n\n          case 'e':\n          case 'E':\n          case '-':\n          case '.': {\n            break;\n          }\n\n          case ',': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case '}': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case ']': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            break;\n          }\n\n          default: {\n            stack.pop();\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, i + 1);\n\n        if (\n          !'false'.startsWith(partialLiteral) &&\n          !'true'.startsWith(partialLiteral) &&\n          !'null'.startsWith(partialLiteral)\n        ) {\n          stack.pop();\n\n          if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n            processAfterObjectValue(char, i);\n          } else if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n            processAfterArrayValue(char, i);\n          }\n        } else {\n          lastValidIndex = i;\n        }\n\n        break;\n      }\n    }\n  }\n\n  let result = input.slice(0, lastValidIndex + 1);\n\n  for (let i = stack.length - 1; i >= 0; i--) {\n    const state = stack[i];\n\n    switch (state) {\n      case 'INSIDE_STRING': {\n        result += '\"';\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY':\n      case 'INSIDE_OBJECT_AFTER_KEY':\n      case 'INSIDE_OBJECT_AFTER_COMMA':\n      case 'INSIDE_OBJECT_START':\n      case 'INSIDE_OBJECT_BEFORE_VALUE':\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        result += '}';\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START':\n      case 'INSIDE_ARRAY_AFTER_COMMA':\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        result += ']';\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, input.length);\n\n        if ('true'.startsWith(partialLiteral)) {\n          result += 'true'.slice(partialLiteral.length);\n        } else if ('false'.startsWith(partialLiteral)) {\n          result += 'false'.slice(partialLiteral.length);\n        } else if ('null'.startsWith(partialLiteral)) {\n          result += 'null'.slice(partialLiteral.length);\n        }\n      }\n    }\n  }\n\n  return result;\n}\n","import { ToolInvocation, ToolInvocationUIPart, UIMessage } from './ui-messages';\n\nexport function getToolInvocations(message: UIMessage): ToolInvocation[] {\n  return message.parts\n    .filter(\n      (part): part is ToolInvocationUIPart => part.type === 'tool-invocation',\n    )\n    .map(part => part.toolInvocation);\n}\n","import { UIMessage } from './ui-messages';\n\nexport function shouldResubmitMessages({\n  originalMaxToolInvocationStep,\n  originalMessageCount,\n  maxSteps,\n  messages,\n}: {\n  originalMaxToolInvocationStep: number | undefined;\n  originalMessageCount: number;\n  maxSteps: number;\n  messages: UIMessage[];\n}) {\n  const lastMessage = messages[messages.length - 1];\n\n  // count the number of step-start parts in the last message:\n  const lastMessageStepStartCount = lastMessage.parts.filter(\n    part => part.type === 'step-start',\n  ).length;\n\n  return (\n    // check if the feature is enabled:\n    maxSteps > 1 &&\n    // ensure there is a last message:\n    lastMessage != null &&\n    // ensure we actually have new steps (to prevent infinite loops in case of errors):\n    (messages.length > originalMessageCount ||\n      lastMessageStepStartCount !== originalMaxToolInvocationStep) &&\n    // check that next step is possible:\n    isAssistantMessageWithCompletedToolCalls(lastMessage) &&\n    // limit the number of automatic steps:\n    lastMessageStepStartCount < maxSteps\n  );\n}\n\n/**\nCheck if the message is an assistant message with completed tool calls.\nThe last step of the message must have at least one tool invocation and\nall tool invocations must have a result.\n */\nexport function isAssistantMessageWithCompletedToolCalls(\n  message: UIMessage | undefined,\n): message is UIMessage & {\n  role: 'assistant';\n} {\n  if (!message) {\n    return false;\n  }\n\n  if (message.role !== 'assistant') {\n    return false;\n  }\n\n  const lastStepStartIndex = message.parts.reduce((lastIndex, part, index) => {\n    return part.type === 'step-start' ? index : lastIndex;\n  }, -1);\n\n  const lastStepToolInvocations = message.parts\n    .slice(lastStepStartIndex + 1)\n    .filter(part => part.type === 'tool-invocation');\n\n  return (\n    lastStepToolInvocations.length > 0 &&\n    lastStepToolInvocations.every(part => 'result' in part.toolInvocation)\n  );\n}\n","import { ToolSet } from '../../core/generate-text/tool-set';\nimport { ToolResultPart } from '../../core/prompt/content-part';\nimport { AssistantContent, ModelMessage } from '../../core/prompt/message';\nimport { MessageConversionError } from '../../core/prompt/message-conversion-error';\nimport {\n  FileUIPart,\n  ReasoningUIPart,\n  TextUIPart,\n  ToolInvocationUIPart,\n  UIMessage,\n} from './ui-messages';\n\n/**\nConverts an array of messages from useChat into an array of CoreMessages that can be used\nwith the AI core functions (e.g. `streamText`).\n */\nexport function convertToModelMessages<TOOLS extends ToolSet = never>(\n  messages: Array<Omit<UIMessage, 'id'>>,\n  options?: { tools?: TOOLS },\n): ModelMessage[] {\n  const tools = options?.tools ?? ({} as TOOLS);\n  const modelMessages: ModelMessage[] = [];\n\n  for (const message of messages) {\n    switch (message.role) {\n      case 'system': {\n        modelMessages.push({\n          role: 'system',\n          content: message.parts\n            .map(part => (part.type === 'text' ? part.text : ''))\n            .join(''),\n        });\n        break;\n      }\n\n      case 'user': {\n        modelMessages.push({\n          role: 'user',\n          content: message.parts\n            .filter(\n              (part): part is TextUIPart | FileUIPart =>\n                part.type === 'text' || part.type === 'file',\n            )\n            .map(part =>\n              part.type === 'file'\n                ? {\n                    type: 'file' as const,\n                    mediaType: part.mediaType,\n                    filename: part.filename,\n                    data: part.url,\n                  }\n                : part,\n            ),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        if (message.parts != null) {\n          let block: Array<\n            TextUIPart | ToolInvocationUIPart | ReasoningUIPart | FileUIPart\n          > = [];\n\n          function processBlock() {\n            if (block.length === 0) {\n              return;\n            }\n\n            const content: AssistantContent = [];\n\n            for (const part of block) {\n              switch (part.type) {\n                case 'text': {\n                  content.push(part);\n                  break;\n                }\n                case 'file': {\n                  content.push({\n                    type: 'file' as const,\n                    mediaType: part.mediaType,\n                    data: part.url,\n                  });\n                  break;\n                }\n                case 'reasoning': {\n                  content.push({\n                    type: 'reasoning' as const,\n                    text: part.text,\n                    providerOptions: part.providerMetadata,\n                  });\n                  break;\n                }\n                case 'tool-invocation':\n                  content.push({\n                    type: 'tool-call' as const,\n                    toolCallId: part.toolInvocation.toolCallId,\n                    toolName: part.toolInvocation.toolName,\n                    args: part.toolInvocation.args,\n                  });\n                  break;\n                default: {\n                  const _exhaustiveCheck: never = part;\n                  throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n                }\n              }\n            }\n\n            modelMessages.push({\n              role: 'assistant',\n              content,\n            });\n\n            // check if there are tool invocations with results in the block\n            const stepInvocations = block\n              .filter(\n                (\n                  part:\n                    | TextUIPart\n                    | ToolInvocationUIPart\n                    | ReasoningUIPart\n                    | FileUIPart,\n                ): part is ToolInvocationUIPart =>\n                  part.type === 'tool-invocation',\n              )\n              .map(part => part.toolInvocation);\n\n            // tool message with tool results\n            if (stepInvocations.length > 0) {\n              modelMessages.push({\n                role: 'tool',\n                content: stepInvocations.map(\n                  (toolInvocation): ToolResultPart => {\n                    if (!('result' in toolInvocation)) {\n                      throw new MessageConversionError({\n                        originalMessage: message,\n                        message:\n                          'ToolInvocation must have a result: ' +\n                          JSON.stringify(toolInvocation),\n                      });\n                    }\n\n                    const { toolCallId, toolName, result } = toolInvocation;\n\n                    const tool = tools[toolName];\n                    return tool?.experimental_toToolResultContent != null\n                      ? {\n                          type: 'tool-result',\n                          toolCallId,\n                          toolName,\n                          result: tool.experimental_toToolResultContent(result),\n                          experimental_content:\n                            tool.experimental_toToolResultContent(result),\n                        }\n                      : {\n                          type: 'tool-result',\n                          toolCallId,\n                          toolName,\n                          result,\n                        };\n                  },\n                ),\n              });\n            }\n\n            // updates for next block\n            block = [];\n          }\n\n          for (const part of message.parts) {\n            switch (part.type) {\n              case 'text':\n              case 'reasoning':\n              case 'file':\n              case 'tool-invocation': {\n                block.push(part);\n                break;\n              }\n              case 'step-start': {\n                processBlock();\n                break;\n              }\n            }\n          }\n\n          processBlock();\n\n          break;\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = message.role;\n        throw new MessageConversionError({\n          originalMessage: message,\n          message: `Unsupported role: ${_exhaustiveCheck}`,\n        });\n      }\n    }\n  }\n\n  return modelMessages;\n}\n\n/**\n@deprecated Use `convertToModelMessages` instead.\n */\n// TODO remove in AI SDK 6\nexport const convertToCoreMessages = convertToModelMessages;\n","import { UIMessageStreamPart } from '../ui-message-stream';\n\nexport function transformTextToUiMessageStream({\n  stream,\n}: {\n  stream: ReadableStream<string>;\n}) {\n  return stream.pipeThrough(\n    new TransformStream<string, UIMessageStreamPart<never, never>>({\n      start(controller) {\n        controller.enqueue({ type: 'start' });\n        controller.enqueue({ type: 'start-step' });\n      },\n\n      async transform(part, controller) {\n        controller.enqueue({ type: 'text', text: part });\n      },\n\n      async flush(controller) {\n        controller.enqueue({ type: 'finish-step' });\n        controller.enqueue({ type: 'finish' });\n      },\n    }),\n  );\n}\n","import { FetchFunction } from '@ai-sdk/provider-utils';\nimport { UIMessageStreamPart } from '../ui-message-stream/ui-message-stream-parts';\nimport { ChatTransport } from './chat-transport';\nimport { PrepareRequest } from './prepare-request';\nimport { transformTextToUiMessageStream } from './transform-text-to-ui-message-stream';\nimport { UIDataTypes } from './ui-messages';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => fetch;\n\nasync function fetchTextStream({\n  api,\n  body,\n  credentials,\n  headers,\n  abortSignal,\n  fetch = getOriginalFetch(),\n  requestType = 'generate',\n}: {\n  api: string;\n  body: Record<string, any>;\n  credentials: RequestCredentials | undefined;\n  headers: HeadersInit | undefined;\n  abortSignal: AbortSignal | undefined;\n  fetch: ReturnType<typeof getOriginalFetch> | undefined;\n  requestType?: 'generate' | 'resume';\n}): Promise<ReadableStream<UIMessageStreamPart<never, never>>> {\n  const response =\n    requestType === 'resume'\n      ? await fetch(`${api}?chatId=${body.chatId}`, {\n          method: 'GET',\n          headers: {\n            'Content-Type': 'application/json',\n            ...headers,\n          },\n          signal: abortSignal,\n          credentials,\n        })\n      : await fetch(api, {\n          method: 'POST',\n          body: JSON.stringify(body),\n          headers: {\n            'Content-Type': 'application/json',\n            ...headers,\n          },\n          signal: abortSignal,\n          credentials,\n        });\n\n  if (!response.ok) {\n    throw new Error(\n      (await response.text()) ?? 'Failed to fetch the chat response.',\n    );\n  }\n\n  if (!response.body) {\n    throw new Error('The response body is empty.');\n  }\n\n  return transformTextToUiMessageStream({\n    stream: response.body.pipeThrough(new TextDecoderStream()),\n  });\n}\n\nexport class TextStreamChatTransport<\n  MESSAGE_METADATA,\n  DATA_TYPES extends UIDataTypes,\n> implements ChatTransport<MESSAGE_METADATA, DATA_TYPES>\n{\n  private api: string;\n  private credentials?: RequestCredentials;\n  private headers?: Record<string, string> | Headers;\n  private body?: object;\n  private fetch?: FetchFunction;\n  private prepareRequest?: PrepareRequest<MESSAGE_METADATA, DATA_TYPES>;\n\n  constructor({\n    api,\n    credentials,\n    headers,\n    body,\n    fetch,\n    prepareRequest,\n  }: {\n    api: string;\n\n    /**\n     * The credentials mode to be used for the fetch request.\n     * Possible values are: 'omit', 'same-origin', 'include'.\n     * Defaults to 'same-origin'.\n     */\n    credentials?: RequestCredentials;\n\n    /**\n     * HTTP headers to be sent with the API request.\n     */\n    headers?: Record<string, string> | Headers;\n\n    /**\n     * Extra body object to be sent with the API request.\n     * @example\n     * Send a `sessionId` to the API along with the messages.\n     * ```js\n     * useChat({\n     *   body: {\n     *     sessionId: '123',\n     *   }\n     * })\n     * ```\n     */\n    body?: object;\n\n    /**\n  Custom fetch implementation. You can use it as a middleware to intercept requests,\n  or to provide a custom fetch implementation for e.g. testing.\n      */\n    fetch?: FetchFunction;\n\n    /**\n     * When a function is provided, it will be used\n     * to prepare the request body for the chat API. This can be useful for\n     * customizing the request body based on the messages and data in the chat.\n     *\n     * @param id The id of the chat.\n     * @param messages The current messages in the chat.\n     * @param requestBody The request body object passed in the chat request.\n     */\n    prepareRequest?: NoInfer<PrepareRequest<MESSAGE_METADATA, DATA_TYPES>>;\n  }) {\n    this.api = api;\n    this.credentials = credentials;\n    this.headers = headers;\n    this.body = body;\n    this.fetch = fetch;\n    this.prepareRequest = prepareRequest;\n  }\n\n  submitMessages({\n    chatId,\n    messages,\n    abortSignal,\n    metadata,\n    headers,\n    body,\n    requestType,\n  }: Parameters<\n    ChatTransport<MESSAGE_METADATA, DATA_TYPES>['submitMessages']\n  >[0]) {\n    const preparedRequest = this.prepareRequest?.({\n      id: chatId,\n      messages,\n      body: { ...this.body, ...body },\n      headers: { ...this.headers, ...headers },\n      credentials: this.credentials,\n      requestMetadata: metadata,\n    });\n\n    return fetchTextStream({\n      api: this.api,\n\n      body:\n        preparedRequest?.body !== undefined\n          ? preparedRequest.body\n          : { ...this.body, ...body },\n      headers:\n        preparedRequest?.headers !== undefined\n          ? preparedRequest.headers\n          : { ...this.headers, ...headers },\n      credentials: preparedRequest?.credentials ?? this.credentials,\n      abortSignal,\n      fetch: this.fetch,\n      requestType,\n    });\n  }\n}\n","import {\n  createStreamingUIMessageState,\n  processUIMessageStream,\n  StreamingUIMessageState,\n} from '../ui/process-ui-message-stream';\nimport {\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  UIMessage,\n} from '../ui/ui-messages';\nimport { UIMessageStreamPart } from './ui-message-stream-parts';\n\nexport function handleUIMessageStreamFinish<UI_MESSAGE extends UIMessage>({\n  newMessageId,\n  originalMessages = [],\n  onFinish,\n  stream,\n}: {\n  stream: ReadableStream<UIMessageStreamPart>;\n\n  newMessageId: string;\n\n  /**\n   * The original messages.\n   */\n  originalMessages?: UIMessage[];\n\n  onFinish?: (options: {\n    /**\n     * The updates list of UI messages.\n     */\n    messages: UI_MESSAGE[];\n\n    /**\n     * Indicates whether the response message is a continuation of the last original message,\n     * or if a new message was created.\n     */\n    isContinuation: boolean;\n\n    /**\n     * The message that was sent to the client as a response\n     * (including the original message if it was extended).\n     */\n    responseMessage: UI_MESSAGE;\n  }) => void;\n}) {\n  if (onFinish == null) {\n    return stream;\n  }\n\n  const lastMessage = originalMessages[originalMessages.length - 1];\n  const isContinuation = lastMessage?.role === 'assistant';\n  const messageId = isContinuation ? lastMessage.id : newMessageId;\n\n  const state = createStreamingUIMessageState<\n    InferUIMessageMetadata<UI_MESSAGE>,\n    InferUIMessageData<UI_MESSAGE>\n  >({\n    lastMessage: structuredClone(lastMessage) as any,\n    newMessageId: messageId,\n  });\n\n  const runUpdateMessageJob = async (\n    job: (options: {\n      state: StreamingUIMessageState<\n        UIMessage<\n          InferUIMessageMetadata<UI_MESSAGE>,\n          InferUIMessageData<UI_MESSAGE>\n        >\n      >;\n      write: () => void;\n    }) => Promise<void>,\n  ) => {\n    await job({ state, write: () => {} });\n  };\n\n  return processUIMessageStream<UI_MESSAGE>({\n    stream,\n    runUpdateMessageJob,\n  }).pipeThrough(\n    new TransformStream({\n      transform(chunk, controller) {\n        controller.enqueue(chunk);\n      },\n\n      flush() {\n        const isContinuation = state.message.id === lastMessage?.id;\n        onFinish({\n          isContinuation,\n          responseMessage: state.message as UI_MESSAGE,\n          messages: [\n            ...(isContinuation\n              ? originalMessages.slice(0, -1)\n              : originalMessages),\n            state.message,\n          ] as UI_MESSAGE[],\n        });\n      },\n    }),\n  );\n}\n","import { UIMessage } from '../ui/ui-messages';\nimport { handleUIMessageStreamFinish } from './handle-ui-message-stream-finish';\nimport { InferUIMessageStreamPart } from './ui-message-stream-parts';\nimport { UIMessageStreamWriter } from './ui-message-stream-writer';\n\nexport function createUIMessageStream<UI_MESSAGE extends UIMessage>({\n  execute,\n  onError = () => 'An error occurred.', // mask error messages for safety by default\n  originalMessages,\n  onFinish,\n}: {\n  execute: (options: {\n    writer: UIMessageStreamWriter<UI_MESSAGE>;\n  }) => Promise<void> | void;\n  onError?: (error: unknown) => string;\n\n  /**\n   * The original messages.\n   */\n  originalMessages?: UI_MESSAGE[];\n\n  onFinish?: (options: {\n    /**\n     * The updates list of UI messages.\n     */\n    messages: UI_MESSAGE[];\n\n    /**\n     * Indicates whether the response message is a continuation of the last original message,\n     * or if a new message was created.\n     */\n    isContinuation: boolean;\n\n    /**\n     * The message that was sent to the client as a response\n     * (including the original message if it was extended).\n     */\n    responseMessage: UI_MESSAGE;\n  }) => void;\n}): ReadableStream<InferUIMessageStreamPart<UI_MESSAGE>> {\n  let controller!: ReadableStreamDefaultController<\n    InferUIMessageStreamPart<UI_MESSAGE>\n  >;\n\n  const ongoingStreamPromises: Promise<void>[] = [];\n\n  const stream = new ReadableStream({\n    start(controllerArg) {\n      controller = controllerArg;\n    },\n  });\n\n  function safeEnqueue(data: InferUIMessageStreamPart<UI_MESSAGE>) {\n    try {\n      controller.enqueue(data);\n    } catch (error) {\n      // suppress errors when the stream has been closed\n    }\n  }\n\n  try {\n    const result = execute({\n      writer: {\n        write(part: InferUIMessageStreamPart<UI_MESSAGE>) {\n          safeEnqueue(part);\n        },\n        merge(streamArg) {\n          ongoingStreamPromises.push(\n            (async () => {\n              const reader = streamArg.getReader();\n              while (true) {\n                const { done, value } = await reader.read();\n                if (done) break;\n                safeEnqueue(value);\n              }\n            })().catch(error => {\n              safeEnqueue({\n                type: 'error',\n                errorText: onError(error),\n              } as InferUIMessageStreamPart<UI_MESSAGE>);\n            }),\n          );\n        },\n        onError,\n      },\n    });\n\n    if (result) {\n      ongoingStreamPromises.push(\n        result.catch(error => {\n          safeEnqueue({\n            type: 'error',\n            errorText: onError(error),\n          } as InferUIMessageStreamPart<UI_MESSAGE>);\n        }),\n      );\n    }\n  } catch (error) {\n    safeEnqueue({\n      type: 'error',\n      errorText: onError(error),\n    } as InferUIMessageStreamPart<UI_MESSAGE>);\n  }\n\n  // Wait until all ongoing streams are done. This approach enables merging\n  // streams even after execute has returned, as long as there is still an\n  // open merged stream. This is important to e.g. forward new streams and\n  // from callbacks.\n  const waitForStreams: Promise<void> = new Promise(async resolve => {\n    while (ongoingStreamPromises.length > 0) {\n      await ongoingStreamPromises.shift();\n    }\n    resolve();\n  });\n\n  waitForStreams.finally(() => {\n    try {\n      controller.close();\n    } catch (error) {\n      // suppress errors when the stream has been closed\n    }\n  });\n\n  return handleUIMessageStreamFinish({\n    stream,\n    newMessageId: '',\n    originalMessages,\n    onFinish,\n  });\n}\n","export class JsonToSseTransformStream extends TransformStream<unknown, string> {\n  constructor() {\n    super({\n      transform(part, controller) {\n        controller.enqueue(`data: ${JSON.stringify(part)}\\n\\n`);\n      },\n      flush(controller) {\n        controller.enqueue('data: [DONE]\\n\\n');\n      },\n    });\n  }\n}\n","export const uiMessageStreamHeaders = {\n  'content-type': 'text/event-stream',\n  'cache-control': 'no-cache',\n  connection: 'keep-alive',\n  'x-vercel-ai-ui-message-stream': 'v1',\n  'x-accel-buffering': 'no', // disable nginx buffering\n};\n","import { prepareHeaders } from '../util/prepare-headers';\nimport { JsonToSseTransformStream } from './json-to-sse-transform-stream';\nimport { uiMessageStreamHeaders } from './ui-message-stream-headers';\nimport { UIMessageStreamPart } from './ui-message-stream-parts';\n\nexport function createUIMessageStreamResponse({\n  status,\n  statusText,\n  headers,\n  stream,\n}: ResponseInit & {\n  stream: ReadableStream<UIMessageStreamPart>;\n}): Response {\n  return new Response(\n    stream\n      .pipeThrough(new JsonToSseTransformStream())\n      .pipeThrough(new TextEncoderStream()),\n    {\n      status,\n      statusText,\n      headers: prepareHeaders(headers, uiMessageStreamHeaders),\n    },\n  );\n}\n","import { ServerResponse } from 'node:http';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { writeToServerResponse } from '../util/write-to-server-response';\nimport { JsonToSseTransformStream } from './json-to-sse-transform-stream';\nimport { uiMessageStreamHeaders } from './ui-message-stream-headers';\nimport { UIMessageStreamPart } from './ui-message-stream-parts';\n\nexport function pipeUIMessageStreamToResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  stream,\n}: {\n  response: ServerResponse;\n  stream: ReadableStream<UIMessageStreamPart>;\n} & ResponseInit): void {\n  writeToServerResponse({\n    response,\n    status,\n    statusText,\n    headers: Object.fromEntries(\n      prepareHeaders(headers, uiMessageStreamHeaders).entries(),\n    ),\n    stream: stream\n      .pipeThrough(new JsonToSseTransformStream())\n      .pipeThrough(new TextEncoderStream()),\n  });\n}\n","import { InvalidArgumentError } from '../../src/error/invalid-argument-error';\n\n/**\n * Calculates the cosine similarity between two vectors. This is a useful metric for\n * comparing the similarity of two vectors such as embeddings.\n *\n * @param vector1 - The first vector.\n * @param vector2 - The second vector.\n *\n * @returns The cosine similarity between vector1 and vector2.\n * @returns 0 if either vector is the zero vector.\n *\n * @throws {InvalidArgumentError} If the vectors do not have the same length.\n */\nexport function cosineSimilarity(vector1: number[], vector2: number[]): number {\n  if (vector1.length !== vector2.length) {\n    throw new InvalidArgumentError({\n      parameter: 'vector1,vector2',\n      value: { vector1Length: vector1.length, vector2Length: vector2.length },\n      message: `Vectors must have the same length`,\n    });\n  }\n\n  const n = vector1.length;\n\n  if (n === 0) {\n    return 0; // Return 0 for empty vectors if no error is thrown\n  }\n\n  let magnitudeSquared1 = 0;\n  let magnitudeSquared2 = 0;\n  let dotProduct = 0;\n\n  for (let i = 0; i < n; i++) {\n    const value1 = vector1[i];\n    const value2 = vector2[i];\n\n    magnitudeSquared1 += value1 * value1;\n    magnitudeSquared2 += value2 * value2;\n    dotProduct += value1 * value2;\n  }\n\n  return magnitudeSquared1 === 0 || magnitudeSquared2 === 0\n    ? 0\n    : dotProduct /\n        (Math.sqrt(magnitudeSquared1) * Math.sqrt(magnitudeSquared2));\n}\n","/**\n * Converts a data URL of type text/* to a text string.\n */\nexport function getTextFromDataUrl(dataUrl: string): string {\n  const [header, base64Content] = dataUrl.split(',');\n  const mediaType = header.split(';')[0].split(':')[1];\n\n  if (mediaType == null || base64Content == null) {\n    throw new Error('Invalid data URL format');\n  }\n\n  try {\n    return window.atob(base64Content);\n  } catch (error) {\n    throw new Error(`Error decoding data URL`);\n  }\n}\n","/**\n * Performs a deep-equal comparison of two parsed JSON objects.\n *\n * @param {any} obj1 - The first object to compare.\n * @param {any} obj2 - The second object to compare.\n * @returns {boolean} - Returns true if the two objects are deeply equal, false otherwise.\n */\nexport function isDeepEqualData(obj1: any, obj2: any): boolean {\n  // Check for strict equality first\n  if (obj1 === obj2) return true;\n\n  // Check if either is null or undefined\n  if (obj1 == null || obj2 == null) return false;\n\n  // Check if both are objects\n  if (typeof obj1 !== 'object' && typeof obj2 !== 'object')\n    return obj1 === obj2;\n\n  // If they are not strictly equal, they both need to be Objects\n  if (obj1.constructor !== obj2.constructor) return false;\n\n  // Special handling for Date objects\n  if (obj1 instanceof Date && obj2 instanceof Date) {\n    return obj1.getTime() === obj2.getTime();\n  }\n\n  // Handle arrays: compare length and then perform a recursive deep comparison on each item\n  if (Array.isArray(obj1)) {\n    if (obj1.length !== obj2.length) return false;\n    for (let i = 0; i < obj1.length; i++) {\n      if (!isDeepEqualData(obj1[i], obj2[i])) return false;\n    }\n    return true; // All array elements matched\n  }\n\n  // Compare the set of keys in each object\n  const keys1 = Object.keys(obj1);\n  const keys2 = Object.keys(obj2);\n  if (keys1.length !== keys2.length) return false;\n\n  // Check each key-value pair recursively\n  for (const key of keys1) {\n    if (!keys2.includes(key)) return false;\n    if (!isDeepEqualData(obj1[key], obj2[key])) return false;\n  }\n\n  return true; // All keys and values matched\n}\n","import { delay as delayFunction } from '@ai-sdk/provider-utils';\n\n/**\n * Creates a ReadableStream that emits the provided values with an optional delay between each value.\n *\n * @param options - The configuration options\n * @param options.chunks - Array of values to be emitted by the stream\n * @param options.initialDelayInMs - Optional initial delay in milliseconds before emitting the first value (default: 0). Can be set to `null` to skip the initial delay. The difference between `initialDelayInMs: null` and `initialDelayInMs: 0` is that `initialDelayInMs: null` will emit the values without any delay, while `initialDelayInMs: 0` will emit the values with a delay of 0 milliseconds.\n * @param options.chunkDelayInMs - Optional delay in milliseconds between emitting each value (default: 0). Can be set to `null` to skip the delay. The difference between `chunkDelayInMs: null` and `chunkDelayInMs: 0` is that `chunkDelayInMs: null` will emit the values without any delay, while `chunkDelayInMs: 0` will emit the values with a delay of 0 milliseconds.\n * @returns A ReadableStream that emits the provided values\n */\nexport function simulateReadableStream<T>({\n  chunks,\n  initialDelayInMs = 0,\n  chunkDelayInMs = 0,\n  _internal,\n}: {\n  chunks: T[];\n  initialDelayInMs?: number | null;\n  chunkDelayInMs?: number | null;\n  _internal?: {\n    delay?: (ms: number | null) => Promise<void>;\n  };\n}): ReadableStream<T> {\n  const delay = _internal?.delay ?? delayFunction;\n\n  let index = 0;\n\n  return new ReadableStream({\n    async pull(controller) {\n      if (index < chunks.length) {\n        await delay(index === 0 ? initialDelayInMs : chunkDelayInMs);\n        controller.enqueue(chunks[index++]);\n      } else {\n        controller.close();\n      }\n    },\n  });\n}\n","import { APICallError } from '@ai-sdk/provider';\nimport { delay, getErrorMessage, isAbortError } from '@ai-sdk/provider-utils';\nimport { RetryError } from './retry-error';\n\nexport type RetryFunction = <OUTPUT>(\n  fn: () => PromiseLike<OUTPUT>,\n) => PromiseLike<OUTPUT>;\n\n/**\nThe `retryWithExponentialBackoff` strategy retries a failed API call with an exponential backoff.\nYou can configure the maximum number of retries, the initial delay, and the backoff factor.\n */\nexport const retryWithExponentialBackoff =\n  ({\n    maxRetries = 2,\n    initialDelayInMs = 2000,\n    backoffFactor = 2,\n  } = {}): RetryFunction =>\n  async <OUTPUT>(f: () => PromiseLike<OUTPUT>) =>\n    _retryWithExponentialBackoff(f, {\n      maxRetries,\n      delayInMs: initialDelayInMs,\n      backoffFactor,\n    });\n\nasync function _retryWithExponentialBackoff<OUTPUT>(\n  f: () => PromiseLike<OUTPUT>,\n  {\n    maxRetries,\n    delayInMs,\n    backoffFactor,\n  }: { maxRetries: number; delayInMs: number; backoffFactor: number },\n  errors: unknown[] = [],\n): Promise<OUTPUT> {\n  try {\n    return await f();\n  } catch (error) {\n    if (isAbortError(error)) {\n      throw error; // don't retry when the request was aborted\n    }\n\n    if (maxRetries === 0) {\n      throw error; // don't wrap the error when retries are disabled\n    }\n\n    const errorMessage = getErrorMessage(error);\n    const newErrors = [...errors, error];\n    const tryNumber = newErrors.length;\n\n    if (tryNumber > maxRetries) {\n      throw new RetryError({\n        message: `Failed after ${tryNumber} attempts. Last error: ${errorMessage}`,\n        reason: 'maxRetriesExceeded',\n        errors: newErrors,\n      });\n    }\n\n    if (\n      error instanceof Error &&\n      APICallError.isInstance(error) &&\n      error.isRetryable === true &&\n      tryNumber <= maxRetries\n    ) {\n      await delay(delayInMs);\n      return _retryWithExponentialBackoff(\n        f,\n        { maxRetries, delayInMs: backoffFactor * delayInMs, backoffFactor },\n        newErrors,\n      );\n    }\n\n    if (tryNumber === 1) {\n      throw error; // don't wrap the error when a non-retryable error occurs on the first try\n    }\n\n    throw new RetryError({\n      message: `Failed after ${tryNumber} attempts with non-retryable error: '${errorMessage}'`,\n      reason: 'errorNotRetryable',\n      errors: newErrors,\n    });\n  }\n}\n","import { InvalidArgumentError } from '../../src/error/invalid-argument-error';\nimport {\n  RetryFunction,\n  retryWithExponentialBackoff,\n} from '../../src/util/retry-with-exponential-backoff';\n\n/**\n * Validate and prepare retries.\n */\nexport function prepareRetries({\n  maxRetries,\n}: {\n  maxRetries: number | undefined;\n}): {\n  maxRetries: number;\n  retry: RetryFunction;\n} {\n  if (maxRetries != null) {\n    if (!Number.isInteger(maxRetries)) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be an integer',\n      });\n    }\n\n    if (maxRetries < 0) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be >= 0',\n      });\n    }\n  }\n\n  const maxRetriesResult = maxRetries ?? 2;\n\n  return {\n    maxRetries: maxRetriesResult,\n    retry: retryWithExponentialBackoff({ maxRetries: maxRetriesResult }),\n  };\n}\n","import { TelemetrySettings } from './telemetry-settings';\n\nexport function assembleOperationName({\n  operationId,\n  telemetry,\n}: {\n  operationId: string;\n  telemetry?: TelemetrySettings;\n}) {\n  return {\n    // standardized operation and resource name:\n    'operation.name': `${operationId}${\n      telemetry?.functionId != null ? ` ${telemetry.functionId}` : ''\n    }`,\n    'resource.name': telemetry?.functionId,\n\n    // detailed, AI SDK specific data:\n    'ai.operationId': operationId,\n    'ai.telemetry.functionId': telemetry?.functionId,\n  };\n}\n","import { Attributes } from '@opentelemetry/api';\nimport { CallSettings } from '../prompt/call-settings';\nimport { TelemetrySettings } from './telemetry-settings';\n\nexport function getBaseTelemetryAttributes({\n  model,\n  settings,\n  telemetry,\n  headers,\n}: {\n  model: { modelId: string; provider: string };\n  settings: Omit<CallSettings, 'abortSignal' | 'headers' | 'temperature'>;\n  telemetry: TelemetrySettings | undefined;\n  headers: Record<string, string | undefined> | undefined;\n}): Attributes {\n  return {\n    'ai.model.provider': model.provider,\n    'ai.model.id': model.modelId,\n\n    // settings:\n    ...Object.entries(settings).reduce((attributes, [key, value]) => {\n      attributes[`ai.settings.${key}`] = value;\n      return attributes;\n    }, {} as Attributes),\n\n    // add metadata as attributes:\n    ...Object.entries(telemetry?.metadata ?? {}).reduce(\n      (attributes, [key, value]) => {\n        attributes[`ai.telemetry.metadata.${key}`] = value;\n        return attributes;\n      },\n      {} as Attributes,\n    ),\n\n    // request headers\n    ...Object.entries(headers ?? {}).reduce((attributes, [key, value]) => {\n      if (value !== undefined) {\n        attributes[`ai.request.headers.${key}`] = value;\n      }\n      return attributes;\n    }, {} as Attributes),\n  };\n}\n","import { Tracer, trace } from '@opentelemetry/api';\nimport { noopTracer } from './noop-tracer';\n\nexport function getTracer({\n  isEnabled = false,\n  tracer,\n}: {\n  isEnabled?: boolean;\n  tracer?: Tracer;\n} = {}): Tracer {\n  if (!isEnabled) {\n    return noopTracer;\n  }\n\n  if (tracer) {\n    return tracer;\n  }\n\n  return trace.getTracer('ai');\n}\n","import { Span, SpanContext, Tracer } from '@opentelemetry/api';\n\n/**\n * Tracer implementation that does nothing (null object).\n */\nexport const noopTracer: Tracer = {\n  startSpan(): Span {\n    return noopSpan;\n  },\n\n  startActiveSpan<F extends (span: Span) => unknown>(\n    name: unknown,\n    arg1: unknown,\n    arg2?: unknown,\n    arg3?: F,\n  ): ReturnType<any> {\n    if (typeof arg1 === 'function') {\n      return arg1(noopSpan);\n    }\n    if (typeof arg2 === 'function') {\n      return arg2(noopSpan);\n    }\n    if (typeof arg3 === 'function') {\n      return arg3(noopSpan);\n    }\n  },\n};\n\nconst noopSpan: Span = {\n  spanContext() {\n    return noopSpanContext;\n  },\n  setAttribute() {\n    return this;\n  },\n  setAttributes() {\n    return this;\n  },\n  addEvent() {\n    return this;\n  },\n  addLink() {\n    return this;\n  },\n  addLinks() {\n    return this;\n  },\n  setStatus() {\n    return this;\n  },\n  updateName() {\n    return this;\n  },\n  end() {\n    return this;\n  },\n  isRecording() {\n    return false;\n  },\n  recordException() {\n    return this;\n  },\n};\n\nconst noopSpanContext: SpanContext = {\n  traceId: '',\n  spanId: '',\n  traceFlags: 0,\n};\n","import { Attributes, Span, Tracer, SpanStatusCode } from '@opentelemetry/api';\n\nexport function recordSpan<T>({\n  name,\n  tracer,\n  attributes,\n  fn,\n  endWhenDone = true,\n}: {\n  name: string;\n  tracer: Tracer;\n  attributes: Attributes;\n  fn: (span: Span) => Promise<T>;\n  endWhenDone?: boolean;\n}) {\n  return tracer.startActiveSpan(name, { attributes }, async span => {\n    try {\n      const result = await fn(span);\n\n      if (endWhenDone) {\n        span.end();\n      }\n\n      return result;\n    } catch (error) {\n      try {\n        if (error instanceof Error) {\n          span.recordException({\n            name: error.name,\n            message: error.message,\n            stack: error.stack,\n          });\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: error.message,\n          });\n        } else {\n          span.setStatus({ code: SpanStatusCode.ERROR });\n        }\n      } finally {\n        // always stop the span when there is an error:\n        span.end();\n      }\n\n      throw error;\n    }\n  });\n}\n","import type { Attributes, AttributeValue } from '@opentelemetry/api';\nimport type { TelemetrySettings } from './telemetry-settings';\n\nexport function selectTelemetryAttributes({\n  telemetry,\n  attributes,\n}: {\n  telemetry?: TelemetrySettings;\n  attributes: {\n    [attributeKey: string]:\n      | AttributeValue\n      | { input: () => AttributeValue | undefined }\n      | { output: () => AttributeValue | undefined }\n      | undefined;\n  };\n}): Attributes {\n  // when telemetry is disabled, return an empty object to avoid serialization overhead:\n  if (telemetry?.isEnabled !== true) {\n    return {};\n  }\n\n  return Object.entries(attributes).reduce((attributes, [key, value]) => {\n    if (value === undefined) {\n      return attributes;\n    }\n\n    // input value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'input' in value &&\n      typeof value.input === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordInputs === false) {\n        return attributes;\n      }\n\n      const result = value.input();\n\n      return result === undefined\n        ? attributes\n        : { ...attributes, [key]: result };\n    }\n\n    // output value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'output' in value &&\n      typeof value.output === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordOutputs === false) {\n        return attributes;\n      }\n\n      const result = value.output();\n\n      return result === undefined\n        ? attributes\n        : { ...attributes, [key]: result };\n    }\n\n    // value is an attribute value already:\n    return { ...attributes, [key]: value };\n  }, {});\n}\n","import { prepareRetries } from '../../src/util/prepare-retries';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { EmbeddingModel, ProviderOptions } from '../types';\nimport { EmbedResult } from './embed-result';\n\n/**\nEmbed a value using an embedding model. The type of the value is defined by the embedding model.\n\n@param model - The embedding model to use.\n@param value - The value that should be embedded.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the embedding, the value, and additional information.\n */\nexport async function embed<VALUE>({\n  model,\n  value,\n  providerOptions,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  experimental_telemetry: telemetry,\n}: {\n  /**\nThe embedding model to use.\n     */\n  model: EmbeddingModel<VALUE>;\n\n  /**\nThe value that should be embedded.\n   */\n  value: VALUE;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n\n  /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n  */\n  providerOptions?: ProviderOptions;\n\n  /**\n   * Optional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n}): Promise<EmbedResult<VALUE>> {\n  const { maxRetries, retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers,\n    settings: { maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  return recordSpan({\n    name: 'ai.embed',\n    attributes: selectTelemetryAttributes({\n      telemetry,\n      attributes: {\n        ...assembleOperationName({ operationId: 'ai.embed', telemetry }),\n        ...baseTelemetryAttributes,\n        'ai.value': { input: () => JSON.stringify(value) },\n      },\n    }),\n    tracer,\n    fn: async span => {\n      const { embedding, usage, response } = await retry(() =>\n        // nested spans to align with the embedMany telemetry data:\n        recordSpan({\n          name: 'ai.embed.doEmbed',\n          attributes: selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              ...assembleOperationName({\n                operationId: 'ai.embed.doEmbed',\n                telemetry,\n              }),\n              ...baseTelemetryAttributes,\n              // specific settings that only make sense on the outer level:\n              'ai.values': { input: () => [JSON.stringify(value)] },\n            },\n          }),\n          tracer,\n          fn: async doEmbedSpan => {\n            const modelResponse = await model.doEmbed({\n              values: [value],\n              abortSignal,\n              headers,\n              providerOptions,\n            });\n\n            const embedding = modelResponse.embeddings[0];\n            const usage = modelResponse.usage ?? { tokens: NaN };\n\n            doEmbedSpan.setAttributes(\n              selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  'ai.embeddings': {\n                    output: () =>\n                      modelResponse.embeddings.map(embedding =>\n                        JSON.stringify(embedding),\n                      ),\n                  },\n                  'ai.usage.tokens': usage.tokens,\n                },\n              }),\n            );\n\n            return {\n              embedding,\n              usage,\n              response: modelResponse.response,\n            };\n          },\n        }),\n      );\n\n      span.setAttributes(\n        selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            'ai.embedding': { output: () => JSON.stringify(embedding) },\n            'ai.usage.tokens': usage.tokens,\n          },\n        }),\n      );\n\n      return new DefaultEmbedResult({\n        value,\n        embedding,\n        usage,\n        response,\n      });\n    },\n  });\n}\n\nclass DefaultEmbedResult<VALUE> implements EmbedResult<VALUE> {\n  readonly value: EmbedResult<VALUE>['value'];\n  readonly embedding: EmbedResult<VALUE>['embedding'];\n  readonly usage: EmbedResult<VALUE>['usage'];\n  readonly response: EmbedResult<VALUE>['response'];\n\n  constructor(options: {\n    value: EmbedResult<VALUE>['value'];\n    embedding: EmbedResult<VALUE>['embedding'];\n    usage: EmbedResult<VALUE>['usage'];\n    response?: EmbedResult<VALUE>['response'];\n  }) {\n    this.value = options.value;\n    this.embedding = options.embedding;\n    this.usage = options.usage;\n    this.response = options.response;\n  }\n}\n","/**\n * Splits an array into chunks of a specified size.\n *\n * @template T - The type of elements in the array.\n * @param {T[]} array - The array to split.\n * @param {number} chunkSize - The size of each chunk.\n * @returns {T[][]} - A new array containing the chunks.\n */\nexport function splitArray<T>(array: T[], chunkSize: number): T[][] {\n  if (chunkSize <= 0) {\n    throw new Error('chunkSize must be greater than 0');\n  }\n\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n\n  return result;\n}\n","import { prepareRetries } from '../../src/util/prepare-retries';\nimport { splitArray } from '../../src/util/split-array';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { Embedding, EmbeddingModel, ProviderOptions } from '../types';\nimport { EmbedManyResult } from './embed-many-result';\n\n/**\nEmbed several values using an embedding model. The type of the value is defined\nby the embedding model.\n\n`embedMany` automatically splits large requests into smaller chunks if the model\nhas a limit on how many embeddings can be generated in a single call.\n\n@param model - The embedding model to use.\n@param values - The values that should be embedded.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the embeddings, the value, and additional information.\n */\nexport async function embedMany<VALUE>({\n  model,\n  values,\n  maxParallelCalls = Infinity,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  providerOptions,\n  experimental_telemetry: telemetry,\n}: {\n  /**\nThe embedding model to use.\n     */\n  model: EmbeddingModel<VALUE>;\n\n  /**\nThe values that should be embedded.\n   */\n  values: Array<VALUE>;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n\n  /**\n   * Optional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n\n  /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n  */\n  providerOptions?: ProviderOptions;\n\n  /**\n   * Maximum number of concurrent requests.\n   *\n   * @default Infinity\n   */\n  maxParallelCalls?: number;\n}): Promise<EmbedManyResult<VALUE>> {\n  const { maxRetries, retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers,\n    settings: { maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  return recordSpan({\n    name: 'ai.embedMany',\n    attributes: selectTelemetryAttributes({\n      telemetry,\n      attributes: {\n        ...assembleOperationName({ operationId: 'ai.embedMany', telemetry }),\n        ...baseTelemetryAttributes,\n        // specific settings that only make sense on the outer level:\n        'ai.values': {\n          input: () => values.map(value => JSON.stringify(value)),\n        },\n      },\n    }),\n    tracer,\n    fn: async span => {\n      const [maxEmbeddingsPerCall, supportsParallelCalls] = await Promise.all([\n        model.maxEmbeddingsPerCall,\n        model.supportsParallelCalls,\n      ]);\n\n      // the model has not specified limits on\n      // how many embeddings can be generated in a single call\n      if (maxEmbeddingsPerCall == null || maxEmbeddingsPerCall === Infinity) {\n        const { embeddings, usage, response } = await retry(() => {\n          // nested spans to align with the embedMany telemetry data:\n          return recordSpan({\n            name: 'ai.embedMany.doEmbed',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.embedMany.doEmbed',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                // specific settings that only make sense on the outer level:\n                'ai.values': {\n                  input: () => values.map(value => JSON.stringify(value)),\n                },\n              },\n            }),\n            tracer,\n            fn: async doEmbedSpan => {\n              const modelResponse = await model.doEmbed({\n                values,\n                abortSignal,\n                headers,\n                providerOptions,\n              });\n\n              const embeddings = modelResponse.embeddings;\n              const usage = modelResponse.usage ?? { tokens: NaN };\n\n              doEmbedSpan.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.embeddings': {\n                      output: () =>\n                        embeddings.map(embedding => JSON.stringify(embedding)),\n                    },\n                    'ai.usage.tokens': usage.tokens,\n                  },\n                }),\n              );\n\n              return {\n                embeddings,\n                usage,\n                response: modelResponse.response,\n              };\n            },\n          });\n        });\n\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.embeddings': {\n                output: () =>\n                  embeddings.map(embedding => JSON.stringify(embedding)),\n              },\n              'ai.usage.tokens': usage.tokens,\n            },\n          }),\n        );\n\n        return new DefaultEmbedManyResult({\n          values,\n          embeddings,\n          usage,\n          responses: [response],\n        });\n      }\n\n      // split the values into chunks that are small enough for the model:\n      const valueChunks = splitArray(values, maxEmbeddingsPerCall);\n\n      // serially embed the chunks:\n      const embeddings: Array<Embedding> = [];\n      const responses: Array<\n        | {\n            headers?: Record<string, string>;\n            body?: unknown;\n          }\n        | undefined\n      > = [];\n      let tokens = 0;\n\n      const parallelChunks = splitArray(\n        valueChunks,\n        supportsParallelCalls ? maxParallelCalls : 1,\n      );\n\n      for (const parallelChunk of parallelChunks) {\n        const results = await Promise.all(\n          parallelChunk.map(chunk => {\n            return retry(() => {\n              // nested spans to align with the embedMany telemetry data:\n              return recordSpan({\n                name: 'ai.embedMany.doEmbed',\n                attributes: selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    ...assembleOperationName({\n                      operationId: 'ai.embedMany.doEmbed',\n                      telemetry,\n                    }),\n                    ...baseTelemetryAttributes,\n                    // specific settings that only make sense on the outer level:\n                    'ai.values': {\n                      input: () => chunk.map(value => JSON.stringify(value)),\n                    },\n                  },\n                }),\n                tracer,\n                fn: async doEmbedSpan => {\n                  const modelResponse = await model.doEmbed({\n                    values: chunk,\n                    abortSignal,\n                    headers,\n                    providerOptions,\n                  });\n\n                  const embeddings = modelResponse.embeddings;\n                  const usage = modelResponse.usage ?? { tokens: NaN };\n\n                  doEmbedSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.embeddings': {\n                          output: () =>\n                            embeddings.map(embedding =>\n                              JSON.stringify(embedding),\n                            ),\n                        },\n                        'ai.usage.tokens': usage.tokens,\n                      },\n                    }),\n                  );\n\n                  return {\n                    embeddings,\n                    usage,\n                    response: modelResponse.response,\n                  };\n                },\n              });\n            });\n          }),\n        );\n\n        for (const result of results) {\n          embeddings.push(...result.embeddings);\n          responses.push(result.response);\n          tokens += result.usage.tokens;\n        }\n      }\n\n      span.setAttributes(\n        selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            'ai.embeddings': {\n              output: () =>\n                embeddings.map(embedding => JSON.stringify(embedding)),\n            },\n            'ai.usage.tokens': tokens,\n          },\n        }),\n      );\n\n      return new DefaultEmbedManyResult({\n        values,\n        embeddings,\n        usage: { tokens },\n        responses,\n      });\n    },\n  });\n}\n\nclass DefaultEmbedManyResult<VALUE> implements EmbedManyResult<VALUE> {\n  readonly values: EmbedManyResult<VALUE>['values'];\n  readonly embeddings: EmbedManyResult<VALUE>['embeddings'];\n  readonly usage: EmbedManyResult<VALUE>['usage'];\n  readonly responses: EmbedManyResult<VALUE>['responses'];\n\n  constructor(options: {\n    values: EmbedManyResult<VALUE>['values'];\n    embeddings: EmbedManyResult<VALUE>['embeddings'];\n    usage: EmbedManyResult<VALUE>['usage'];\n    responses?: EmbedManyResult<VALUE>['responses'];\n  }) {\n    this.values = options.values;\n    this.embeddings = options.embeddings;\n    this.usage = options.usage;\n    this.responses = options.responses;\n  }\n}\n","import { convertBase64ToUint8Array } from '@ai-sdk/provider-utils';\n\nexport const imageMediaTypeSignatures = [\n  {\n    mediaType: 'image/gif' as const,\n    bytesPrefix: [0x47, 0x49, 0x46],\n    base64Prefix: 'R0lG',\n  },\n  {\n    mediaType: 'image/png' as const,\n    bytesPrefix: [0x89, 0x50, 0x4e, 0x47],\n    base64Prefix: 'iVBORw',\n  },\n  {\n    mediaType: 'image/jpeg' as const,\n    bytesPrefix: [0xff, 0xd8],\n    base64Prefix: '/9j/',\n  },\n  {\n    mediaType: 'image/webp' as const,\n    bytesPrefix: [0x52, 0x49, 0x46, 0x46],\n    base64Prefix: 'UklGRg',\n  },\n  {\n    mediaType: 'image/bmp' as const,\n    bytesPrefix: [0x42, 0x4d],\n    base64Prefix: 'Qk',\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x49, 0x49, 0x2a, 0x00],\n    base64Prefix: 'SUkqAA',\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x4d, 0x4d, 0x00, 0x2a],\n    base64Prefix: 'TU0AKg',\n  },\n  {\n    mediaType: 'image/avif' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x61, 0x76, 0x69, 0x66,\n    ],\n    base64Prefix: 'AAAAIGZ0eXBhdmlm',\n  },\n  {\n    mediaType: 'image/heic' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x68, 0x65, 0x69, 0x63,\n    ],\n    base64Prefix: 'AAAAIGZ0eXBoZWlj',\n  },\n] as const;\n\nexport const audioMediaTypeSignatures = [\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xfb],\n    base64Prefix: '//s=',\n  },\n  {\n    mediaType: 'audio/wav' as const,\n    bytesPrefix: [0x52, 0x49, 0x46, 0x46],\n    base64Prefix: 'UklGR',\n  },\n  {\n    mediaType: 'audio/ogg' as const,\n    bytesPrefix: [0x4f, 0x67, 0x67, 0x53],\n    base64Prefix: 'T2dnUw',\n  },\n  {\n    mediaType: 'audio/flac' as const,\n    bytesPrefix: [0x66, 0x4c, 0x61, 0x43],\n    base64Prefix: 'ZkxhQw',\n  },\n  {\n    mediaType: 'audio/aac' as const,\n    bytesPrefix: [0x40, 0x15, 0x00, 0x00],\n    base64Prefix: 'QBUA',\n  },\n  {\n    mediaType: 'audio/mp4' as const,\n    bytesPrefix: [0x66, 0x74, 0x79, 0x70],\n    base64Prefix: 'ZnR5cA',\n  },\n] as const;\n\nconst stripID3 = (data: Uint8Array | string) => {\n  const bytes =\n    typeof data === 'string' ? convertBase64ToUint8Array(data) : data;\n  const id3Size =\n    ((bytes[6] & 0x7f) << 21) |\n    ((bytes[7] & 0x7f) << 14) |\n    ((bytes[8] & 0x7f) << 7) |\n    (bytes[9] & 0x7f);\n\n  // The raw MP3 starts here\n  return bytes.slice(id3Size + 10);\n};\n\nfunction stripID3TagsIfPresent(data: Uint8Array | string): Uint8Array | string {\n  const hasId3 =\n    (typeof data === 'string' && data.startsWith('SUQz')) ||\n    (typeof data !== 'string' &&\n      data.length > 10 &&\n      data[0] === 0x49 && // 'I'\n      data[1] === 0x44 && // 'D'\n      data[2] === 0x33); // '3'\n\n  return hasId3 ? stripID3(data) : data;\n}\n\n/**\n * Detect the media IANA media type of a file using a list of signatures.\n *\n * @param data - The file data.\n * @param signatures - The signatures to use for detection.\n * @returns The media type of the file.\n */\nexport function detectMediaType({\n  data,\n  signatures,\n}: {\n  data: Uint8Array | string;\n  signatures: typeof audioMediaTypeSignatures | typeof imageMediaTypeSignatures;\n}): (typeof signatures)[number]['mediaType'] | undefined {\n  const processedData = stripID3TagsIfPresent(data);\n\n  for (const signature of signatures) {\n    if (\n      typeof processedData === 'string'\n        ? processedData.startsWith(signature.base64Prefix)\n        : processedData.length >= signature.bytesPrefix.length &&\n          signature.bytesPrefix.every(\n            (byte, index) => processedData[index] === byte,\n          )\n    ) {\n      return signature.mediaType;\n    }\n  }\n\n  return undefined;\n}\n","import {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n} from '@ai-sdk/provider-utils';\n\n/**\n * A generated file.\n */\nexport interface GeneratedFile {\n  /**\nFile as a base64 encoded string.\n     */\n  readonly base64: string;\n\n  /**\nFile as a Uint8Array.\n     */\n  readonly uint8Array: Uint8Array;\n\n  /**\nThe IANA media type of the file.\n\n@see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  readonly mediaType: string;\n}\n\nexport class DefaultGeneratedFile implements GeneratedFile {\n  private base64Data: string | undefined;\n  private uint8ArrayData: Uint8Array | undefined;\n\n  readonly mediaType: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    const isUint8Array = data instanceof Uint8Array;\n    this.base64Data = isUint8Array ? undefined : data;\n    this.uint8ArrayData = isUint8Array ? data : undefined;\n    this.mediaType = mediaType;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get base64() {\n    if (this.base64Data == null) {\n      this.base64Data = convertUint8ArrayToBase64(this.uint8ArrayData!);\n    }\n    return this.base64Data;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get uint8Array() {\n    if (this.uint8ArrayData == null) {\n      this.uint8ArrayData = convertBase64ToUint8Array(this.base64Data!);\n    }\n    return this.uint8ArrayData;\n  }\n}\n\nexport class DefaultGeneratedFileWithType extends DefaultGeneratedFile {\n  readonly type = 'file';\n\n  constructor(options: { data: string | Uint8Array; mediaType: string }) {\n    super(options);\n  }\n}\n","import { ImageModelV2, ImageModelV2ProviderMetadata } from '@ai-sdk/provider';\nimport { NoImageGeneratedError } from '../../src/error/no-image-generated-error';\nimport {\n  detectMediaType,\n  imageMediaTypeSignatures,\n} from '../../src/util/detect-media-type';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport {\n  DefaultGeneratedFile,\n  GeneratedFile,\n} from '../generate-text/generated-file';\nimport { ImageGenerationWarning } from '../types/image-model';\nimport { ImageModelResponseMetadata } from '../types/image-model-response-metadata';\nimport { ProviderOptions } from '../types/provider-metadata';\nimport { GenerateImageResult } from './generate-image-result';\n\n/**\nGenerates images using an image model.\n\n@param model - The image model to use.\n@param prompt - The prompt that should be used to generate the image.\n@param n - Number of images to generate. Default: 1.\n@param size - Size of the images to generate. Must have the format `{width}x{height}`.\n@param aspectRatio - Aspect ratio of the images to generate. Must have the format `{width}:{height}`.\n@param seed - Seed for the image generation.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated images.\n */\nexport async function generateImage({\n  model,\n  prompt,\n  n = 1,\n  maxImagesPerCall,\n  size,\n  aspectRatio,\n  seed,\n  providerOptions,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe image model to use.\n     */\n  model: ImageModelV2;\n\n  /**\nThe prompt that should be used to generate the image.\n   */\n  prompt: string;\n\n  /**\nNumber of images to generate.\n   */\n  n?: number;\n\n  /**\nNumber of images to generate.\n   */\n  maxImagesPerCall?: number;\n\n  /**\nSize of the images to generate. Must have the format `{width}x{height}`. If not provided, the default size will be used.\n   */\n  size?: `${number}x${number}`;\n\n  /**\nAspect ratio of the images to generate. Must have the format `{width}:{height}`. If not provided, the default aspect ratio will be used.\n   */\n  aspectRatio?: `${number}:${number}`;\n\n  /**\nSeed for the image generation. If not provided, the default seed will be used.\n   */\n  seed?: number;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {\n    \"style\": \"vivid\"\n  }\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<GenerateImageResult> {\n  const { retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  // default to 1 if the model has not specified limits on\n  // how many images can be generated in a single call\n  const maxImagesPerCallWithDefault =\n    maxImagesPerCall ?? (await invokeModelMaxImagesPerCall(model)) ?? 1;\n\n  // parallelize calls to the model:\n  const callCount = Math.ceil(n / maxImagesPerCallWithDefault);\n  const callImageCounts = Array.from({ length: callCount }, (_, i) => {\n    if (i < callCount - 1) {\n      return maxImagesPerCallWithDefault;\n    }\n\n    const remainder = n % maxImagesPerCallWithDefault;\n    return remainder === 0 ? maxImagesPerCallWithDefault : remainder;\n  });\n\n  const results = await Promise.all(\n    callImageCounts.map(async callImageCount =>\n      retry(() =>\n        model.doGenerate({\n          prompt,\n          n: callImageCount,\n          abortSignal,\n          headers,\n          size,\n          aspectRatio,\n          seed,\n          providerOptions: providerOptions ?? {},\n        }),\n      ),\n    ),\n  );\n\n  // collect result images, warnings, and response metadata\n  const images: Array<DefaultGeneratedFile> = [];\n  const warnings: Array<ImageGenerationWarning> = [];\n  const responses: Array<ImageModelResponseMetadata> = [];\n  const providerMetadata: ImageModelV2ProviderMetadata = {};\n  for (const result of results) {\n    images.push(\n      ...result.images.map(\n        image =>\n          new DefaultGeneratedFile({\n            data: image,\n            mediaType:\n              detectMediaType({\n                data: image,\n                signatures: imageMediaTypeSignatures,\n              }) ?? 'image/png',\n          }),\n      ),\n    );\n    warnings.push(...result.warnings);\n\n    if (result.providerMetadata) {\n      for (const [providerName, metadata] of Object.entries<{\n        images: unknown;\n      }>(result.providerMetadata)) {\n        providerMetadata[providerName] ??= { images: [] };\n        providerMetadata[providerName].images.push(\n          ...result.providerMetadata[providerName].images,\n        );\n      }\n    }\n\n    responses.push(result.response);\n  }\n\n  if (!images.length) {\n    throw new NoImageGeneratedError({ responses });\n  }\n\n  return new DefaultGenerateImageResult({\n    images,\n    warnings,\n    responses,\n    providerMetadata,\n  });\n}\n\nclass DefaultGenerateImageResult implements GenerateImageResult {\n  readonly images: Array<GeneratedFile>;\n  readonly warnings: Array<ImageGenerationWarning>;\n  readonly responses: Array<ImageModelResponseMetadata>;\n  readonly providerMetadata: ImageModelV2ProviderMetadata;\n\n  constructor(options: {\n    images: Array<GeneratedFile>;\n    warnings: Array<ImageGenerationWarning>;\n    responses: Array<ImageModelResponseMetadata>;\n    providerMetadata: ImageModelV2ProviderMetadata;\n  }) {\n    this.images = options.images;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata;\n  }\n\n  get image() {\n    return this.images[0];\n  }\n}\n\nasync function invokeModelMaxImagesPerCall(model: ImageModelV2) {\n  const isFunction = model.maxImagesPerCall instanceof Function;\n\n  if (!isFunction) {\n    return model.maxImagesPerCall;\n  }\n\n  return model.maxImagesPerCall({\n    modelId: model.modelId,\n  });\n}\n","import {\n  JSONParseError,\n  JSONValue,\n  TypeValidationError,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  InferSchema,\n  safeParseJSON,\n  Schema,\n} from '@ai-sdk/provider-utils';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { NoObjectGeneratedError } from '../../src/error/no-object-generated-error';\nimport { prepareHeaders } from '../../src/util/prepare-headers';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { extractContentText } from '../generate-text/extract-content-text';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { resolveLanguageModel } from '../prompt/resolve-language-model';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n} from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata, ProviderOptions } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { GenerateObjectResult } from './generate-object-result';\nimport { getOutputStrategy } from './output-strategy';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nA function that attempts to repair the raw output of the mode\nto enable JSON parsing.\n\nShould return the repaired text or null if the text cannot be repaired.\n     */\nexport type RepairTextFunction = (options: {\n  text: string;\n  error: JSONParseError | TypeValidationError;\n}) => Promise<string | null>;\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_repairText - A function that attempts to repair the raw output of the mode\nto enable JSON parsing.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object that contains the generated object, the finish reason, the token usage, and additional information.\n */\nexport async function generateObject<\n  SCHEMA extends z3.Schema | z4.$ZodType | Schema = z4.$ZodType<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n        */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n        */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n        */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n        */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\n  The language model to use.\n       */\n      model: LanguageModel;\n      /**\n  A function that attempts to repair the raw output of the mode\n  to enable JSON parsing.\n       */\n      experimental_repairText?: RepairTextFunction;\n\n      /**\n  Optional telemetry configuration (experimental).\n         */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n   */\n      providerOptions?: ProviderOptions;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n      };\n    },\n): Promise<GenerateObjectResult<RESULT>> {\n  const {\n    model: modelArg,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    headers,\n    experimental_repairText: repairText,\n    experimental_telemetry: telemetry,\n    providerOptions,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n    } = {},\n    ...settings\n  } = options;\n\n  const model = resolveLanguageModel(modelArg);\n\n  const enumValues = 'enum' in options ? options.enum : undefined;\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const { maxRetries, retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      fn: async span => {\n        let result: string;\n        let finishReason: FinishReason;\n        let usage: LanguageModelUsage;\n        let warnings: CallWarning[] | undefined;\n        let response: LanguageModelResponseMetadata;\n        let request: LanguageModelRequestMetadata;\n        let resultProviderMetadata: ProviderMetadata | undefined;\n\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        });\n\n        const promptMessages = await convertToLanguageModelPrompt({\n          prompt: standardizedPrompt,\n          supportedUrls: await model.supportedUrls,\n        });\n\n        const generateResult = await retry(() =>\n          recordSpan({\n            name: 'ai.generateObject.doGenerate',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.generateObject.doGenerate',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(promptMessages),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            fn: async span => {\n              const result = await model.doGenerate({\n                responseFormat: {\n                  type: 'json',\n                  schema: outputStrategy.jsonSchema,\n                  name: schemaName,\n                  description: schemaDescription,\n                },\n                ...prepareCallSettings(settings),\n                prompt: promptMessages,\n                providerOptions,\n                abortSignal,\n                headers,\n              });\n\n              const responseData = {\n                id: result.response?.id ?? generateId(),\n                timestamp: result.response?.timestamp ?? currentDate(),\n                modelId: result.response?.modelId ?? model.modelId,\n                headers: result.response?.headers,\n                body: result.response?.body,\n              };\n\n              const text = extractContentText(result.content);\n\n              if (text === undefined) {\n                throw new NoObjectGeneratedError({\n                  message:\n                    'No object generated: the model did not return a response.',\n                  response: responseData,\n                  usage: result.usage,\n                  finishReason: result.finishReason,\n                });\n              }\n\n              // Add response information to the span:\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.response.finishReason': result.finishReason,\n                    'ai.response.object': { output: () => text },\n                    'ai.response.id': responseData.id,\n                    'ai.response.model': responseData.modelId,\n                    'ai.response.timestamp':\n                      responseData.timestamp.toISOString(),\n\n                    // TODO rename telemetry attributes to inputTokens and outputTokens\n                    'ai.usage.promptTokens': result.usage.inputTokens,\n                    'ai.usage.completionTokens': result.usage.outputTokens,\n\n                    // standardized gen-ai llm span attributes:\n                    'gen_ai.response.finish_reasons': [result.finishReason],\n                    'gen_ai.response.id': responseData.id,\n                    'gen_ai.response.model': responseData.modelId,\n                    'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                    'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                  },\n                }),\n              );\n\n              return { ...result, objectText: text, responseData };\n            },\n          }),\n        );\n\n        result = generateResult.objectText;\n        finishReason = generateResult.finishReason;\n        usage = generateResult.usage;\n        warnings = generateResult.warnings;\n        resultProviderMetadata = generateResult.providerMetadata;\n        request = generateResult.request ?? {};\n        response = generateResult.responseData;\n\n        async function processResult(result: string): Promise<RESULT> {\n          const parseResult = await safeParseJSON({ text: result });\n\n          if (!parseResult.success) {\n            throw new NoObjectGeneratedError({\n              message: 'No object generated: could not parse the response.',\n              cause: parseResult.error,\n              text: result,\n              response,\n              usage,\n              finishReason,\n            });\n          }\n\n          const validationResult = await outputStrategy.validateFinalResult(\n            parseResult.value,\n            {\n              text: result,\n              response,\n              usage,\n            },\n          );\n\n          if (!validationResult.success) {\n            throw new NoObjectGeneratedError({\n              message: 'No object generated: response did not match schema.',\n              cause: validationResult.error,\n              text: result,\n              response,\n              usage,\n              finishReason,\n            });\n          }\n\n          return validationResult.value;\n        }\n\n        let object: RESULT;\n        try {\n          object = await processResult(result);\n        } catch (error) {\n          if (\n            repairText != null &&\n            NoObjectGeneratedError.isInstance(error) &&\n            (JSONParseError.isInstance(error.cause) ||\n              TypeValidationError.isInstance(error.cause))\n          ) {\n            const repairedText = await repairText({\n              text: result,\n              error: error.cause,\n            });\n\n            if (repairedText === null) {\n              throw error;\n            }\n\n            object = await processResult(repairedText);\n          } else {\n            throw error;\n          }\n        }\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': finishReason,\n              'ai.response.object': {\n                output: () => JSON.stringify(object),\n              },\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': usage.inputTokens,\n              'ai.usage.completionTokens': usage.outputTokens,\n            },\n          }),\n        );\n\n        return new DefaultGenerateObjectResult({\n          object,\n          finishReason,\n          usage,\n          warnings,\n          request,\n          response,\n          providerMetadata: resultProviderMetadata,\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nclass DefaultGenerateObjectResult<T> implements GenerateObjectResult<T> {\n  readonly object: GenerateObjectResult<T>['object'];\n  readonly finishReason: GenerateObjectResult<T>['finishReason'];\n  readonly usage: GenerateObjectResult<T>['usage'];\n  readonly warnings: GenerateObjectResult<T>['warnings'];\n  readonly providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n  readonly response: GenerateObjectResult<T>['response'];\n  readonly request: GenerateObjectResult<T>['request'];\n\n  constructor(options: {\n    object: GenerateObjectResult<T>['object'];\n    finishReason: GenerateObjectResult<T>['finishReason'];\n    usage: GenerateObjectResult<T>['usage'];\n    warnings: GenerateObjectResult<T>['warnings'];\n    providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n    response: GenerateObjectResult<T>['response'];\n    request: GenerateObjectResult<T>['request'];\n  }) {\n    this.object = options.object;\n    this.finishReason = options.finishReason;\n    this.usage = options.usage;\n    this.warnings = options.warnings;\n    this.providerMetadata = options.providerMetadata;\n    this.response = options.response;\n    this.request = options.request;\n  }\n\n  toJsonResponse(init?: ResponseInit): Response {\n    return new Response(JSON.stringify(this.object), {\n      status: init?.status ?? 200,\n      headers: prepareHeaders(init?.headers, {\n        'content-type': 'application/json; charset=utf-8',\n      }),\n    });\n  }\n}\n","import { LanguageModelV2Content, LanguageModelV2Text } from '@ai-sdk/provider';\n\nexport function extractContentText(\n  content: LanguageModelV2Content[],\n): string | undefined {\n  const parts = content.filter(\n    (content): content is LanguageModelV2Text => content.type === 'text',\n  );\n\n  if (parts.length === 0) {\n    return undefined;\n  }\n\n  return parts.map(content => content.text).join('');\n}\n","import {\n  LanguageModelV2FilePart,\n  LanguageModelV2Message,\n  LanguageModelV2Prompt,\n  LanguageModelV2TextPart,\n} from '@ai-sdk/provider';\nimport { isUrlSupported } from '@ai-sdk/provider-utils';\nimport {\n  detectMediaType,\n  imageMediaTypeSignatures,\n} from '../../src/util/detect-media-type';\nimport { download } from '../../src/util/download';\nimport { ModelMessage } from '../prompt/message';\nimport { FilePart, ImagePart, TextPart } from './content-part';\nimport {\n  convertToLanguageModelV2DataContent,\n  DataContent,\n} from './data-content';\nimport { InvalidMessageRoleError } from './invalid-message-role-error';\nimport { StandardizedPrompt } from './standardize-prompt';\n\nexport async function convertToLanguageModelPrompt({\n  prompt,\n  supportedUrls,\n  downloadImplementation = download,\n}: {\n  prompt: StandardizedPrompt;\n  supportedUrls: Record<string, RegExp[]>;\n  downloadImplementation?: typeof download;\n}): Promise<LanguageModelV2Prompt> {\n  const downloadedAssets = await downloadAssets(\n    prompt.messages,\n    downloadImplementation,\n    supportedUrls,\n  );\n\n  return [\n    ...(prompt.system != null\n      ? [{ role: 'system' as const, content: prompt.system }]\n      : []),\n    ...prompt.messages.map(message =>\n      convertToLanguageModelMessage(message, downloadedAssets),\n    ),\n  ];\n}\n\n/**\n * Convert a ModelMessage to a LanguageModelV2Message.\n *\n * @param message The ModelMessage to convert.\n * @param downloadedAssets A map of URLs to their downloaded data. Only\n *   available if the model does not support URLs, null otherwise.\n */\nexport function convertToLanguageModelMessage(\n  message: ModelMessage,\n  downloadedAssets: Record<\n    string,\n    { mediaType: string | undefined; data: Uint8Array }\n  >,\n): LanguageModelV2Message {\n  const role = message.role;\n  switch (role) {\n    case 'system': {\n      return {\n        role: 'system',\n        content: message.content,\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'user': {\n      if (typeof message.content === 'string') {\n        return {\n          role: 'user',\n          content: [{ type: 'text', text: message.content }],\n          providerOptions: message.providerOptions,\n        };\n      }\n\n      return {\n        role: 'user',\n        content: message.content\n          .map(part => convertPartToLanguageModelPart(part, downloadedAssets))\n          // remove empty text parts:\n          .filter(part => part.type !== 'text' || part.text !== ''),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'assistant': {\n      if (typeof message.content === 'string') {\n        return {\n          role: 'assistant',\n          content: [{ type: 'text', text: message.content }],\n          providerOptions: message.providerOptions,\n        };\n      }\n\n      return {\n        role: 'assistant',\n        content: message.content\n          .filter(\n            // remove empty text parts:\n            part => part.type !== 'text' || part.text !== '',\n          )\n          .map(part => {\n            const providerOptions = part.providerOptions;\n\n            switch (part.type) {\n              case 'file': {\n                const { data, mediaType } = convertToLanguageModelV2DataContent(\n                  part.data,\n                );\n                return {\n                  type: 'file',\n                  data,\n                  filename: part.filename,\n                  mediaType: mediaType ?? part.mediaType,\n                  providerOptions,\n                };\n              }\n              case 'reasoning': {\n                return {\n                  type: 'reasoning',\n                  text: part.text,\n                  providerOptions,\n                };\n              }\n              case 'text': {\n                return {\n                  type: 'text' as const,\n                  text: part.text,\n                  providerOptions,\n                };\n              }\n              case 'tool-call': {\n                return {\n                  type: 'tool-call' as const,\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  args: part.args,\n                  providerOptions,\n                };\n              }\n            }\n          }),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'tool': {\n      return {\n        role: 'tool',\n        content: message.content.map(part => ({\n          type: 'tool-result',\n          toolCallId: part.toolCallId,\n          toolName: part.toolName,\n          result: part.result,\n          content: part.experimental_content,\n          isError: part.isError,\n          providerOptions: part.providerOptions,\n        })),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    default: {\n      const _exhaustiveCheck: never = role;\n      throw new InvalidMessageRoleError({ role: _exhaustiveCheck });\n    }\n  }\n}\n\n/**\n * Downloads images and files from URLs in the messages.\n */\nasync function downloadAssets(\n  messages: ModelMessage[],\n  downloadImplementation: typeof download,\n  supportedUrls: Record<string, RegExp[]>,\n): Promise<\n  Record<string, { mediaType: string | undefined; data: Uint8Array }>\n> {\n  const urls = messages\n    .filter(message => message.role === 'user')\n    .map(message => message.content)\n    .filter((content): content is Array<TextPart | ImagePart | FilePart> =>\n      Array.isArray(content),\n    )\n    .flat()\n    .filter(\n      (part): part is ImagePart | FilePart =>\n        part.type === 'image' || part.type === 'file',\n    )\n    .map(part => {\n      const mediaType =\n        part.mediaType ?? (part.type === 'image' ? 'image/*' : undefined);\n\n      let data = part.type === 'image' ? part.image : part.data;\n      if (typeof data === 'string') {\n        try {\n          data = new URL(data);\n        } catch (ignored) {}\n      }\n\n      return { mediaType, data };\n    })\n    /**\n     * Filter out URLs that the model supports natively, so we don't download them.\n     */\n    .filter(\n      (part): part is { mediaType: string; data: URL } =>\n        part.data instanceof URL &&\n        part.mediaType != null &&\n        !isUrlSupported({\n          url: part.data.toString(),\n          mediaType: part.mediaType,\n          supportedUrls,\n        }),\n    )\n    .map(part => part.data);\n\n  // download in parallel:\n  const downloadedImages = await Promise.all(\n    urls.map(async url => ({\n      url,\n      data: await downloadImplementation({ url }),\n    })),\n  );\n\n  return Object.fromEntries(\n    downloadedImages.map(({ url, data }) => [url.toString(), data]),\n  );\n}\n\n/**\n * Convert part of a message to a LanguageModelV2Part.\n * @param part The part to convert.\n * @param downloadedAssets A map of URLs to their downloaded data. Only\n *  available if the model does not support URLs, null otherwise.\n *\n * @returns The converted part.\n */\nfunction convertPartToLanguageModelPart(\n  part: TextPart | ImagePart | FilePart,\n  downloadedAssets: Record<\n    string,\n    { mediaType: string | undefined; data: Uint8Array }\n  >,\n): LanguageModelV2TextPart | LanguageModelV2FilePart {\n  if (part.type === 'text') {\n    return {\n      type: 'text',\n      text: part.text,\n      providerOptions: part.providerOptions,\n    };\n  }\n\n  let originalData: DataContent | URL;\n  const type = part.type;\n  switch (type) {\n    case 'image':\n      originalData = part.image;\n      break;\n    case 'file':\n      originalData = part.data;\n\n      break;\n    default:\n      throw new Error(`Unsupported part type: ${type}`);\n  }\n\n  const { data: convertedData, mediaType: convertedMediaType } =\n    convertToLanguageModelV2DataContent(originalData);\n\n  let mediaType: string | undefined = convertedMediaType ?? part.mediaType;\n  let data: Uint8Array | string | URL = convertedData; // binary | base64 | url\n\n  // If the content is a URL, we check if it was downloaded:\n  if (data instanceof URL) {\n    const downloadedFile = downloadedAssets[data.toString()];\n    if (downloadedFile) {\n      data = downloadedFile.data;\n      mediaType = downloadedFile.mediaType ?? mediaType;\n    }\n  }\n\n  // Now that we have the normalized data either as a URL or a Uint8Array,\n  // we can create the LanguageModelV2Part.\n  switch (type) {\n    case 'image': {\n      // When possible, try to detect the media type automatically\n      // to deal with incorrect media type inputs.\n      // When detection fails, use provided media type.\n      if (data instanceof Uint8Array || typeof data === 'string') {\n        mediaType =\n          detectMediaType({ data, signatures: imageMediaTypeSignatures }) ??\n          mediaType;\n      }\n\n      return {\n        type: 'file',\n        mediaType: mediaType ?? 'image/*', // any image\n        filename: undefined,\n        data,\n        providerOptions: part.providerOptions,\n      };\n    }\n\n    case 'file': {\n      // We must have a mediaType for files, if not, throw an error.\n      if (mediaType == null) {\n        throw new Error(`Media type is missing for file part`);\n      }\n\n      return {\n        type: 'file',\n        mediaType,\n        filename: part.filename,\n        data,\n        providerOptions: part.providerOptions,\n      };\n    }\n  }\n}\n","import { DownloadError } from './download-error';\n\nexport async function download({ url }: { url: URL }): Promise<{\n  data: Uint8Array;\n  mediaType: string | undefined;\n}> {\n  const urlText = url.toString();\n  try {\n    const response = await fetch(urlText);\n\n    if (!response.ok) {\n      throw new DownloadError({\n        url: urlText,\n        statusCode: response.status,\n        statusText: response.statusText,\n      });\n    }\n\n    return {\n      data: new Uint8Array(await response.arrayBuffer()),\n      mediaType: response.headers.get('content-type') ?? undefined,\n    };\n  } catch (error) {\n    if (DownloadError.isInstance(error)) {\n      throw error;\n    }\n\n    throw new DownloadError({ url: urlText, cause: error });\n  }\n}\n","import { AISDKError, LanguageModelV2DataContent } from '@ai-sdk/provider';\nimport {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { InvalidDataContentError } from './invalid-data-content-error';\nimport { splitDataUrl } from './split-data-url';\n\n/**\nData content. Can either be a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer.\n */\nexport type DataContent = string | Uint8Array | ArrayBuffer | Buffer;\n\n/**\n@internal\n */\nexport const dataContentSchema: z.ZodType<DataContent> = z.union([\n  z.string(),\n  z.instanceof(Uint8Array),\n  z.instanceof(ArrayBuffer),\n  z.custom(\n    // Buffer might not be available in some environments such as CloudFlare:\n    (value: unknown): value is Buffer =>\n      globalThis.Buffer?.isBuffer(value) ?? false,\n    { message: 'Must be a Buffer' },\n  ),\n]);\n\nexport function convertToLanguageModelV2DataContent(\n  content: DataContent | URL,\n): {\n  data: LanguageModelV2DataContent;\n  mediaType: string | undefined;\n} {\n  // Buffer & Uint8Array:\n  if (content instanceof Uint8Array) {\n    return { data: content, mediaType: undefined };\n  }\n\n  // ArrayBuffer needs conversion to Uint8Array (lightweight):\n  if (content instanceof ArrayBuffer) {\n    return { data: new Uint8Array(content), mediaType: undefined };\n  }\n\n  // Attempt to create a URL from the data. If it fails, we can assume the data\n  // is not a URL and likely some other sort of data.\n  if (typeof content === 'string') {\n    try {\n      content = new URL(content);\n    } catch (error) {\n      // ignored\n    }\n  }\n\n  // Extract data from data URL:\n  if (content instanceof URL && content.protocol === 'data:') {\n    const { mediaType: dataUrlMediaType, base64Content } = splitDataUrl(\n      content.toString(),\n    );\n\n    if (dataUrlMediaType == null || base64Content == null) {\n      throw new AISDKError({\n        name: 'InvalidDataContentError',\n        message: `Invalid data URL format in content ${content.toString()}`,\n      });\n    }\n\n    return { data: base64Content, mediaType: dataUrlMediaType };\n  }\n\n  return { data: content, mediaType: undefined };\n}\n\n/**\nConverts data content to a base64-encoded string.\n\n@param content - Data content to convert.\n@returns Base64-encoded string.\n*/\nexport function convertDataContentToBase64String(content: DataContent): string {\n  if (typeof content === 'string') {\n    return content;\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return convertUint8ArrayToBase64(new Uint8Array(content));\n  }\n\n  return convertUint8ArrayToBase64(content);\n}\n\n/**\nConverts data content to a Uint8Array.\n\n@param content - Data content to convert.\n@returns Uint8Array.\n */\nexport function convertDataContentToUint8Array(\n  content: DataContent,\n): Uint8Array {\n  if (content instanceof Uint8Array) {\n    return content;\n  }\n\n  if (typeof content === 'string') {\n    try {\n      return convertBase64ToUint8Array(content);\n    } catch (error) {\n      throw new InvalidDataContentError({\n        message:\n          'Invalid data content. Content string is not a base64-encoded media.',\n        content,\n        cause: error,\n      });\n    }\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return new Uint8Array(content);\n  }\n\n  throw new InvalidDataContentError({ content });\n}\n\n/**\n * Converts a Uint8Array to a string of text.\n *\n * @param uint8Array - The Uint8Array to convert.\n * @returns The converted string.\n */\nexport function convertUint8ArrayToText(uint8Array: Uint8Array): string {\n  try {\n    return new TextDecoder().decode(uint8Array);\n  } catch (error) {\n    throw new Error('Error decoding Uint8Array to text');\n  }\n}\n","export function splitDataUrl(dataUrl: string): {\n  mediaType: string | undefined;\n  base64Content: string | undefined;\n} {\n  try {\n    const [header, base64Content] = dataUrl.split(',');\n    return {\n      mediaType: header.split(';')[0].split(':')[1],\n      base64Content,\n    };\n  } catch (error) {\n    return {\n      mediaType: undefined,\n      base64Content: undefined,\n    };\n  }\n}\n","import { InvalidArgumentError } from '../../src/error/invalid-argument-error';\nimport { CallSettings } from './call-settings';\n\n/**\n * Validates call settings and returns a new object with limited values.\n */\nexport function prepareCallSettings({\n  maxOutputTokens,\n  temperature,\n  topP,\n  topK,\n  presencePenalty,\n  frequencyPenalty,\n  seed,\n  stopSequences,\n}: Omit<CallSettings, 'abortSignal' | 'headers' | 'maxRetries'>): Omit<\n  CallSettings,\n  'abortSignal' | 'headers' | 'maxRetries'\n> {\n  if (maxOutputTokens != null) {\n    if (!Number.isInteger(maxOutputTokens)) {\n      throw new InvalidArgumentError({\n        parameter: 'maxOutputTokens',\n        value: maxOutputTokens,\n        message: 'maxOutputTokens must be an integer',\n      });\n    }\n\n    if (maxOutputTokens < 1) {\n      throw new InvalidArgumentError({\n        parameter: 'maxOutputTokens',\n        value: maxOutputTokens,\n        message: 'maxOutputTokens must be >= 1',\n      });\n    }\n  }\n\n  if (temperature != null) {\n    if (typeof temperature !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'temperature',\n        value: temperature,\n        message: 'temperature must be a number',\n      });\n    }\n  }\n\n  if (topP != null) {\n    if (typeof topP !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'topP',\n        value: topP,\n        message: 'topP must be a number',\n      });\n    }\n  }\n\n  if (topK != null) {\n    if (typeof topK !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'topK',\n        value: topK,\n        message: 'topK must be a number',\n      });\n    }\n  }\n\n  if (presencePenalty != null) {\n    if (typeof presencePenalty !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'presencePenalty',\n        value: presencePenalty,\n        message: 'presencePenalty must be a number',\n      });\n    }\n  }\n\n  if (frequencyPenalty != null) {\n    if (typeof frequencyPenalty !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'frequencyPenalty',\n        value: frequencyPenalty,\n        message: 'frequencyPenalty must be a number',\n      });\n    }\n  }\n\n  if (seed != null) {\n    if (!Number.isInteger(seed)) {\n      throw new InvalidArgumentError({\n        parameter: 'seed',\n        value: seed,\n        message: 'seed must be an integer',\n      });\n    }\n  }\n\n  return {\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    stopSequences,\n    seed,\n  };\n}\n","import { gateway } from '@ai-sdk/gateway';\nimport { LanguageModelV2, ProviderV2 } from '@ai-sdk/provider';\nimport { LanguageModel } from '../types/language-model';\n\nexport const GLOBAL_DEFAULT_PROVIDER = Symbol(\n  'vercel.ai.global.defaultProvider',\n);\n\nexport function resolveLanguageModel(model: LanguageModel): LanguageModelV2 {\n  if (typeof model !== 'string') {\n    return model;\n  }\n\n  const globalProvider = (globalThis as any)[GLOBAL_DEFAULT_PROVIDER] as\n    | ProviderV2\n    | undefined;\n\n  return (globalProvider ?? gateway).languageModel(model);\n}\n","import { InvalidPromptError } from '@ai-sdk/provider';\nimport { safeValidateTypes } from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { ModelMessage, modelMessageSchema } from './message';\nimport { Prompt } from './prompt';\n\nexport type StandardizedPrompt = {\n  /**\n   * System message.\n   */\n  system?: string;\n\n  /**\n   * Messages.\n   */\n  messages: ModelMessage[];\n};\n\nexport async function standardizePrompt(\n  prompt: Prompt,\n): Promise<StandardizedPrompt> {\n  if (prompt.prompt == null && prompt.messages == null) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt or messages must be defined',\n    });\n  }\n\n  if (prompt.prompt != null && prompt.messages != null) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt and messages cannot be defined at the same time',\n    });\n  }\n\n  // validate that system is a string\n  if (prompt.system != null && typeof prompt.system !== 'string') {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'system must be a string',\n    });\n  }\n\n  let messages: ModelMessage[];\n\n  if (prompt.prompt != null && typeof prompt.prompt === 'string') {\n    messages = [{ role: 'user', content: prompt.prompt }];\n  } else if (prompt.prompt != null && Array.isArray(prompt.prompt)) {\n    messages = prompt.prompt;\n  } else if (prompt.messages != null) {\n    messages = prompt.messages;\n  } else {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt or messages must be defined',\n    });\n  }\n\n  if (messages.length === 0) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'messages must not be empty',\n    });\n  }\n\n  const validationResult = await safeValidateTypes({\n    value: messages,\n    schema: z.array(modelMessageSchema),\n  });\n\n  if (!validationResult.success) {\n    throw new InvalidPromptError({\n      prompt,\n      message:\n        'The messages must be a ModelMessage[]. ' +\n        'If you have passed a UIMessage[], you can use convertToModelMessages to convert them.',\n      cause: validationResult.error,\n    });\n  }\n\n  return {\n    messages,\n    system: prompt.system,\n  };\n}\n","import { z } from 'zod';\nimport {\n  providerMetadataSchema,\n  ProviderOptions,\n} from '../types/provider-metadata';\nimport {\n  FilePart,\n  filePartSchema,\n  ImagePart,\n  imagePartSchema,\n  ReasoningPart,\n  reasoningPartSchema,\n  TextPart,\n  textPartSchema,\n  ToolCallPart,\n  toolCallPartSchema,\n  ToolResultPart,\n  toolResultPartSchema,\n} from './content-part';\n\n/**\n A system message. It can contain system information.\n\n Note: using the \"system\" part of the prompt is strongly preferred\n to increase the resilience against prompt injection attacks,\n and because not all providers support several system messages.\n */\nexport type SystemModelMessage = {\n  role: 'system';\n  content: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n};\n\n/**\n@deprecated Use `SystemModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreSystemMessage = SystemModelMessage;\n\nexport const systemModelMessageSchema: z.ZodType<SystemModelMessage> = z.object(\n  {\n    role: z.literal('system'),\n    content: z.string(),\n    providerOptions: providerMetadataSchema.optional(),\n  },\n);\n\n/**\n@deprecated Use `systemModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreSystemMessageSchema = systemModelMessageSchema;\n\n/**\nA user message. It can contain text or a combination of text and images.\n */\nexport type UserModelMessage = {\n  role: 'user';\n  content: UserContent;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n};\n\n/**\n@deprecated Use `UserModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreUserMessage = UserModelMessage;\n\nexport const userModelMessageSchema: z.ZodType<UserModelMessage> = z.object({\n  role: z.literal('user'),\n  content: z.union([\n    z.string(),\n    z.array(z.union([textPartSchema, imagePartSchema, filePartSchema])),\n  ]),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `userModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreUserMessageSchema = userModelMessageSchema;\n\n/**\nContent of a user message. It can be a string or an array of text and image parts.\n */\nexport type UserContent = string | Array<TextPart | ImagePart | FilePart>;\n\n/**\nAn assistant message. It can contain text, tool calls, or a combination of text and tool calls.\n */\nexport type AssistantModelMessage = {\n  role: 'assistant';\n  content: AssistantContent;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n};\n\n/**\n@deprecated Use `AssistantModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreAssistantMessage = AssistantModelMessage;\n\nexport const assistantModelMessageSchema: z.ZodType<AssistantModelMessage> =\n  z.object({\n    role: z.literal('assistant'),\n    content: z.union([\n      z.string(),\n      z.array(\n        z.union([\n          textPartSchema,\n          filePartSchema,\n          reasoningPartSchema,\n          toolCallPartSchema,\n        ]),\n      ),\n    ]),\n    providerOptions: providerMetadataSchema.optional(),\n  });\n\n/**\n@deprecated Use `assistantModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreAssistantMessageSchema = assistantModelMessageSchema;\n\n/**\nContent of an assistant message.\nIt can be a string or an array of text, image, reasoning, redacted reasoning, and tool call parts.\n */\nexport type AssistantContent =\n  | string\n  | Array<TextPart | FilePart | ReasoningPart | ToolCallPart>;\n\n/**\nA tool message. It contains the result of one or more tool calls.\n */\nexport type ToolModelMessage = {\n  role: 'tool';\n  content: ToolContent;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n};\n\n/**\n@deprecated Use `ToolModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreToolMessage = ToolModelMessage;\n\nexport const toolModelMessageSchema: z.ZodType<ToolModelMessage> = z.object({\n  role: z.literal('tool'),\n  content: z.array(toolResultPartSchema),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `toolModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreToolMessageSchema = toolModelMessageSchema;\n\n/**\nContent of a tool message. It is an array of tool result parts.\n */\nexport type ToolContent = Array<ToolResultPart>;\n\n/**\nA message that can be used in the `messages` field of a prompt.\nIt can be a user message, an assistant message, or a tool message.\n */\nexport type ModelMessage =\n  | SystemModelMessage\n  | UserModelMessage\n  | AssistantModelMessage\n  | ToolModelMessage;\n\n/**\n@deprecated Use `ModelMessage` instead.\n   */\n// TODO remove in AI SDK 6\nexport type CoreMessage = ModelMessage;\n\nexport const modelMessageSchema: z.ZodType<ModelMessage> = z.union([\n  systemModelMessageSchema,\n  userModelMessageSchema,\n  assistantModelMessageSchema,\n  toolModelMessageSchema,\n]);\n\n/**\n@deprecated Use `modelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreMessageSchema: z.ZodType<CoreMessage> = modelMessageSchema;\n","import {\n  SharedV2ProviderMetadata,\n  SharedV2ProviderOptions,\n} from '@ai-sdk/provider';\nimport { z } from 'zod';\nimport { jsonValueSchema } from './json-value';\n\n/**\nAdditional provider-specific metadata that is returned from the provider.\n\nThis is needed to enable provider-specific functionality that can be\nfully encapsulated in the provider.\n */\nexport type ProviderMetadata = SharedV2ProviderMetadata;\n\n/**\nAdditional provider-specific options.\n\nThey are passed through to the provider from the AI SDK and enable\nprovider-specific functionality that can be fully encapsulated in the provider.\n */\nexport type ProviderOptions = SharedV2ProviderOptions;\n\nexport const providerMetadataSchema: z.ZodType<ProviderMetadata> = z.record(\n  z.string(),\n  z.record(z.string(), jsonValueSchema),\n);\n","import { JSONValue as OriginalJSONValue } from '@ai-sdk/provider';\nimport { z } from 'zod';\n\nexport const jsonValueSchema: z.ZodType<JSONValue> = z.lazy(() =>\n  z.union([\n    z.null(),\n    z.string(),\n    z.number(),\n    z.boolean(),\n    z.record(z.string(), jsonValueSchema),\n    z.array(jsonValueSchema),\n  ]),\n);\n\nexport type JSONValue = OriginalJSONValue;\n","import { z } from 'zod';\nimport {\n  providerMetadataSchema,\n  ProviderOptions,\n} from '../types/provider-metadata';\nimport { DataContent, dataContentSchema } from './data-content';\nimport {\n  ToolResultContent,\n  toolResultContentSchema,\n} from './tool-result-content';\n\n/**\nText content part of a prompt. It contains a string of text.\n */\nexport interface TextPart {\n  type: 'text';\n\n  /**\nThe text content.\n   */\n  text: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const textPartSchema: z.ZodType<TextPart> = z.object({\n  type: z.literal('text'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\nImage content part of a prompt. It contains an image.\n */\nexport interface ImagePart {\n  type: 'image';\n\n  /**\nImage data. Can either be:\n\n- data: a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer\n- URL: a URL that points to the image\n   */\n  image: DataContent | URL;\n\n  /**\nOptional IANA media type of the image.\n\n@see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  mediaType?: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const imagePartSchema: z.ZodType<ImagePart> = z.object({\n  type: z.literal('image'),\n  image: z.union([dataContentSchema, z.instanceof(URL)]),\n  mediaType: z.string().optional(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\nFile content part of a prompt. It contains a file.\n */\nexport interface FilePart {\n  type: 'file';\n\n  /**\nFile data. Can either be:\n\n- data: a base64-encoded string, a Uint8Array, an ArrayBuffer, or a Buffer\n- URL: a URL that points to the image\n   */\n  data: DataContent | URL;\n\n  /**\nOptional filename of the file.\n   */\n  filename?: string;\n\n  /**\nIANA media type of the file.\n\n@see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  mediaType: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const filePartSchema: z.ZodType<FilePart> = z.object({\n  type: z.literal('file'),\n  data: z.union([dataContentSchema, z.instanceof(URL)]),\n  filename: z.string().optional(),\n  mediaType: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n * Reasoning content part of a prompt. It contains a reasoning.\n */\nexport interface ReasoningPart {\n  type: 'reasoning';\n\n  /**\nThe reasoning text.\n   */\n  text: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const reasoningPartSchema: z.ZodType<ReasoningPart> = z.object({\n  type: z.literal('reasoning'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\nTool call content part of a prompt. It contains a tool call (usually generated by the AI model).\n */\nexport interface ToolCallPart {\n  type: 'tool-call';\n\n  /**\nID of the tool call. This ID is used to match the tool call with the tool result.\n */\n  toolCallId: string;\n\n  /**\nName of the tool that is being called.\n */\n  toolName: string;\n\n  /**\nArguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.\n   */\n  args: unknown;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const toolCallPartSchema: z.ZodType<ToolCallPart> = z.object({\n  type: z.literal('tool-call'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  args: z.unknown(),\n  providerOptions: providerMetadataSchema.optional(),\n}) as z.ZodType<ToolCallPart>; // necessary bc args is optional on Zod type\n\n/**\nTool result content part of a prompt. It contains the result of the tool call with the matching ID.\n */\nexport interface ToolResultPart {\n  type: 'tool-result';\n\n  /**\nID of the tool call that this result is associated with.\n */\n  toolCallId: string;\n\n  /**\nName of the tool that generated this result.\n  */\n  toolName: string;\n\n  /**\nResult of the tool call. This is a JSON-serializable object.\n   */\n  result: unknown;\n\n  /**\nMulti-part content of the tool result. Only for tools that support multipart results.\n   */\n  experimental_content?: ToolResultContent;\n\n  /**\nOptional flag if the result is an error or an error message.\n   */\n  isError?: boolean;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const toolResultPartSchema: z.ZodType<ToolResultPart> = z.object({\n  type: z.literal('tool-result'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  result: z.unknown(),\n  content: toolResultContentSchema.optional(),\n  isError: z.boolean().optional(),\n  providerOptions: providerMetadataSchema.optional(),\n}) as z.ZodType<ToolResultPart>; // necessary bc result is optional on Zod type\n","import { ToolResultContent } from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\n\nexport type { ToolResultContent };\n\nexport const toolResultContentSchema: z.ZodType<ToolResultContent> = z.array(\n  z.union([\n    z.object({ type: z.literal('text'), text: z.string() }),\n    z.object({\n      type: z.literal('image'),\n      data: z.string(),\n      mediaType: z.string().optional(),\n    }),\n  ]),\n);\n\nexport function isToolResultContent(\n  value: unknown,\n): value is ToolResultContent {\n  if (!Array.isArray(value) || value.length === 0) {\n    return false;\n  }\n\n  return value.every(part => {\n    if (typeof part !== 'object' || part === null) {\n      return false;\n    }\n\n    if (part.type === 'text') {\n      return typeof part.text === 'string';\n    }\n\n    if (part.type === 'image') {\n      return (\n        typeof part.data === 'string' &&\n        (part.mimeType === undefined || typeof part.mimeType === 'string')\n      );\n    }\n\n    return false;\n  });\n}\n","import {\n  GatewayAuthenticationError,\n  GatewayModelNotFoundError,\n} from '@ai-sdk/gateway';\nimport { AISDKError } from '@ai-sdk/provider';\n\nexport function wrapGatewayError(error: unknown): unknown {\n  if (\n    GatewayAuthenticationError.isInstance(error) ||\n    GatewayModelNotFoundError.isInstance(error)\n  ) {\n    return new AISDKError({\n      name: 'GatewayError',\n      message:\n        'Vercel AI Gateway access failed. ' +\n        'If you want to use AI SDK providers directly, use the providers, e.g. @ai-sdk/openai, ' +\n        'or register a different global default provider.',\n      cause: error,\n    });\n  }\n\n  return error;\n}\n","import {\n  LanguageModelV2Message,\n  LanguageModelV2Prompt,\n} from '@ai-sdk/provider';\nimport { convertDataContentToBase64String } from '../prompt/data-content';\n\n/**\n * Helper utility to serialize prompt content for OpenTelemetry tracing.\n * It is initially created because normalized LanguageModelV1Prompt carries\n * images as Uint8Arrays, on which JSON.stringify acts weirdly, converting\n * them to objects with stringified indices as keys, e.g. {\"0\": 42, \"1\": 69 }.\n */\nexport function stringifyForTelemetry(prompt: LanguageModelV2Prompt): string {\n  return JSON.stringify(\n    prompt.map((message: LanguageModelV2Message) => ({\n      ...message,\n      content:\n        typeof message.content === 'string'\n          ? message.content\n          : message.content.map(part =>\n              part.type === 'file'\n                ? {\n                    ...part,\n                    data:\n                      part.data instanceof Uint8Array\n                        ? convertDataContentToBase64String(part.data)\n                        : part.data,\n                  }\n                : part,\n            ),\n    })),\n  );\n}\n","import {\n  isJSONArray,\n  isJSONObject,\n  JSONObject,\n  JSONSchema7,\n  JSONValue,\n  TypeValidationError,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  asSchema,\n  safeValidateTypes,\n  Schema,\n  ValidationResult,\n} from '@ai-sdk/provider-utils';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { NoObjectGeneratedError } from '../../src/error/no-object-generated-error';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../../src/util/async-iterable-stream';\nimport { DeepPartial } from '../../src/util/deep-partial';\nimport {\n  FinishReason,\n  LanguageModelResponseMetadata,\n  LanguageModelUsage,\n} from '../types';\nimport { ObjectStreamPart } from './stream-object-result';\n\nexport interface OutputStrategy<PARTIAL, RESULT, ELEMENT_STREAM> {\n  readonly type: 'object' | 'array' | 'enum' | 'no-schema';\n  readonly jsonSchema: JSONSchema7 | undefined;\n\n  validatePartialResult({\n    value,\n    textDelta,\n    isFinalDelta,\n  }: {\n    value: JSONValue;\n    textDelta: string;\n    isFirstDelta: boolean;\n    isFinalDelta: boolean;\n    latestObject: PARTIAL | undefined;\n  }): Promise<\n    ValidationResult<{\n      partial: PARTIAL;\n      textDelta: string;\n    }>\n  >;\n  validateFinalResult(\n    value: JSONValue | undefined,\n    context: {\n      text: string;\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n    },\n  ): Promise<ValidationResult<RESULT>>;\n\n  createElementStream(\n    originalStream: ReadableStream<ObjectStreamPart<PARTIAL>>,\n  ): ELEMENT_STREAM;\n}\n\nconst noSchemaOutputStrategy: OutputStrategy<JSONValue, JSONValue, never> = {\n  type: 'no-schema',\n  jsonSchema: undefined,\n\n  async validatePartialResult({ value, textDelta }) {\n    return { success: true, value: { partial: value, textDelta } };\n  },\n\n  async validateFinalResult(\n    value: JSONValue | undefined,\n    context: {\n      text: string;\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n      finishReason: FinishReason;\n    },\n  ): Promise<ValidationResult<JSONValue>> {\n    return value === undefined\n      ? {\n          success: false,\n          error: new NoObjectGeneratedError({\n            message: 'No object generated: response did not match schema.',\n            text: context.text,\n            response: context.response,\n            usage: context.usage,\n            finishReason: context.finishReason,\n          }),\n        }\n      : { success: true, value };\n  },\n\n  createElementStream() {\n    throw new UnsupportedFunctionalityError({\n      functionality: 'element streams in no-schema mode',\n    });\n  },\n};\n\nconst objectOutputStrategy = <OBJECT>(\n  schema: Schema<OBJECT>,\n): OutputStrategy<DeepPartial<OBJECT>, OBJECT, never> => ({\n  type: 'object',\n  jsonSchema: schema.jsonSchema,\n\n  async validatePartialResult({ value, textDelta }) {\n    return {\n      success: true,\n      value: {\n        // Note: currently no validation of partial results:\n        partial: value as DeepPartial<OBJECT>,\n        textDelta,\n      },\n    };\n  },\n\n  async validateFinalResult(\n    value: JSONValue | undefined,\n  ): Promise<ValidationResult<OBJECT>> {\n    return safeValidateTypes({ value, schema });\n  },\n\n  createElementStream() {\n    throw new UnsupportedFunctionalityError({\n      functionality: 'element streams in object mode',\n    });\n  },\n});\n\nconst arrayOutputStrategy = <ELEMENT>(\n  schema: Schema<ELEMENT>,\n): OutputStrategy<ELEMENT[], ELEMENT[], AsyncIterableStream<ELEMENT>> => {\n  // remove $schema from schema.jsonSchema:\n  const { $schema, ...itemSchema } = schema.jsonSchema;\n\n  return {\n    type: 'enum',\n\n    // wrap in object that contains array of elements, since most LLMs will not\n    // be able to generate an array directly:\n    // possible future optimization: use arrays directly when model supports grammar-guided generation\n    jsonSchema: {\n      $schema: 'http://json-schema.org/draft-07/schema#',\n      type: 'object',\n      properties: {\n        elements: { type: 'array', items: itemSchema },\n      },\n      required: ['elements'],\n      additionalProperties: false,\n    },\n\n    async validatePartialResult({\n      value,\n      latestObject,\n      isFirstDelta,\n      isFinalDelta,\n    }) {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || !isJSONArray(value.elements)) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be an object that contains an array of elements',\n          }),\n        };\n      }\n\n      const inputArray = value.elements as Array<JSONObject>;\n      const resultArray: Array<ELEMENT> = [];\n\n      for (let i = 0; i < inputArray.length; i++) {\n        const element = inputArray[i];\n        const result = await safeValidateTypes({ value: element, schema });\n\n        // special treatment for last processed element:\n        // ignore parse or validation failures, since they indicate that the\n        // last element is incomplete and should not be included in the result,\n        // unless it is the final delta\n        if (i === inputArray.length - 1 && !isFinalDelta) {\n          continue;\n        }\n\n        if (!result.success) {\n          return result;\n        }\n\n        resultArray.push(result.value);\n      }\n\n      // calculate delta:\n      const publishedElementCount = latestObject?.length ?? 0;\n\n      let textDelta = '';\n\n      if (isFirstDelta) {\n        textDelta += '[';\n      }\n\n      if (publishedElementCount > 0) {\n        textDelta += ',';\n      }\n\n      textDelta += resultArray\n        .slice(publishedElementCount) // only new elements\n        .map(element => JSON.stringify(element))\n        .join(',');\n\n      if (isFinalDelta) {\n        textDelta += ']';\n      }\n\n      return {\n        success: true,\n        value: {\n          partial: resultArray,\n          textDelta,\n        },\n      };\n    },\n\n    async validateFinalResult(\n      value: JSONValue | undefined,\n    ): Promise<ValidationResult<Array<ELEMENT>>> {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || !isJSONArray(value.elements)) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be an object that contains an array of elements',\n          }),\n        };\n      }\n\n      const inputArray = value.elements as Array<JSONObject>;\n\n      // check that each element in the array is of the correct type:\n      for (const element of inputArray) {\n        const result = await safeValidateTypes({ value: element, schema });\n        if (!result.success) {\n          return result;\n        }\n      }\n\n      return { success: true, value: inputArray as Array<ELEMENT> };\n    },\n\n    createElementStream(\n      originalStream: ReadableStream<ObjectStreamPart<ELEMENT[]>>,\n    ) {\n      let publishedElements = 0;\n\n      return createAsyncIterableStream(\n        originalStream.pipeThrough(\n          new TransformStream<ObjectStreamPart<ELEMENT[]>, ELEMENT>({\n            transform(chunk, controller) {\n              switch (chunk.type) {\n                case 'object': {\n                  const array = chunk.object;\n\n                  // publish new elements one by one:\n                  for (\n                    ;\n                    publishedElements < array.length;\n                    publishedElements++\n                  ) {\n                    controller.enqueue(array[publishedElements]);\n                  }\n\n                  break;\n                }\n\n                case 'text-delta':\n                case 'finish':\n                case 'error': // suppress error (use onError instead)\n                  break;\n\n                default: {\n                  const _exhaustiveCheck: never = chunk;\n                  throw new Error(\n                    `Unsupported chunk type: ${_exhaustiveCheck}`,\n                  );\n                }\n              }\n            },\n          }),\n        ),\n      );\n    },\n  };\n};\n\nconst enumOutputStrategy = <ENUM extends string>(\n  enumValues: Array<ENUM>,\n): OutputStrategy<string, ENUM, never> => {\n  return {\n    type: 'enum',\n\n    // wrap in object that contains result, since most LLMs will not\n    // be able to generate an enum value directly:\n    // possible future optimization: use enums directly when model supports top-level enums\n    jsonSchema: {\n      $schema: 'http://json-schema.org/draft-07/schema#',\n      type: 'object',\n      properties: {\n        result: { type: 'string', enum: enumValues },\n      },\n      required: ['result'],\n      additionalProperties: false,\n    },\n\n    async validateFinalResult(\n      value: JSONValue | undefined,\n    ): Promise<ValidationResult<ENUM>> {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || typeof value.result !== 'string') {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause:\n              'value must be an object that contains a string in the \"result\" property.',\n          }),\n        };\n      }\n\n      const result = value.result as string;\n\n      return enumValues.includes(result as ENUM)\n        ? { success: true, value: result as ENUM }\n        : {\n            success: false,\n            error: new TypeValidationError({\n              value,\n              cause: 'value must be a string in the enum',\n            }),\n          };\n    },\n\n    async validatePartialResult({ value, textDelta }) {\n      if (!isJSONObject(value) || typeof value.result !== 'string') {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause:\n              'value must be an object that contains a string in the \"result\" property.',\n          }),\n        };\n      }\n\n      const result = value.result as string;\n      const possibleEnumValues = enumValues.filter(enumValue =>\n        enumValue.startsWith(result),\n      );\n\n      if (value.result.length === 0 || possibleEnumValues.length === 0) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be a string in the enum',\n          }),\n        };\n      }\n\n      return {\n        success: true,\n        value: {\n          partial:\n            possibleEnumValues.length > 1 ? result : possibleEnumValues[0],\n          textDelta,\n        },\n      };\n    },\n\n    createElementStream() {\n      // no streaming in enum mode\n      throw new UnsupportedFunctionalityError({\n        functionality: 'element streams in enum mode',\n      });\n    },\n  };\n};\n\nexport function getOutputStrategy<SCHEMA>({\n  output,\n  schema,\n  enumValues,\n}: {\n  output: 'object' | 'array' | 'enum' | 'no-schema';\n  schema?:\n    | z4.$ZodType<SCHEMA, any>\n    | z3.Schema<SCHEMA, z3.ZodTypeDef, any>\n    | Schema<SCHEMA>;\n  enumValues?: Array<SCHEMA>;\n}): OutputStrategy<any, any, any> {\n  switch (output) {\n    case 'object':\n      return objectOutputStrategy(asSchema(schema!));\n    case 'array':\n      return arrayOutputStrategy(asSchema(schema!));\n    case 'enum':\n      return enumOutputStrategy(enumValues! as Array<string>);\n    case 'no-schema':\n      return noSchemaOutputStrategy;\n    default: {\n      const _exhaustiveCheck: never = output;\n      throw new Error(`Unsupported output: ${_exhaustiveCheck}`);\n    }\n  }\n}\n","export type AsyncIterableStream<T> = AsyncIterable<T> & ReadableStream<T>;\n\nexport function createAsyncIterableStream<T>(\n  source: ReadableStream<T>,\n): AsyncIterableStream<T> {\n  const stream = source.pipeThrough(new TransformStream<T, T>());\n\n  (stream as AsyncIterableStream<T>)[Symbol.asyncIterator] = () => {\n    const reader = stream.getReader();\n    return {\n      async next(): Promise<IteratorResult<T>> {\n        const { done, value } = await reader.read();\n        return done ? { done: true, value: undefined } : { done: false, value };\n      },\n    };\n  };\n\n  return stream as AsyncIterableStream<T>;\n}\n","import { Schema } from '@ai-sdk/provider-utils';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { InvalidArgumentError } from '../../src/error/invalid-argument-error';\n\nexport function validateObjectGenerationInput({\n  output,\n  schema,\n  schemaName,\n  schemaDescription,\n  enumValues,\n}: {\n  output?: 'object' | 'array' | 'enum' | 'no-schema';\n  schema?:\n    | z4.$ZodType<any, any>\n    | z3.Schema<any, z3.ZodTypeDef, any>\n    | Schema<any>;\n  schemaName?: string;\n  schemaDescription?: string;\n  enumValues?: Array<unknown>;\n}) {\n  if (\n    output != null &&\n    output !== 'object' &&\n    output !== 'array' &&\n    output !== 'enum' &&\n    output !== 'no-schema'\n  ) {\n    throw new InvalidArgumentError({\n      parameter: 'output',\n      value: output,\n      message: 'Invalid output type.',\n    });\n  }\n\n  if (output === 'no-schema') {\n    if (schema != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is not supported for no-schema output.',\n      });\n    }\n\n    if (schemaDescription != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaDescription',\n        value: schemaDescription,\n        message: 'Schema description is not supported for no-schema output.',\n      });\n    }\n\n    if (schemaName != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaName',\n        value: schemaName,\n        message: 'Schema name is not supported for no-schema output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for no-schema output.',\n      });\n    }\n  }\n\n  if (output === 'object') {\n    if (schema == null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is required for object output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for object output.',\n      });\n    }\n  }\n\n  if (output === 'array') {\n    if (schema == null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Element schema is required for array output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for array output.',\n      });\n    }\n  }\n\n  if (output === 'enum') {\n    if (schema != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is not supported for enum output.',\n      });\n    }\n\n    if (schemaDescription != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaDescription',\n        value: schemaDescription,\n        message: 'Schema description is not supported for enum output.',\n      });\n    }\n\n    if (schemaName != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaName',\n        value: schemaName,\n        message: 'Schema name is not supported for enum output.',\n      });\n    }\n\n    if (enumValues == null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are required for enum output.',\n      });\n    }\n\n    for (const value of enumValues) {\n      if (typeof value !== 'string') {\n        throw new InvalidArgumentError({\n          parameter: 'enumValues',\n          value,\n          message: 'Enum values must be strings.',\n        });\n      }\n    }\n  }\n}\n","import {\n  JSONValue,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  type InferSchema,\n  type Schema,\n} from '@ai-sdk/provider-utils';\nimport { ServerResponse } from 'http';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { NoObjectGeneratedError } from '../../src/error/no-object-generated-error';\nimport { createTextStreamResponse } from '../../src/text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../../src/text-stream/pipe-text-stream-to-response';\nimport { DeepPartial, isDeepEqualData, parsePartialJson } from '../../src/util';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../../src/util/async-iterable-stream';\nimport { createStitchableStream } from '../../src/util/create-stitchable-stream';\nimport { DelayedPromise } from '../../src/util/delayed-promise';\nimport { now as originalNow } from '../../src/util/now';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { resolveLanguageModel } from '../prompt/resolve-language-model';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { CallWarning, LanguageModel } from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata, ProviderOptions } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { getOutputStrategy, OutputStrategy } from './output-strategy';\nimport { ObjectStreamPart, StreamObjectResult } from './stream-object-result';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnErrorCallback = (event: {\n  error: unknown;\n}) => Promise<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnFinishCallback<RESULT> = (event: {\n  /**\nThe token usage of the generated response.\n*/\n  usage: LanguageModelUsage;\n\n  /**\nThe generated object. Can be undefined if the final object does not match the schema.\n*/\n  object: RESULT | undefined;\n\n  /**\nOptional error object. This is e.g. a TypeValidationError when the final object does not match the schema.\n*/\n  error: unknown | undefined;\n\n  /**\nResponse metadata.\n */\n  response: LanguageModelResponseMetadata;\n\n  /**\nWarnings from the model provider (e.g. unsupported settings).\n*/\n  warnings?: CallWarning[];\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n*/\n  providerMetadata: ProviderMetadata | undefined;\n}) => Promise<void> | void;\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object for accessing the partial object stream and additional information.\n */\nexport function streamObject<\n  SCHEMA extends z3.Schema | z4.$ZodType | Schema = z4.$ZodType<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n      */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n      */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n      */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n      */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\nThe language model to use.\n     */\n      model: LanguageModel;\n\n      /**\nOptional telemetry configuration (experimental).\n       */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n      providerOptions?: ProviderOptions;\n\n      /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n      onError?: StreamObjectOnErrorCallback;\n\n      /**\nCallback that is called when the LLM response and the final object validation are finished.\n*/\n      onFinish?: StreamObjectOnFinishCallback<RESULT>;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n        now?: () => number;\n      };\n    },\n): StreamObjectResult<\n  OUTPUT extends 'enum'\n    ? string\n    : OUTPUT extends 'array'\n      ? RESULT\n      : DeepPartial<RESULT>,\n  OUTPUT extends 'array' ? RESULT : RESULT,\n  OUTPUT extends 'array'\n    ? RESULT extends Array<infer U>\n      ? AsyncIterableStream<U>\n      : never\n    : never\n> {\n  const {\n    model,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries,\n    abortSignal,\n    headers,\n    experimental_telemetry: telemetry,\n    providerOptions,\n    onError = ({ error }: { error: unknown }) => {\n      console.error(error);\n    },\n    onFinish,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n      now = originalNow,\n    } = {},\n    ...settings\n  } = options;\n\n  const enumValues =\n    'enum' in options && options.enum ? options.enum : undefined;\n\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  return new DefaultStreamObjectResult({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    onError,\n    onFinish,\n    generateId,\n    currentDate,\n    now,\n  });\n}\n\nclass DefaultStreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n  implements StreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n{\n  private readonly _object = new DelayedPromise<RESULT>();\n  private readonly _usage = new DelayedPromise<LanguageModelUsage>();\n  private readonly _providerMetadata = new DelayedPromise<\n    ProviderMetadata | undefined\n  >();\n  private readonly _warnings = new DelayedPromise<CallWarning[] | undefined>();\n  private readonly _request =\n    new DelayedPromise<LanguageModelRequestMetadata>();\n  private readonly _response =\n    new DelayedPromise<LanguageModelResponseMetadata>();\n\n  private readonly baseStream: ReadableStream<ObjectStreamPart<PARTIAL>>;\n\n  private readonly outputStrategy: OutputStrategy<\n    PARTIAL,\n    RESULT,\n    ELEMENT_STREAM\n  >;\n\n  constructor({\n    model: modelArg,\n    headers,\n    telemetry,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    onError,\n    onFinish,\n    generateId,\n    currentDate,\n    now,\n  }: {\n    model: LanguageModel;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    outputStrategy: OutputStrategy<PARTIAL, RESULT, ELEMENT_STREAM>;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    schemaName: string | undefined;\n    schemaDescription: string | undefined;\n    providerOptions: ProviderOptions | undefined;\n    onError: StreamObjectOnErrorCallback;\n    onFinish: StreamObjectOnFinishCallback<RESULT> | undefined;\n    generateId: () => string;\n    currentDate: () => Date;\n    now: () => number;\n  }) {\n    const model = resolveLanguageModel(modelArg);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n    });\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const tracer = getTracer(telemetry);\n    const self = this;\n\n    const stitchableStream =\n      createStitchableStream<ObjectStreamPart<PARTIAL>>();\n\n    const eventProcessor = new TransformStream<\n      ObjectStreamPart<PARTIAL>,\n      ObjectStreamPart<PARTIAL>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue(chunk);\n\n        if (chunk.type === 'error') {\n          onError({ error: wrapGatewayError(chunk.error) });\n        }\n      },\n    });\n\n    this.baseStream = stitchableStream.stream.pipeThrough(eventProcessor);\n\n    recordSpan({\n      name: 'ai.streamObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.streamObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpan => {\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        });\n\n        const callOptions = {\n          responseFormat: {\n            type: 'json' as const,\n            schema: outputStrategy.jsonSchema,\n            name: schemaName,\n            description: schemaDescription,\n          },\n          ...prepareCallSettings(settings),\n          prompt: await convertToLanguageModelPrompt({\n            prompt: standardizedPrompt,\n            supportedUrls: await model.supportedUrls,\n          }),\n          providerOptions,\n          abortSignal,\n          headers,\n          includeRawChunks: false,\n        };\n\n        const transformer: Transformer<\n          LanguageModelV2StreamPart,\n          ObjectStreamInputPart\n        > = {\n          transform: (chunk, controller) => {\n            switch (chunk.type) {\n              case 'text':\n                controller.enqueue(chunk.text);\n                break;\n              case 'response-metadata':\n              case 'finish':\n              case 'error':\n                controller.enqueue(chunk);\n                break;\n            }\n          },\n        };\n\n        const {\n          result: { stream, response, request },\n          doStreamSpan,\n          startTimestampMs,\n        } = await retry(() =>\n          recordSpan({\n            name: 'ai.streamObject.doStream',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.streamObject.doStream',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(callOptions.prompt),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            endWhenDone: false,\n            fn: async doStreamSpan => ({\n              startTimestampMs: now(),\n              doStreamSpan,\n              result: await model.doStream(callOptions),\n            }),\n          }),\n        );\n\n        self._request.resolve(request ?? {});\n\n        // store information for onFinish callback:\n        let warnings: LanguageModelV2CallWarning[] | undefined;\n        let usage: LanguageModelUsage = {\n          inputTokens: undefined,\n          outputTokens: undefined,\n          totalTokens: undefined,\n        };\n        let finishReason: LanguageModelV2FinishReason | undefined;\n        let providerMetadata: ProviderMetadata | undefined;\n        let object: RESULT | undefined;\n        let error: unknown | undefined;\n\n        // pipe chunks through a transformation stream that extracts metadata:\n        let accumulatedText = '';\n        let textDelta = '';\n        let fullResponse: {\n          id: string;\n          timestamp: Date;\n          modelId: string;\n        } = {\n          id: generateId(),\n          timestamp: currentDate(),\n          modelId: model.modelId,\n        };\n\n        // Keep track of raw parse result before type validation, since e.g. Zod might\n        // change the object by mapping properties.\n        let latestObjectJson: JSONValue | undefined = undefined;\n        let latestObject: PARTIAL | undefined = undefined;\n        let isFirstChunk = true;\n        let isFirstDelta = true;\n\n        const transformedStream = stream\n          .pipeThrough(new TransformStream(transformer))\n          .pipeThrough(\n            new TransformStream<\n              string | ObjectStreamInputPart,\n              ObjectStreamPart<PARTIAL>\n            >({\n              async transform(chunk, controller): Promise<void> {\n                if (\n                  typeof chunk === 'object' &&\n                  chunk.type === 'stream-start'\n                ) {\n                  warnings = chunk.warnings;\n                  return; // stream start chunks are sent immediately and do not count as first chunk\n                }\n\n                // Telemetry event for first chunk:\n                if (isFirstChunk) {\n                  const msToFirstChunk = now() - startTimestampMs;\n\n                  isFirstChunk = false;\n\n                  doStreamSpan.addEvent('ai.stream.firstChunk', {\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n\n                  doStreamSpan.setAttributes({\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n                }\n\n                // process partial text chunks\n                if (typeof chunk === 'string') {\n                  accumulatedText += chunk;\n                  textDelta += chunk;\n\n                  const { value: currentObjectJson, state: parseState } =\n                    await parsePartialJson(accumulatedText);\n\n                  if (\n                    currentObjectJson !== undefined &&\n                    !isDeepEqualData(latestObjectJson, currentObjectJson)\n                  ) {\n                    const validationResult =\n                      await outputStrategy.validatePartialResult({\n                        value: currentObjectJson,\n                        textDelta,\n                        latestObject,\n                        isFirstDelta,\n                        isFinalDelta: parseState === 'successful-parse',\n                      });\n\n                    if (\n                      validationResult.success &&\n                      !isDeepEqualData(\n                        latestObject,\n                        validationResult.value.partial,\n                      )\n                    ) {\n                      // inside inner check to correctly parse the final element in array mode:\n                      latestObjectJson = currentObjectJson;\n                      latestObject = validationResult.value.partial;\n\n                      controller.enqueue({\n                        type: 'object',\n                        object: latestObject,\n                      });\n\n                      controller.enqueue({\n                        type: 'text-delta',\n                        textDelta: validationResult.value.textDelta,\n                      });\n\n                      textDelta = '';\n                      isFirstDelta = false;\n                    }\n                  }\n\n                  return;\n                }\n\n                switch (chunk.type) {\n                  case 'response-metadata': {\n                    fullResponse = {\n                      id: chunk.id ?? fullResponse.id,\n                      timestamp: chunk.timestamp ?? fullResponse.timestamp,\n                      modelId: chunk.modelId ?? fullResponse.modelId,\n                    };\n                    break;\n                  }\n\n                  case 'finish': {\n                    // send final text delta:\n                    if (textDelta !== '') {\n                      controller.enqueue({ type: 'text-delta', textDelta });\n                    }\n\n                    // store finish reason for telemetry:\n                    finishReason = chunk.finishReason;\n\n                    // store usage and metadata for promises and onFinish callback:\n                    usage = chunk.usage;\n                    providerMetadata = chunk.providerMetadata;\n\n                    controller.enqueue({\n                      ...chunk,\n                      usage,\n                      response: fullResponse,\n                    });\n\n                    // resolve promises that can be resolved now:\n                    self._usage.resolve(usage);\n                    self._providerMetadata.resolve(providerMetadata);\n                    self._response.resolve({\n                      ...fullResponse,\n                      headers: response?.headers,\n                    });\n\n                    // resolve the object promise with the latest object:\n                    const validationResult =\n                      await outputStrategy.validateFinalResult(\n                        latestObjectJson,\n                        {\n                          text: accumulatedText,\n                          response: fullResponse,\n                          usage,\n                        },\n                      );\n\n                    if (validationResult.success) {\n                      object = validationResult.value;\n                      self._object.resolve(object);\n                    } else {\n                      error = new NoObjectGeneratedError({\n                        message:\n                          'No object generated: response did not match schema.',\n                        cause: validationResult.error,\n                        text: accumulatedText,\n                        response: fullResponse,\n                        usage,\n                        finishReason,\n                      });\n                      self._object.reject(error);\n                    }\n\n                    break;\n                  }\n\n                  default: {\n                    controller.enqueue(chunk);\n                    break;\n                  }\n                }\n              },\n\n              // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n              async flush(controller) {\n                try {\n                  const finalUsage = usage ?? {\n                    promptTokens: NaN,\n                    completionTokens: NaN,\n                    totalTokens: NaN,\n                  };\n\n                  doStreamSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.response.finishReason': finishReason,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                        'ai.response.id': fullResponse.id,\n                        'ai.response.model': fullResponse.modelId,\n                        'ai.response.timestamp':\n                          fullResponse.timestamp.toISOString(),\n\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n\n                        // standardized gen-ai llm span attributes:\n                        'gen_ai.response.finish_reasons': [finishReason],\n                        'gen_ai.response.id': fullResponse.id,\n                        'gen_ai.response.model': fullResponse.modelId,\n                        'gen_ai.usage.input_tokens': finalUsage.inputTokens,\n                        'gen_ai.usage.output_tokens': finalUsage.outputTokens,\n                      },\n                    }),\n                  );\n\n                  // finish doStreamSpan before other operations for correct timing:\n                  doStreamSpan.end();\n\n                  // Add response information to the root span:\n                  rootSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                      },\n                    }),\n                  );\n\n                  // call onFinish callback:\n                  await onFinish?.({\n                    usage: finalUsage,\n                    object,\n                    error,\n                    response: {\n                      ...fullResponse,\n                      headers: response?.headers,\n                    },\n                    warnings,\n                    providerMetadata,\n                  });\n                } catch (error) {\n                  controller.enqueue({ type: 'error', error });\n                } finally {\n                  rootSpan.end();\n                }\n              },\n            }),\n          );\n\n        stitchableStream.addStream(transformedStream);\n      },\n    })\n      .catch(error => {\n        // add an empty stream with an error to break the stream:\n        stitchableStream.addStream(\n          new ReadableStream({\n            start(controller) {\n              controller.enqueue({ type: 'error', error });\n              controller.close();\n            },\n          }),\n        );\n      })\n      .finally(() => {\n        stitchableStream.close();\n      });\n\n    this.outputStrategy = outputStrategy;\n  }\n\n  get object() {\n    return this._object.promise;\n  }\n\n  get usage() {\n    return this._usage.promise;\n  }\n\n  get providerMetadata() {\n    return this._providerMetadata.promise;\n  }\n\n  get warnings() {\n    return this._warnings.promise;\n  }\n\n  get request() {\n    return this._request.promise;\n  }\n\n  get response() {\n    return this._response.promise;\n  }\n\n  get partialObjectStream(): AsyncIterableStream<PARTIAL> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, PARTIAL>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'object':\n                controller.enqueue(chunk.object);\n                break;\n\n              case 'text-delta':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get elementStream(): ELEMENT_STREAM {\n    return this.outputStrategy.createElementStream(this.baseStream);\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, string>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'text-delta':\n                controller.enqueue(chunk.textDelta);\n                break;\n\n              case 'object':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<ObjectStreamPart<PARTIAL>> {\n    return createAsyncIterableStream(this.baseStream);\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n\nexport type ObjectStreamInputPart =\n  | string\n  | {\n      type: 'stream-start';\n      warnings: LanguageModelV2CallWarning[];\n    }\n  | {\n      type: 'error';\n      error: unknown;\n    }\n  | {\n      type: 'response-metadata';\n      id?: string;\n      timestamp?: Date;\n      modelId?: string;\n    }\n  | {\n      type: 'finish';\n      finishReason: LanguageModelV2FinishReason;\n      usage: LanguageModelV2Usage;\n      providerMetadata?: SharedV2ProviderMetadata;\n    };\n","/**\n * Creates a Promise with externally accessible resolve and reject functions.\n *\n * @template T - The type of the value that the Promise will resolve to.\n * @returns An object containing:\n *   - promise: A Promise that can be resolved or rejected externally.\n *   - resolve: A function to resolve the Promise with a value of type T.\n *   - reject: A function to reject the Promise with an error.\n */\nexport function createResolvablePromise<T = any>(): {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n  reject: (error: unknown) => void;\n} {\n  let resolve: (value: T) => void;\n  let reject: (error: unknown) => void;\n\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n\n  return {\n    promise,\n    resolve: resolve!,\n    reject: reject!,\n  };\n}\n","import { createResolvablePromise } from './create-resolvable-promise';\n\n/**\n * Creates a stitchable stream that can pipe one stream at a time.\n *\n * @template T - The type of values emitted by the streams.\n * @returns {Object} An object containing the stitchable stream and control methods.\n */\nexport function createStitchableStream<T>(): {\n  stream: ReadableStream<T>;\n  addStream: (innerStream: ReadableStream<T>) => void;\n  close: () => void;\n  terminate: () => void;\n} {\n  let innerStreamReaders: ReadableStreamDefaultReader<T>[] = [];\n  let controller: ReadableStreamDefaultController<T> | null = null;\n  let isClosed = false;\n  let waitForNewStream = createResolvablePromise<void>();\n\n  const processPull = async () => {\n    // Case 1: Outer stream is closed and no more inner streams\n    if (isClosed && innerStreamReaders.length === 0) {\n      controller?.close();\n      return;\n    }\n\n    // Case 2: No inner streams available, but outer stream is open\n    // wait for a new inner stream to be added or the outer stream to close\n    if (innerStreamReaders.length === 0) {\n      waitForNewStream = createResolvablePromise<void>();\n      await waitForNewStream.promise;\n      return processPull();\n    }\n\n    try {\n      const { value, done } = await innerStreamReaders[0].read();\n\n      if (done) {\n        // Case 3: Current inner stream is done\n        innerStreamReaders.shift(); // Remove the finished stream\n\n        // Continue pulling from the next stream if available\n        if (innerStreamReaders.length > 0) {\n          await processPull();\n        } else if (isClosed) {\n          controller?.close();\n        }\n      } else {\n        // Case 4: Current inner stream returns an item\n        controller?.enqueue(value);\n      }\n    } catch (error) {\n      // Case 5: Current inner stream throws an error\n      controller?.error(error);\n      innerStreamReaders.shift(); // Remove the errored stream\n\n      if (isClosed && innerStreamReaders.length === 0) {\n        controller?.close();\n      }\n    }\n  };\n\n  return {\n    stream: new ReadableStream<T>({\n      start(controllerParam) {\n        controller = controllerParam;\n      },\n      pull: processPull,\n      async cancel() {\n        for (const reader of innerStreamReaders) {\n          await reader.cancel();\n        }\n        innerStreamReaders = [];\n        isClosed = true;\n      },\n    }),\n    addStream: (innerStream: ReadableStream<T>) => {\n      if (isClosed) {\n        throw new Error('Cannot add inner stream: outer stream is closed');\n      }\n\n      innerStreamReaders.push(innerStream.getReader());\n      waitForNewStream.resolve();\n    },\n\n    /**\n     * Gracefully close the outer stream. This will let the inner streams\n     * finish processing and then close the outer stream.\n     */\n    close: () => {\n      isClosed = true;\n      waitForNewStream.resolve();\n\n      if (innerStreamReaders.length === 0) {\n        controller?.close();\n      }\n    },\n\n    /**\n     * Immediately close the outer stream. This will cancel all inner streams\n     * and close the outer stream.\n     */\n    terminate: () => {\n      isClosed = true;\n      waitForNewStream.resolve();\n\n      innerStreamReaders.forEach(reader => reader.cancel());\n      innerStreamReaders = [];\n      controller?.close();\n    },\n  };\n}\n","/**\n * Delayed promise. It is only constructed once the value is accessed.\n * This is useful to avoid unhandled promise rejections when the promise is created\n * but not accessed.\n */\nexport class DelayedPromise<T> {\n  private status:\n    | { type: 'pending' }\n    | { type: 'resolved'; value: T }\n    | { type: 'rejected'; error: unknown } = { type: 'pending' };\n  private _promise: Promise<T> | undefined;\n  private _resolve: undefined | ((value: T) => void) = undefined;\n  private _reject: undefined | ((error: unknown) => void) = undefined;\n\n  get promise(): Promise<T> {\n    if (this._promise) {\n      return this._promise;\n    }\n\n    this._promise = new Promise<T>((resolve, reject) => {\n      if (this.status.type === 'resolved') {\n        resolve(this.status.value);\n      } else if (this.status.type === 'rejected') {\n        reject(this.status.error);\n      }\n\n      this._resolve = resolve;\n      this._reject = reject;\n    });\n\n    return this._promise;\n  }\n\n  resolve(value: T): void {\n    this.status = { type: 'resolved', value };\n\n    if (this._promise) {\n      this._resolve?.(value);\n    }\n  }\n\n  reject(error: unknown): void {\n    this.status = { type: 'rejected', error };\n\n    if (this._promise) {\n      this._reject?.(error);\n    }\n  }\n}\n","// Shim for performance.now() to support environments that don't have it:\nexport function now(): number {\n  return globalThis?.performance?.now() ?? Date.now();\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { SpeechModelResponseMetadata } from '../../core/types/speech-model-response-metadata';\n\n/**\nError that is thrown when no speech audio was generated.\n */\nexport class NoSpeechGeneratedError extends AISDKError {\n  readonly responses: Array<SpeechModelResponseMetadata>;\n\n  constructor(options: { responses: Array<SpeechModelResponseMetadata> }) {\n    super({\n      name: 'AI_NoSpeechGeneratedError',\n      message: 'No speech audio generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n","import {\n  GeneratedFile,\n  DefaultGeneratedFile,\n} from '../generate-text/generated-file';\n\n/**\n * A generated audio file.\n */\nexport interface GeneratedAudioFile extends GeneratedFile {\n  /**\n   * Audio format of the file (e.g., 'mp3', 'wav', etc.)\n   */\n  readonly format: string;\n}\n\nexport class DefaultGeneratedAudioFile\n  extends DefaultGeneratedFile\n  implements GeneratedAudioFile\n{\n  readonly format: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    super({ data, mediaType });\n    let format = 'mp3';\n\n    // If format is not provided, try to determine it from the media type\n    if (mediaType) {\n      const mediaTypeParts = mediaType.split('/');\n\n      if (mediaTypeParts.length === 2) {\n        // Handle special cases for audio formats\n        if (mediaType !== 'audio/mpeg') {\n          format = mediaTypeParts[1];\n        }\n      }\n    }\n\n    if (!format) {\n      // TODO this should be an AI SDK error\n      throw new Error(\n        'Audio format must be provided or determinable from media type',\n      );\n    }\n\n    this.format = format;\n  }\n}\n\nexport class DefaultGeneratedAudioFileWithType extends DefaultGeneratedAudioFile {\n  readonly type = 'audio';\n\n  constructor(options: {\n    data: string | Uint8Array;\n    mediaType: string;\n    format: string;\n  }) {\n    super(options);\n  }\n}\n","import { JSONValue, SpeechModelV1 } from '@ai-sdk/provider';\nimport { NoSpeechGeneratedError } from '../../src/error/no-speech-generated-error';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../../src/util/detect-media-type';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { ProviderOptions } from '../types/provider-metadata';\nimport { SpeechWarning } from '../types/speech-model';\nimport { SpeechModelResponseMetadata } from '../types/speech-model-response-metadata';\nimport { SpeechResult } from './generate-speech-result';\nimport {\n  DefaultGeneratedAudioFile,\n  GeneratedAudioFile,\n} from './generated-audio-file';\n\n/**\nGenerates speech audio using a speech model.\n\n@param model - The speech model to use.\n@param text - The text to convert to speech.\n@param voice - The voice to use for speech generation.\n@param outputFormat - The output format to use for speech generation e.g. \"mp3\", \"wav\", etc.\n@param instructions - Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n@param speed - The speed of the speech generation.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated audio data.\n */\nexport async function generateSpeech({\n  model,\n  text,\n  voice,\n  outputFormat,\n  instructions,\n  speed,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe speech model to use.\n     */\n  model: SpeechModelV1;\n\n  /**\nThe text to convert to speech.\n   */\n  text: string;\n\n  /**\nThe voice to use for speech generation.\n   */\n  voice?: string;\n\n  /**\n   * The desired output format for the audio e.g. \"mp3\", \"wav\", etc.\n   */\n  outputFormat?: 'mp3' | 'wav' | (string & {});\n\n  /**\n    Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n  */\n  instructions?: string;\n\n  /**\n  The speed of the speech generation.\n   */\n  speed?: number;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {}\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per speech model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<SpeechResult> {\n  const { retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  const result = await retry(() =>\n    model.doGenerate({\n      text,\n      voice,\n      outputFormat,\n      instructions,\n      speed,\n      abortSignal,\n      headers,\n      providerOptions,\n    }),\n  );\n\n  if (!result.audio || result.audio.length === 0) {\n    throw new NoSpeechGeneratedError({ responses: [result.response] });\n  }\n\n  return new DefaultSpeechResult({\n    audio: new DefaultGeneratedAudioFile({\n      data: result.audio,\n      mediaType:\n        detectMediaType({\n          data: result.audio,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/mp3',\n    }),\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultSpeechResult implements SpeechResult {\n  readonly audio: GeneratedAudioFile;\n  readonly warnings: Array<SpeechWarning>;\n  readonly responses: Array<SpeechModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    audio: GeneratedAudioFile;\n    warnings: Array<SpeechWarning>;\n    responses: Array<SpeechModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.audio = options.audio;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n","import {\n  LanguageModelV2,\n  LanguageModelV2Content,\n  LanguageModelV2ToolCall,\n} from '@ai-sdk/provider';\nimport { createIdGenerator, IdGenerator } from '@ai-sdk/provider-utils';\nimport { Tracer } from '@opentelemetry/api';\nimport { NoOutputSpecifiedError } from '../../src/error/no-output-specified-error';\nimport { ToolExecutionError } from '../../src/error/tool-execution-error';\nimport { asArray } from '../../src/util/as-array';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { ModelMessage } from '../prompt';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { LanguageModel, ProviderOptions, ToolChoice } from '../types';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { asContent } from './as-content';\nimport { extractContentText } from './extract-content-text';\nimport { GenerateTextResult } from './generate-text-result';\nimport { Output } from './output';\nimport { parseToolCall } from './parse-tool-call';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport { toResponseMessages } from './to-response-messages';\nimport { ToolCallArray } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair';\nimport { ToolResultArray } from './tool-result';\nimport { ToolSet } from './tool-set';\nimport { resolveLanguageModel } from '../prompt/resolve-language-model';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type GenerateTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => Promise<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamText` instead.\n\n@param model - The language model to use.\n\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n@param toolChoice - The tool choice strategy. Default: 'auto'.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param experimental_generateMessageId - Generate a unique ID for each message.\n\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n\n@returns\nA result object that contains the generated text, the results of the tool calls, and additional information.\n */\nexport async function generateText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  OUTPUT_PARTIAL = never,\n>({\n  model: modelArg,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_prepareStep,\n  prepareStep = experimental_prepareStep,\n  experimental_repairToolCall: repairToolCall,\n  _internal: {\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  onStepFinish,\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n*/\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<NoInfer<TOOLS>>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nLimits the tools that are available for the model to call without\nchanging the tool call and result types in the result.\n     */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, OUTPUT_PARTIAL>;\n\n    /**\n     * @deprecated Use `prepareStep` instead.\n     */\n    experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;\n\n    /**\n    Callback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;\n\n    /**\n     * Internal. For test use only. May change without notice.\n     */\n    _internal?: {\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): Promise<GenerateTextResult<TOOLS, OUTPUT>> {\n  const model = resolveLanguageModel(modelArg);\n  const stopConditions = asArray(stopWhen);\n  const { maxRetries, retry } = prepareRetries({ maxRetries: maxRetriesArg });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const initialPrompt = await standardizePrompt({\n    system,\n    prompt,\n    messages,\n  });\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateText',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // model:\n          'ai.model.provider': model.provider,\n          'ai.model.id': model.modelId,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      fn: async span => {\n        const callSettings = prepareCallSettings(settings);\n\n        let currentModelResponse: Awaited<\n          ReturnType<LanguageModelV2['doGenerate']>\n        > & { response: { id: string; timestamp: Date; modelId: string } };\n        let currentToolCalls: ToolCallArray<TOOLS> = [];\n        let currentToolResults: ToolResultArray<TOOLS> = [];\n        const responseMessages: Array<ResponseMessage> = [];\n        const steps: GenerateTextResult<TOOLS, OUTPUT>['steps'] = [];\n\n        do {\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps,\n            stepNumber: steps.length,\n          });\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: stepInputMessages,\n            },\n            supportedUrls: await model.supportedUrls,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          currentModelResponse = await retry(() =>\n            recordSpan({\n              name: 'ai.generateText.doGenerate',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.generateText.doGenerate',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty': settings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': settings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty': settings.presencePenalty,\n                  'gen_ai.request.stop_sequences': settings.stopSequences,\n                  'gen_ai.request.temperature':\n                    settings.temperature ?? undefined,\n                  'gen_ai.request.top_k': settings.topK,\n                  'gen_ai.request.top_p': settings.topP,\n                },\n              }),\n              tracer,\n              fn: async span => {\n                const result = await stepModel.doGenerate({\n                  ...callSettings,\n                  tools: stepTools,\n                  toolChoice: stepToolChoice,\n                  responseFormat: output?.responseFormat,\n                  prompt: promptMessages,\n                  providerOptions,\n                  abortSignal,\n                  headers,\n                });\n\n                // Fill in default values:\n                const responseData = {\n                  id: result.response?.id ?? generateId(),\n                  timestamp: result.response?.timestamp ?? currentDate(),\n                  modelId: result.response?.modelId ?? stepModel.modelId,\n                  headers: result.response?.headers,\n                  body: result.response?.body,\n                };\n\n                // Add response information to the span:\n                span.setAttributes(\n                  selectTelemetryAttributes({\n                    telemetry,\n                    attributes: {\n                      'ai.response.finishReason': result.finishReason,\n                      'ai.response.text': {\n                        output: () => extractContentText(result.content),\n                      },\n                      'ai.response.toolCalls': {\n                        output: () => {\n                          const toolCalls = asToolCalls(result.content);\n                          return toolCalls == null\n                            ? undefined\n                            : JSON.stringify(toolCalls);\n                        },\n                      },\n                      'ai.response.id': responseData.id,\n                      'ai.response.model': responseData.modelId,\n                      'ai.response.timestamp':\n                        responseData.timestamp.toISOString(),\n\n                      // TODO rename telemetry attributes to inputTokens and outputTokens\n                      'ai.usage.promptTokens': result.usage.inputTokens,\n                      'ai.usage.completionTokens': result.usage.outputTokens,\n\n                      // standardized gen-ai llm span attributes:\n                      'gen_ai.response.finish_reasons': [result.finishReason],\n                      'gen_ai.response.id': responseData.id,\n                      'gen_ai.response.model': responseData.modelId,\n                      'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                      'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                    },\n                  }),\n                );\n\n                return { ...result, response: responseData };\n              },\n            }),\n          );\n\n          // parse tool calls:\n          currentToolCalls = await Promise.all(\n            currentModelResponse.content\n              .filter(\n                (part): part is LanguageModelV2ToolCall =>\n                  part.type === 'tool-call',\n              )\n              .map(toolCall =>\n                parseToolCall({\n                  toolCall,\n                  tools,\n                  repairToolCall,\n                  system,\n                  messages: stepInputMessages,\n                }),\n              ),\n          );\n\n          // execute tools:\n          currentToolResults =\n            tools == null\n              ? []\n              : await executeTools({\n                  toolCalls: currentToolCalls,\n                  tools,\n                  tracer,\n                  telemetry,\n                  messages: stepInputMessages,\n                  abortSignal,\n                });\n\n          // content:\n          const stepContent = asContent({\n            content: currentModelResponse.content,\n            toolCalls: currentToolCalls,\n            toolResults: currentToolResults,\n          });\n\n          // append to messages for potential next step:\n          responseMessages.push(\n            ...toResponseMessages({\n              content: stepContent,\n              tools: tools ?? ({} as TOOLS),\n            }),\n          );\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: stepContent,\n            finishReason: currentModelResponse.finishReason,\n            usage: currentModelResponse.usage,\n            warnings: currentModelResponse.warnings,\n            providerMetadata: currentModelResponse.providerMetadata,\n            request: currentModelResponse.request ?? {},\n            response: {\n              ...currentModelResponse.response,\n              // deep clone msgs to avoid mutating past messages in multi-step:\n              messages: structuredClone(responseMessages),\n            },\n          });\n\n          steps.push(currentStepResult);\n          await onStepFinish?.(currentStepResult);\n        } while (\n          // there are tool calls:\n          currentToolCalls.length > 0 &&\n          // all current tool calls have results:\n          currentToolResults.length === currentToolCalls.length &&\n          // continue until a stop condition is met:\n          !(await isStopConditionMet({ stopConditions, steps }))\n        );\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': currentModelResponse.finishReason,\n              'ai.response.text': {\n                output: () => extractContentText(currentModelResponse.content),\n              },\n              'ai.response.toolCalls': {\n                output: () => {\n                  const toolCalls = asToolCalls(currentModelResponse.content);\n                  return toolCalls == null\n                    ? undefined\n                    : JSON.stringify(toolCalls);\n                },\n              },\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': currentModelResponse.usage.inputTokens,\n              'ai.usage.completionTokens':\n                currentModelResponse.usage.outputTokens,\n            },\n          }),\n        );\n\n        const lastStep = steps[steps.length - 1];\n\n        return new DefaultGenerateTextResult({\n          steps,\n          resolvedOutput: await output?.parseOutput(\n            { text: lastStep.text },\n            {\n              response: lastStep.response,\n              usage: lastStep.usage,\n              finishReason: lastStep.finishReason,\n            },\n          ),\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nasync function executeTools<TOOLS extends ToolSet>({\n  toolCalls,\n  tools,\n  tracer,\n  telemetry,\n  messages,\n  abortSignal,\n}: {\n  toolCalls: ToolCallArray<TOOLS>;\n  tools: TOOLS;\n  tracer: Tracer;\n  telemetry: TelemetrySettings | undefined;\n  messages: ModelMessage[];\n  abortSignal: AbortSignal | undefined;\n}): Promise<ToolResultArray<TOOLS>> {\n  const toolResults = await Promise.all(\n    toolCalls.map(async ({ toolCallId, toolName, args }) => {\n      const tool = tools[toolName];\n\n      if (tool?.onArgsAvailable != null) {\n        await tool.onArgsAvailable({\n          args,\n          toolCallId,\n          messages,\n          abortSignal,\n        });\n      }\n\n      if (tool?.execute == null) {\n        return undefined;\n      }\n\n      const result = await recordSpan({\n        name: 'ai.toolCall',\n        attributes: selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            ...assembleOperationName({\n              operationId: 'ai.toolCall',\n              telemetry,\n            }),\n            'ai.toolCall.name': toolName,\n            'ai.toolCall.id': toolCallId,\n            'ai.toolCall.args': {\n              output: () => JSON.stringify(args),\n            },\n          },\n        }),\n        tracer,\n        fn: async span => {\n          try {\n            const result = await tool.execute!(args, {\n              toolCallId,\n              messages,\n              abortSignal,\n            });\n\n            try {\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.toolCall.result': {\n                      output: () => JSON.stringify(result),\n                    },\n                  },\n                }),\n              );\n            } catch (ignored) {\n              // JSON stringify might fail if the result is not serializable,\n              // in which case we just ignore it. In the future we might want to\n              // add an optional serialize method to the tool interface and warn\n              // if the result is not serializable.\n            }\n\n            return result;\n          } catch (error) {\n            throw new ToolExecutionError({\n              toolCallId,\n              toolName,\n              toolArgs: args,\n              cause: error,\n            });\n          }\n        },\n      });\n\n      return {\n        type: 'tool-result',\n        toolCallId,\n        toolName,\n        args,\n        result,\n      } as ToolResultArray<TOOLS>[number];\n    }),\n  );\n\n  return toolResults.filter(\n    (result): result is NonNullable<typeof result> => result != null,\n  );\n}\n\nclass DefaultGenerateTextResult<TOOLS extends ToolSet, OUTPUT>\n  implements GenerateTextResult<TOOLS, OUTPUT>\n{\n  readonly steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n\n  private readonly resolvedOutput: OUTPUT;\n\n  constructor(options: {\n    steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n    resolvedOutput: OUTPUT;\n  }) {\n    this.steps = options.steps;\n    this.resolvedOutput = options.resolvedOutput;\n  }\n\n  private get finalStep() {\n    return this.steps[this.steps.length - 1];\n  }\n\n  get content() {\n    return this.finalStep.content;\n  }\n\n  get text() {\n    return this.finalStep.text;\n  }\n\n  get files() {\n    return this.finalStep.files;\n  }\n\n  get reasoningText() {\n    return this.finalStep.reasoningText;\n  }\n\n  get reasoning() {\n    return this.finalStep.reasoning;\n  }\n\n  get toolCalls() {\n    return this.finalStep.toolCalls;\n  }\n\n  get toolResults() {\n    return this.finalStep.toolResults;\n  }\n\n  get sources() {\n    return this.finalStep.sources;\n  }\n\n  get finishReason() {\n    return this.finalStep.finishReason;\n  }\n\n  get warnings() {\n    return this.finalStep.warnings;\n  }\n\n  get providerMetadata() {\n    return this.finalStep.providerMetadata;\n  }\n\n  get response() {\n    return this.finalStep.response;\n  }\n\n  get request() {\n    return this.finalStep.request;\n  }\n\n  get usage() {\n    return this.finalStep.usage;\n  }\n\n  get totalUsage() {\n    return this.steps.reduce(\n      (totalUsage, step) => {\n        return addLanguageModelUsage(totalUsage, step.usage);\n      },\n      {\n        inputTokens: undefined,\n        outputTokens: undefined,\n        totalTokens: undefined,\n        reasoningTokens: undefined,\n        cachedInputTokens: undefined,\n      } as LanguageModelUsage,\n    );\n  }\n\n  get experimental_output() {\n    if (this.resolvedOutput == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return this.resolvedOutput;\n  }\n}\n\nfunction asToolCalls(content: Array<LanguageModelV2Content>) {\n  const parts = content.filter(\n    (part): part is LanguageModelV2ToolCall => part.type === 'tool-call',\n  );\n\n  if (parts.length === 0) {\n    return undefined;\n  }\n\n  return parts.map(toolCall => ({\n    toolCallType: toolCall.toolCallType,\n    toolCallId: toolCall.toolCallId,\n    toolName: toolCall.toolName,\n    args: toolCall.args,\n  }));\n}\n","export function asArray<T>(value: T | T[] | undefined): T[] {\n  return value === undefined ? [] : Array.isArray(value) ? value : [value];\n}\n","import {\n  LanguageModelV2FunctionTool,\n  LanguageModelV2ProviderDefinedTool,\n  LanguageModelV2ToolChoice,\n} from '@ai-sdk/provider';\nimport { asSchema } from '@ai-sdk/provider-utils';\nimport { isNonEmptyObject } from '../../src/util/is-non-empty-object';\nimport { ToolSet } from '../generate-text';\nimport { ToolChoice } from '../types/language-model';\n\nexport function prepareToolsAndToolChoice<TOOLS extends ToolSet>({\n  tools,\n  toolChoice,\n  activeTools,\n}: {\n  tools: TOOLS | undefined;\n  toolChoice: ToolChoice<TOOLS> | undefined;\n  activeTools: Array<keyof TOOLS> | undefined;\n}): {\n  tools:\n    | Array<LanguageModelV2FunctionTool | LanguageModelV2ProviderDefinedTool>\n    | undefined;\n  toolChoice: LanguageModelV2ToolChoice | undefined;\n} {\n  if (!isNonEmptyObject(tools)) {\n    return {\n      tools: undefined,\n      toolChoice: undefined,\n    };\n  }\n\n  // when activeTools is provided, we only include the tools that are in the list:\n  const filteredTools =\n    activeTools != null\n      ? Object.entries(tools).filter(([name]) =>\n          activeTools.includes(name as keyof TOOLS),\n        )\n      : Object.entries(tools);\n\n  return {\n    tools: filteredTools.map(([name, tool]) => {\n      const toolType = tool.type;\n      switch (toolType) {\n        case undefined:\n        case 'function':\n          return {\n            type: 'function' as const,\n            name,\n            description: tool.description,\n            parameters: asSchema(tool.parameters).jsonSchema,\n          };\n        case 'provider-defined':\n          return {\n            type: 'provider-defined' as const,\n            name,\n            id: tool.id,\n            args: tool.args,\n          };\n        default: {\n          const exhaustiveCheck: never = toolType;\n          throw new Error(`Unsupported tool type: ${exhaustiveCheck}`);\n        }\n      }\n    }),\n    toolChoice:\n      toolChoice == null\n        ? { type: 'auto' }\n        : typeof toolChoice === 'string'\n          ? { type: toolChoice }\n          : { type: 'tool' as const, toolName: toolChoice.toolName as string },\n  };\n}\n","export function isNonEmptyObject(\n  object: Record<string, unknown> | undefined | null,\n): object is Record<string, unknown> {\n  return object != null && Object.keys(object).length > 0;\n}\n","import { LanguageModelV2Usage } from '@ai-sdk/provider';\n\n/**\nRepresents the number of tokens used in a prompt and completion.\n */\nexport type LanguageModelUsage = LanguageModelV2Usage;\n\n/**\nRepresents the number of tokens used in an embedding.\n */\n// TODO replace with EmbeddingModelV2Usage\nexport type EmbeddingModelUsage = {\n  /**\nThe number of tokens used in the embedding.\n   */\n  tokens: number;\n};\n\nexport function addLanguageModelUsage(\n  usage1: LanguageModelUsage,\n  usage2: LanguageModelUsage,\n): LanguageModelUsage {\n  return {\n    inputTokens: addTokenCounts(usage1.inputTokens, usage2.inputTokens),\n    outputTokens: addTokenCounts(usage1.outputTokens, usage2.outputTokens),\n    totalTokens: addTokenCounts(usage1.totalTokens, usage2.totalTokens),\n    reasoningTokens: addTokenCounts(\n      usage1.reasoningTokens,\n      usage2.reasoningTokens,\n    ),\n    cachedInputTokens: addTokenCounts(\n      usage1.cachedInputTokens,\n      usage2.cachedInputTokens,\n    ),\n  };\n}\n\nfunction addTokenCounts(\n  tokenCount1: number | undefined,\n  tokenCount2: number | undefined,\n): number | undefined {\n  return tokenCount1 == null && tokenCount2 == null\n    ? undefined\n    : (tokenCount1 ?? 0) + (tokenCount2 ?? 0);\n}\n","import { LanguageModelV2Content } from '@ai-sdk/provider';\nimport { ContentPart } from './content-part';\nimport { DefaultGeneratedFile } from './generated-file';\nimport { ToolCallArray } from './tool-call';\nimport { ToolResultArray } from './tool-result';\nimport { ToolSet } from './tool-set';\n\nexport function asContent<TOOLS extends ToolSet>({\n  content,\n  toolCalls,\n  toolResults,\n}: {\n  content: Array<LanguageModelV2Content>;\n  toolCalls: ToolCallArray<TOOLS>;\n  toolResults: ToolResultArray<TOOLS>;\n}): Array<ContentPart<TOOLS>> {\n  return [\n    ...content.map(part => {\n      switch (part.type) {\n        case 'text':\n        case 'reasoning':\n        case 'source':\n          return part;\n\n        case 'file': {\n          return {\n            type: 'file' as const,\n            file: new DefaultGeneratedFile(part),\n          };\n        }\n\n        case 'tool-call': {\n          return toolCalls.find(\n            toolCall => toolCall.toolCallId === part.toolCallId,\n          )!;\n        }\n      }\n    }),\n    ...toolResults,\n  ];\n}\n","import { LanguageModelV2ToolCall } from '@ai-sdk/provider';\nimport {\n  asSchema,\n  safeParseJSON,\n  safeValidateTypes,\n} from '@ai-sdk/provider-utils';\nimport { InvalidToolArgumentsError } from '../../src/error/invalid-tool-arguments-error';\nimport { NoSuchToolError } from '../../src/error/no-such-tool-error';\nimport { ToolCallRepairError } from '../../src/error/tool-call-repair-error';\nimport { ModelMessage } from '../prompt';\nimport { ToolCallUnion } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair';\nimport { ToolSet } from './tool-set';\n\nexport async function parseToolCall<TOOLS extends ToolSet>({\n  toolCall,\n  tools,\n  repairToolCall,\n  system,\n  messages,\n}: {\n  toolCall: LanguageModelV2ToolCall;\n  tools: TOOLS | undefined;\n  repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n  system: string | undefined;\n  messages: ModelMessage[];\n}): Promise<ToolCallUnion<TOOLS>> {\n  if (tools == null) {\n    throw new NoSuchToolError({ toolName: toolCall.toolName });\n  }\n\n  try {\n    return await doParseToolCall({ toolCall, tools });\n  } catch (error) {\n    if (\n      repairToolCall == null ||\n      !(\n        NoSuchToolError.isInstance(error) ||\n        InvalidToolArgumentsError.isInstance(error)\n      )\n    ) {\n      throw error;\n    }\n\n    let repairedToolCall: LanguageModelV2ToolCall | null = null;\n\n    try {\n      repairedToolCall = await repairToolCall({\n        toolCall,\n        tools,\n        parameterSchema: ({ toolName }) => {\n          const { parameters } = tools[toolName];\n          return asSchema(parameters).jsonSchema;\n        },\n        system,\n        messages,\n        error,\n      });\n    } catch (repairError) {\n      throw new ToolCallRepairError({\n        cause: repairError,\n        originalError: error,\n      });\n    }\n\n    // no repaired tool call returned\n    if (repairedToolCall == null) {\n      throw error;\n    }\n\n    return await doParseToolCall({ toolCall: repairedToolCall, tools });\n  }\n}\n\nasync function doParseToolCall<TOOLS extends ToolSet>({\n  toolCall,\n  tools,\n}: {\n  toolCall: LanguageModelV2ToolCall;\n  tools: TOOLS;\n}): Promise<ToolCallUnion<TOOLS>> {\n  const toolName = toolCall.toolName as keyof TOOLS & string;\n\n  const tool = tools[toolName];\n\n  if (tool == null) {\n    throw new NoSuchToolError({\n      toolName: toolCall.toolName,\n      availableTools: Object.keys(tools),\n    });\n  }\n\n  const schema = asSchema(tool.parameters);\n\n  // when the tool call has no arguments, we try passing an empty object to the schema\n  // (many LLMs generate empty strings for tool calls with no arguments)\n  const parseResult =\n    toolCall.args.trim() === ''\n      ? await safeValidateTypes({ value: {}, schema })\n      : await safeParseJSON({ text: toolCall.args, schema });\n\n  if (parseResult.success === false) {\n    throw new InvalidToolArgumentsError({\n      toolName,\n      toolArgs: toolCall.args,\n      cause: parseResult.error,\n    });\n  }\n\n  return {\n    type: 'tool-call',\n    toolCallId: toolCall.toolCallId,\n    toolName,\n    args: parseResult?.value,\n  };\n}\n","import { ReasoningPart } from '../prompt/content-part';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModelRequestMetadata,\n  LanguageModelResponseMetadata,\n  ProviderMetadata,\n} from '../types';\nimport { Source } from '../types/language-model';\nimport { LanguageModelUsage } from '../types/usage';\nimport { ContentPart } from './content-part';\nimport { GeneratedFile } from './generated-file';\nimport { ResponseMessage } from './response-message';\nimport { ToolCallArray } from './tool-call';\nimport { ToolResultArray } from './tool-result';\nimport { ToolSet } from './tool-set';\n\n/**\n * The result of a single step in the generation process.\n */\nexport type StepResult<TOOLS extends ToolSet> = {\n  /**\nThe content that was generated in the last step.\n   */\n  readonly content: Array<ContentPart<TOOLS>>;\n\n  /**\nThe generated text.\n*/\n  readonly text: string;\n\n  /**\nThe reasoning that was generated during the generation.\n*/\n  readonly reasoning: Array<ReasoningPart>;\n\n  /**\nThe reasoning text that was generated during the generation.\n*/\n  readonly reasoningText: string | undefined;\n\n  /**\nThe files that were generated during the generation.\n*/\n  readonly files: Array<GeneratedFile>;\n\n  /**\nThe sources that were used to generate the text.\n*/\n  readonly sources: Array<Source>;\n\n  /**\nThe tool calls that were made during the generation.\n*/\n  readonly toolCalls: ToolCallArray<TOOLS>;\n\n  /**\nThe results of the tool calls.\n*/\n  readonly toolResults: ToolResultArray<TOOLS>;\n\n  /**\nThe reason why the generation finished.\n*/\n  readonly finishReason: FinishReason;\n\n  /**\nThe token usage of the generated text.\n*/\n  readonly usage: LanguageModelUsage;\n\n  /**\nWarnings from the model provider (e.g. unsupported settings).\n*/\n  readonly warnings: CallWarning[] | undefined;\n\n  /**\nAdditional request information.\n   */\n  readonly request: LanguageModelRequestMetadata;\n\n  /**\nAdditional response information.\n*/\n  readonly response: LanguageModelResponseMetadata & {\n    /**\nThe response messages that were generated during the call.\nResponse messages can be either assistant messages or tool messages.\nThey contain a generated id.\n*/\n    readonly messages: Array<ResponseMessage>;\n\n    /**\nResponse body (available only for providers that use HTTP requests).\n     */\n    body?: unknown;\n  };\n\n  /**\nAdditional provider-specific metadata. They are passed through\nfrom the provider to the AI SDK and enable provider-specific\nresults that can be fully encapsulated in the provider.\n   */\n  readonly providerMetadata: ProviderMetadata | undefined;\n};\n\nexport class DefaultStepResult<TOOLS extends ToolSet>\n  implements StepResult<TOOLS>\n{\n  readonly content: StepResult<TOOLS>['content'];\n  readonly finishReason: StepResult<TOOLS>['finishReason'];\n  readonly usage: StepResult<TOOLS>['usage'];\n  readonly warnings: StepResult<TOOLS>['warnings'];\n  readonly request: StepResult<TOOLS>['request'];\n  readonly response: StepResult<TOOLS>['response'];\n  readonly providerMetadata: StepResult<TOOLS>['providerMetadata'];\n\n  constructor({\n    content,\n    finishReason,\n    usage,\n    warnings,\n    request,\n    response,\n    providerMetadata,\n  }: {\n    content: StepResult<TOOLS>['content'];\n    finishReason: StepResult<TOOLS>['finishReason'];\n    usage: StepResult<TOOLS>['usage'];\n    warnings: StepResult<TOOLS>['warnings'];\n    request: StepResult<TOOLS>['request'];\n    response: StepResult<TOOLS>['response'];\n    providerMetadata: StepResult<TOOLS>['providerMetadata'];\n  }) {\n    this.content = content;\n    this.finishReason = finishReason;\n    this.usage = usage;\n    this.warnings = warnings;\n    this.request = request;\n    this.response = response;\n    this.providerMetadata = providerMetadata;\n  }\n\n  get text() {\n    return this.content\n      .filter(part => part.type === 'text')\n      .map(part => part.text)\n      .join('');\n  }\n\n  get reasoning() {\n    return this.content.filter(part => part.type === 'reasoning');\n  }\n\n  get reasoningText() {\n    return this.reasoning.length === 0\n      ? undefined\n      : this.reasoning.map(part => part.text).join('');\n  }\n\n  get files() {\n    return this.content\n      .filter(part => part.type === 'file')\n      .map(part => part.file);\n  }\n\n  get sources() {\n    return this.content.filter(part => part.type === 'source');\n  }\n\n  get toolCalls() {\n    return this.content.filter(part => part.type === 'tool-call');\n  }\n\n  get toolResults() {\n    return this.content.filter(part => part.type === 'tool-result');\n  }\n}\n","import { StepResult } from './step-result';\nimport { ToolSet } from './tool-set';\n\nexport type StopCondition<TOOLS extends ToolSet> = (options: {\n  steps: Array<StepResult<TOOLS>>;\n}) => PromiseLike<boolean> | boolean;\n\nexport function stepCountIs(stepCount: number): StopCondition<any> {\n  return ({ steps }) => steps.length === stepCount;\n}\n\nexport function hasToolCall(toolName: string): StopCondition<any> {\n  return ({ steps }) =>\n    steps[steps.length - 1]?.toolCalls?.some(\n      toolCall => toolCall.toolName === toolName,\n    ) ?? false;\n}\n\nexport async function isStopConditionMet<TOOLS extends ToolSet>({\n  stopConditions,\n  steps,\n}: {\n  stopConditions: Array<StopCondition<TOOLS>>;\n  steps: Array<StepResult<TOOLS>>;\n}): Promise<boolean> {\n  return (\n    await Promise.all(stopConditions.map(condition => condition({ steps })))\n  ).some(result => result);\n}\n","import {\n  AssistantContent,\n  AssistantModelMessage,\n  ToolContent,\n  ToolModelMessage,\n  ToolResultPart,\n} from '../prompt';\nimport { ContentPart } from './content-part';\nimport { ToolSet } from './tool-set';\n\n/**\nConverts the result of a `generateText` or `streamText` call to a list of response messages.\n */\nexport function toResponseMessages<TOOLS extends ToolSet>({\n  content: inputContent,\n  tools,\n}: {\n  content: Array<ContentPart<TOOLS>>;\n  tools: TOOLS;\n}): Array<AssistantModelMessage | ToolModelMessage> {\n  const responseMessages: Array<AssistantModelMessage | ToolModelMessage> = [];\n\n  const content: AssistantContent = inputContent\n    .filter(part => part.type !== 'tool-result' && part.type !== 'source')\n    .filter(part => part.type !== 'text' || part.text.length > 0)\n    .map(part => {\n      switch (part.type) {\n        case 'text':\n          return part;\n        case 'reasoning':\n          return {\n            type: 'reasoning' as const,\n            text: part.text,\n            providerOptions: part.providerMetadata,\n          };\n        case 'file':\n          return {\n            type: 'file' as const,\n            data: part.file.base64,\n            mediaType: part.file.mediaType,\n          };\n        case 'tool-call':\n          return part;\n      }\n    });\n\n  if (content.length > 0) {\n    responseMessages.push({\n      role: 'assistant',\n      content,\n    });\n  }\n\n  const toolResultContent: ToolContent = inputContent\n    .filter(part => part.type === 'tool-result')\n    .map((toolResult): ToolResultPart => {\n      const tool = tools[toolResult.toolName];\n      return tool?.experimental_toToolResultContent != null\n        ? {\n            type: 'tool-result',\n            toolCallId: toolResult.toolCallId,\n            toolName: toolResult.toolName,\n            result: tool.experimental_toToolResultContent(toolResult.result),\n            experimental_content: tool.experimental_toToolResultContent(\n              toolResult.result,\n            ),\n          }\n        : {\n            type: 'tool-result',\n            toolCallId: toolResult.toolCallId,\n            toolName: toolResult.toolName,\n            result: toolResult.result,\n          };\n    });\n\n  if (toolResultContent.length > 0) {\n    responseMessages.push({\n      role: 'tool',\n      content: toolResultContent,\n    });\n  }\n\n  return responseMessages;\n}\n","import { LanguageModelV2CallOptions } from '@ai-sdk/provider';\nimport {\n  asSchema,\n  safeParseJSON,\n  safeValidateTypes,\n  Schema,\n} from '@ai-sdk/provider-utils';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { NoObjectGeneratedError } from '../../src/error/no-object-generated-error';\nimport { DeepPartial } from '../../src/util/deep-partial';\nimport { parsePartialJson } from '../../src/util/parse-partial-json';\nimport { FinishReason } from '../types/language-model';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../types/usage';\n\nexport interface Output<OUTPUT, PARTIAL> {\n  readonly type: 'object' | 'text';\n\n  responseFormat: LanguageModelV2CallOptions['responseFormat'];\n\n  parsePartial(options: {\n    text: string;\n  }): Promise<{ partial: PARTIAL } | undefined>;\n\n  parseOutput(\n    options: { text: string },\n    context: {\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n      finishReason: FinishReason;\n    },\n  ): Promise<OUTPUT>;\n}\n\nexport const text = (): Output<string, string> => ({\n  type: 'text',\n\n  responseFormat: { type: 'text' },\n\n  async parsePartial({ text }: { text: string }) {\n    return { partial: text };\n  },\n\n  async parseOutput({ text }: { text: string }) {\n    return text;\n  },\n});\n\nexport const object = <OUTPUT>({\n  schema: inputSchema,\n}: {\n  schema:\n    | z4.$ZodType<OUTPUT, any>\n    | z3.Schema<OUTPUT, z3.ZodTypeDef, any>\n    | Schema<OUTPUT>;\n}): Output<OUTPUT, DeepPartial<OUTPUT>> => {\n  const schema = asSchema(inputSchema);\n\n  return {\n    type: 'object',\n\n    responseFormat: {\n      type: 'json',\n      schema: schema.jsonSchema,\n    },\n\n    async parsePartial({ text }: { text: string }) {\n      const result = await parsePartialJson(text);\n\n      switch (result.state) {\n        case 'failed-parse':\n        case 'undefined-input':\n          return undefined;\n\n        case 'repaired-parse':\n        case 'successful-parse':\n          return {\n            // Note: currently no validation of partial results:\n            partial: result.value as DeepPartial<OUTPUT>,\n          };\n\n        default: {\n          const _exhaustiveCheck: never = result.state;\n          throw new Error(`Unsupported parse state: ${_exhaustiveCheck}`);\n        }\n      }\n    },\n\n    async parseOutput(\n      { text }: { text: string },\n      context: {\n        response: LanguageModelResponseMetadata;\n        usage: LanguageModelUsage;\n        finishReason: FinishReason;\n      },\n    ) {\n      const parseResult = await safeParseJSON({ text });\n\n      if (!parseResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: could not parse the response.',\n          cause: parseResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      const validationResult = await safeValidateTypes({\n        value: parseResult.value,\n        schema,\n      });\n\n      if (!validationResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: response did not match schema.',\n          cause: validationResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      return validationResult.value;\n    },\n  };\n};\n","import { delay as originalDelay } from '@ai-sdk/provider-utils';\nimport { TextStreamPart } from './stream-text-result';\nimport { ToolSet } from './tool-set';\nimport { InvalidArgumentError } from '@ai-sdk/provider';\n\nconst CHUNKING_REGEXPS = {\n  word: /\\S+\\s+/m,\n  line: /\\n+/m,\n};\n\n/**\n * Detects the first chunk in a buffer.\n *\n * @param buffer - The buffer to detect the first chunk in.\n *\n * @returns The first detected chunk, or `undefined` if no chunk was detected.\n */\nexport type ChunkDetector = (buffer: string) => string | undefined | null;\n\n/**\n * Smooths text streaming output.\n *\n * @param delayInMs - The delay in milliseconds between each chunk. Defaults to 10ms. Can be set to `null` to skip the delay.\n * @param chunking - Controls how the text is chunked for streaming. Use \"word\" to stream word by word (default), \"line\" to stream line by line, or provide a custom RegExp pattern for custom chunking.\n *\n * @returns A transform stream that smooths text streaming output.\n */\nexport function smoothStream<TOOLS extends ToolSet>({\n  delayInMs = 10,\n  chunking = 'word',\n  _internal: { delay = originalDelay } = {},\n}: {\n  delayInMs?: number | null;\n  chunking?: 'word' | 'line' | RegExp | ChunkDetector;\n  /**\n   * Internal. For test use only. May change without notice.\n   */\n  _internal?: {\n    delay?: (delayInMs: number | null) => Promise<void>;\n  };\n} = {}): (options: {\n  tools: TOOLS;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>> {\n  let detectChunk: ChunkDetector;\n\n  if (typeof chunking === 'function') {\n    detectChunk = buffer => {\n      const match = chunking(buffer);\n\n      if (match == null) {\n        return null;\n      }\n\n      if (!match.length) {\n        throw new Error(`Chunking function must return a non-empty string.`);\n      }\n\n      if (!buffer.startsWith(match)) {\n        throw new Error(\n          `Chunking function must return a match that is a prefix of the buffer. Received: \"${match}\" expected to start with \"${buffer}\"`,\n        );\n      }\n\n      return match;\n    };\n  } else {\n    const chunkingRegex =\n      typeof chunking === 'string' ? CHUNKING_REGEXPS[chunking] : chunking;\n\n    if (chunkingRegex == null) {\n      throw new InvalidArgumentError({\n        argument: 'chunking',\n        message: `Chunking must be \"word\" or \"line\" or a RegExp. Received: ${chunking}`,\n      });\n    }\n\n    detectChunk = buffer => {\n      const match = chunkingRegex.exec(buffer);\n\n      if (!match) {\n        return null;\n      }\n\n      return buffer.slice(0, match.index) + match?.[0];\n    };\n  }\n\n  return () => {\n    let buffer = '';\n\n    return new TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>({\n      async transform(chunk, controller) {\n        if (chunk.type !== 'text') {\n          if (buffer.length > 0) {\n            controller.enqueue({ type: 'text', text: buffer });\n            buffer = '';\n          }\n\n          controller.enqueue(chunk);\n          return;\n        }\n\n        buffer += chunk.text;\n\n        let match;\n\n        while ((match = detectChunk(buffer)) != null) {\n          controller.enqueue({ type: 'text', text: match });\n          buffer = buffer.slice(match.length);\n\n          await delay(delayInMs);\n        }\n      },\n    });\n  };\n}\n","import { LanguageModelV2, LanguageModelV2CallWarning } from '@ai-sdk/provider';\nimport { createIdGenerator, IdGenerator } from '@ai-sdk/provider-utils';\nimport { Span } from '@opentelemetry/api';\nimport { ServerResponse } from 'node:http';\nimport { NoOutputSpecifiedError } from '../../src/error/no-output-specified-error';\nimport { createTextStreamResponse } from '../../src/text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../../src/text-stream/pipe-text-stream-to-response';\nimport { UIDataTypes, UIMessage } from '../../src/ui';\nimport { createUIMessageStreamResponse } from '../../src/ui-message-stream/create-ui-message-stream-response';\nimport { handleUIMessageStreamFinish } from '../../src/ui-message-stream/handle-ui-message-stream-finish';\nimport { pipeUIMessageStreamToResponse } from '../../src/ui-message-stream/pipe-ui-message-stream-to-response';\nimport {\n  InferUIMessageStreamPart,\n  UIMessageStreamPart,\n} from '../../src/ui-message-stream/ui-message-stream-parts';\nimport { InferUIMessageMetadata } from '../../src/ui/ui-messages';\nimport { asArray } from '../../src/util/as-array';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../../src/util/async-iterable-stream';\nimport { consumeStream } from '../../src/util/consume-stream';\nimport { createStitchableStream } from '../../src/util/create-stitchable-stream';\nimport { DelayedPromise } from '../../src/util/delayed-promise';\nimport { now as originalNow } from '../../src/util/now';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { resolveLanguageModel } from '../prompt/resolve-language-model';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { LanguageModelRequestMetadata } from '../types';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n  ToolChoice,\n} from '../types/language-model';\nimport { ProviderMetadata, ProviderOptions } from '../types/provider-metadata';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { ContentPart } from './content-part';\nimport { Output } from './output';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport {\n  runToolsTransformation,\n  SingleRequestTextStreamPart,\n} from './run-tools-transformation';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport {\n  ConsumeStreamOptions,\n  StreamTextResult,\n  TextStreamPart,\n  UIMessageStreamOptions,\n} from './stream-text-result';\nimport { toResponseMessages } from './to-response-messages';\nimport { ToolCallUnion } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair';\nimport { ToolResultUnion } from './tool-result';\nimport { ToolSet } from './tool-set';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nA transformation that is applied to the stream.\n\n@param stopStream - A function that stops the source stream.\n@param tools - The tools that are accessible to and can be called by the model. The model needs to support calling tools.\n */\nexport type StreamTextTransform<TOOLS extends ToolSet> = (options: {\n  tools: TOOLS; // for type inference\n  stopStream: () => void;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>;\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnErrorCallback = (event: {\n  error: unknown;\n}) => Promise<void> | void;\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type StreamTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => Promise<void> | void;\n\n/**\nCallback that is set using the `onChunk` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnChunkCallback<TOOLS extends ToolSet> = (event: {\n  chunk: Extract<\n    TextStreamPart<TOOLS>,\n    {\n      type:\n        | 'text'\n        | 'reasoning'\n        | 'source'\n        | 'tool-call'\n        | 'tool-call-streaming-start'\n        | 'tool-call-delta'\n        | 'tool-result';\n    }\n  >;\n}) => Promise<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnFinishCallback<TOOLS extends ToolSet> = (\n  event: StepResult<TOOLS> & {\n    /**\nDetails for all steps.\n   */\n    readonly steps: StepResult<TOOLS>[];\n\n    /**\nTotal usage for all steps. This is the sum of the usage of all steps.\n     */\n    readonly totalUsage: LanguageModelUsage;\n  },\n) => Promise<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateText` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param maxSteps - Maximum number of sequential LLM calls (steps), e.g. when you use tool calls.\n\n@param onChunk - Callback that is called for each chunk of the stream. The stream processing will pause until the callback promise is resolved.\n@param onError - Callback that is called when an error occurs during streaming. You can use it to log errors.\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n@param onFinish - Callback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\n@return\nA result object for accessing different stream types and additional information.\n */\nexport function streamText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  PARTIAL_OUTPUT = never,\n>({\n  model,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  prepareStep,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_repairToolCall: repairToolCall,\n  experimental_transform: transform,\n  includeRawChunks = false,\n  onChunk,\n  onError = ({ error }) => {\n    console.error(error);\n  },\n  onFinish,\n  onStepFinish,\n  _internal: {\n    now = originalNow,\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n    */\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<TOOLS>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\n   Limits the tools that are available for the model to call without\n   changing the tool call and result types in the result.\n        */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, PARTIAL_OUTPUT>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n\n@param options - The options for the step.\n@param options.steps - The steps that have been executed so far.\n@param options.stepNumber - The number of the step that is being executed.\n@param options.model - The model that is being used.\n\n@returns An object that contains the settings for the step.\nIf you return undefined (or for undefined settings), the settings from the outer level will be used.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<TOOLS>;\n\n    /**\nOptional stream transformations.\nThey are applied in the order they are provided.\nThe stream transformations must maintain the stream structure for streamText to work correctly.\n     */\n    experimental_transform?:\n      | StreamTextTransform<TOOLS>\n      | Array<StreamTextTransform<TOOLS>>;\n\n    /**\nWhether to include raw chunks from the provider in the stream.\nWhen enabled, you will receive raw chunks with type 'raw' that contain the unprocessed data from the provider.\nThis allows access to cutting-edge provider features not yet wrapped by the AI SDK.\nDefaults to false.\n     */\n    includeRawChunks?: boolean;\n\n    /**\nCallback that is called for each chunk of the stream.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onChunk?: StreamTextOnChunkCallback<TOOLS>;\n\n    /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onError?: StreamTextOnErrorCallback;\n\n    /**\nCallback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\nThe usage is the combined usage of all steps.\n     */\n    onFinish?: StreamTextOnFinishCallback<TOOLS>;\n\n    /**\nCallback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: StreamTextOnStepFinishCallback<TOOLS>;\n\n    /**\nInternal. For test use only. May change without notice.\n     */\n    _internal?: {\n      now?: () => number;\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): StreamTextResult<TOOLS, PARTIAL_OUTPUT> {\n  return new DefaultStreamTextResult<TOOLS, OUTPUT, PARTIAL_OUTPUT>({\n    model: resolveLanguageModel(model),\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms: asArray(transform),\n    activeTools,\n    repairToolCall,\n    stopConditions: asArray(stopWhen),\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    onChunk,\n    onError,\n    onFinish,\n    onStepFinish,\n    now,\n    currentDate,\n    generateId,\n  });\n}\n\ntype EnrichedStreamPart<TOOLS extends ToolSet, PARTIAL_OUTPUT> = {\n  part: TextStreamPart<TOOLS>;\n  partialOutput: PARTIAL_OUTPUT | undefined;\n};\n\nfunction createOutputTransformStream<\n  TOOLS extends ToolSet,\n  OUTPUT,\n  PARTIAL_OUTPUT,\n>(\n  output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined,\n): TransformStream<\n  TextStreamPart<TOOLS>,\n  EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n> {\n  if (!output) {\n    return new TransformStream<\n      TextStreamPart<TOOLS>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n      },\n    });\n  }\n\n  let text = '';\n  let textChunk = '';\n  let lastPublishedJson = '';\n\n  function publishTextChunk({\n    controller,\n    partialOutput = undefined,\n  }: {\n    controller: TransformStreamDefaultController<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >;\n    partialOutput?: PARTIAL_OUTPUT;\n  }) {\n    controller.enqueue({\n      part: { type: 'text', text: textChunk },\n      partialOutput,\n    });\n    textChunk = '';\n  }\n\n  return new TransformStream<\n    TextStreamPart<TOOLS>,\n    EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n  >({\n    async transform(chunk, controller) {\n      // ensure that we publish the last text chunk before the step finish:\n      if (chunk.type === 'finish-step') {\n        publishTextChunk({ controller });\n      }\n\n      if (chunk.type !== 'text') {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      text += chunk.text;\n      textChunk += chunk.text;\n\n      // only publish if partial json can be parsed:\n      const result = await output.parsePartial({ text });\n      if (result != null) {\n        // only send new json if it has changed:\n        const currentJson = JSON.stringify(result.partial);\n        if (currentJson !== lastPublishedJson) {\n          publishTextChunk({ controller, partialOutput: result.partial });\n          lastPublishedJson = currentJson;\n        }\n      }\n    },\n\n    flush(controller) {\n      // publish remaining text (there should be none if the content was correctly formatted):\n      if (textChunk.length > 0) {\n        publishTextChunk({ controller });\n      }\n    },\n  });\n}\n\nclass DefaultStreamTextResult<TOOLS extends ToolSet, OUTPUT, PARTIAL_OUTPUT>\n  implements StreamTextResult<TOOLS, PARTIAL_OUTPUT>\n{\n  private readonly _totalUsage = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['usage']>\n  >();\n  private readonly _finishReason = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['finishReason']>\n  >();\n  private readonly _steps = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['steps']>\n  >();\n\n  private readonly addStream: (\n    stream: ReadableStream<TextStreamPart<TOOLS>>,\n  ) => void;\n\n  private readonly closeStream: () => void;\n\n  private baseStream: ReadableStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>>;\n\n  private output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n\n  private includeRawChunks: boolean;\n\n  private generateId: () => string;\n\n  constructor({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms,\n    activeTools,\n    repairToolCall,\n    stopConditions,\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    now,\n    currentDate,\n    generateId,\n    onChunk,\n    onError,\n    onFinish,\n    onStepFinish,\n  }: {\n    model: LanguageModelV2;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    tools: TOOLS | undefined;\n    toolChoice: ToolChoice<TOOLS> | undefined;\n    transforms: Array<StreamTextTransform<TOOLS>>;\n    activeTools: Array<keyof TOOLS> | undefined;\n    repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n    stopConditions: Array<StopCondition<NoInfer<TOOLS>>>;\n    output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n    providerOptions: ProviderOptions | undefined;\n    prepareStep: PrepareStepFunction<NoInfer<TOOLS>> | undefined;\n    includeRawChunks: boolean;\n    now: () => number;\n    currentDate: () => Date;\n    generateId: () => string;\n\n    // callbacks:\n    onChunk: undefined | StreamTextOnChunkCallback<TOOLS>;\n    onError: StreamTextOnErrorCallback;\n    onFinish: undefined | StreamTextOnFinishCallback<TOOLS>;\n    onStepFinish: undefined | StreamTextOnStepFinishCallback<TOOLS>;\n  }) {\n    this.output = output;\n    this.includeRawChunks = includeRawChunks;\n    this.generateId = generateId;\n\n    // promise to ensure that the step has been fully processed by the event processor\n    // before a new step is started. This is required because the continuation condition\n    // needs the updated steps to determine if another step is needed.\n    let stepFinish!: DelayedPromise<void>;\n\n    let activeReasoningPart:\n      | undefined\n      | (ContentPart<TOOLS> & { type: 'reasoning' }) = undefined;\n\n    let recordedContent: Array<ContentPart<TOOLS>> = [];\n    const recordedResponseMessages: Array<ResponseMessage> = [];\n    let recordedFinishReason: FinishReason | undefined = undefined;\n    let recordedTotalUsage: LanguageModelUsage | undefined = undefined;\n    let recordedRequest: LanguageModelRequestMetadata = {};\n    let recordedWarnings: Array<CallWarning> = [];\n    const recordedSteps: StepResult<TOOLS>[] = [];\n\n    let rootSpan!: Span;\n\n    const eventProcessor = new TransformStream<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      async transform(chunk, controller) {\n        controller.enqueue(chunk); // forward the chunk to the next stream\n\n        const { part } = chunk;\n\n        if (\n          part.type === 'text' ||\n          part.type === 'reasoning' ||\n          part.type === 'source' ||\n          part.type === 'tool-call' ||\n          part.type === 'tool-result' ||\n          part.type === 'tool-call-streaming-start' ||\n          part.type === 'tool-call-delta'\n        ) {\n          await onChunk?.({ chunk: part });\n        }\n\n        if (part.type === 'error') {\n          await onError({ error: wrapGatewayError(part.error) });\n        }\n\n        if (part.type === 'text') {\n          const latestContent = recordedContent[recordedContent.length - 1];\n          if (latestContent?.type === 'text') {\n            latestContent.text += part.text;\n          } else {\n            recordedContent.push({ type: 'text', text: part.text });\n          }\n        }\n\n        if (part.type === 'reasoning') {\n          if (activeReasoningPart == null) {\n            activeReasoningPart = {\n              type: 'reasoning',\n              text: part.text,\n              providerMetadata: part.providerMetadata,\n            };\n            recordedContent.push(activeReasoningPart);\n          } else {\n            activeReasoningPart.text += part.text;\n            activeReasoningPart.providerMetadata = part.providerMetadata;\n          }\n        }\n\n        if (\n          part.type === 'reasoning-part-finish' &&\n          activeReasoningPart != null\n        ) {\n          activeReasoningPart = undefined;\n        }\n\n        if (part.type === 'file') {\n          recordedContent.push({ type: 'file', file: part.file });\n        }\n\n        if (part.type === 'source') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-call') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-result') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'start-step') {\n          recordedRequest = part.request;\n          recordedWarnings = part.warnings;\n        }\n\n        if (part.type === 'finish-step') {\n          const stepMessages = toResponseMessages({\n            content: recordedContent,\n            tools: tools ?? ({} as TOOLS),\n          });\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: recordedContent,\n            finishReason: part.finishReason,\n            usage: part.usage,\n            warnings: recordedWarnings,\n            request: recordedRequest,\n            response: {\n              ...part.response,\n              messages: [...recordedResponseMessages, ...stepMessages],\n            },\n            providerMetadata: part.providerMetadata,\n          });\n\n          await onStepFinish?.(currentStepResult);\n\n          recordedSteps.push(currentStepResult);\n\n          recordedContent = [];\n          activeReasoningPart = undefined;\n\n          recordedResponseMessages.push(...stepMessages);\n\n          // resolve the promise to signal that the step has been fully processed\n          // by the event processor:\n          stepFinish.resolve();\n        }\n\n        if (part.type === 'finish') {\n          recordedTotalUsage = part.totalUsage;\n          recordedFinishReason = part.finishReason;\n        }\n      },\n\n      async flush(controller) {\n        try {\n          if (recordedSteps.length === 0) {\n            return; // no steps recorded (e.g. in error scenario)\n          }\n\n          // derived:\n          const finishReason = recordedFinishReason ?? 'unknown';\n          const totalUsage = recordedTotalUsage ?? {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n\n          // from finish:\n          self._finishReason.resolve(finishReason);\n          self._totalUsage.resolve(totalUsage);\n\n          // aggregate results:\n          self._steps.resolve(recordedSteps);\n\n          // call onFinish callback:\n          const finalStep = recordedSteps[recordedSteps.length - 1];\n          await onFinish?.({\n            finishReason,\n            totalUsage,\n            usage: finalStep.usage,\n            content: finalStep.content,\n            text: finalStep.text,\n            reasoningText: finalStep.reasoningText,\n            reasoning: finalStep.reasoning,\n            files: finalStep.files,\n            sources: finalStep.sources,\n            toolCalls: finalStep.toolCalls,\n            toolResults: finalStep.toolResults,\n            request: finalStep.request,\n            response: finalStep.response,\n            warnings: finalStep.warnings,\n            providerMetadata: finalStep.providerMetadata,\n            steps: recordedSteps,\n          });\n\n          // Add response information to the root span:\n          rootSpan.setAttributes(\n            selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                'ai.response.finishReason': finishReason,\n                'ai.response.text': { output: () => finalStep.text },\n                'ai.response.toolCalls': {\n                  output: () =>\n                    finalStep.toolCalls?.length\n                      ? JSON.stringify(finalStep.toolCalls)\n                      : undefined,\n                },\n\n                'ai.usage.inputTokens': totalUsage.inputTokens,\n                'ai.usage.outputTokens': totalUsage.outputTokens,\n                'ai.usage.totalTokens': totalUsage.totalTokens,\n                'ai.usage.reasoningTokens': totalUsage.reasoningTokens,\n                'ai.usage.cachedInputTokens': totalUsage.cachedInputTokens,\n              },\n            }),\n          );\n        } catch (error) {\n          controller.error(error);\n        } finally {\n          rootSpan.end();\n        }\n      },\n    });\n\n    // initialize the stitchable stream and the transformed stream:\n    const stitchableStream = createStitchableStream<TextStreamPart<TOOLS>>();\n    this.addStream = stitchableStream.addStream;\n    this.closeStream = stitchableStream.close;\n\n    let stream = stitchableStream.stream;\n\n    // add a stream that emits a start event:\n    stream = stream.pipeThrough(\n      new TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>({\n        start(controller) {\n          controller.enqueue({ type: 'start' });\n        },\n      }),\n    );\n\n    // transform the stream before output parsing\n    // to enable replacement of stream segments:\n    for (const transform of transforms) {\n      stream = stream.pipeThrough(\n        transform({\n          tools: tools as TOOLS,\n          stopStream() {\n            stitchableStream.terminate();\n          },\n        }),\n      );\n    }\n\n    this.baseStream = stream\n      .pipeThrough(createOutputTransformStream(output))\n      .pipeThrough(eventProcessor);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n    });\n\n    const tracer = getTracer(telemetry);\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const self = this;\n\n    recordSpan({\n      name: 'ai.streamText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({ operationId: 'ai.streamText', telemetry }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpanArg => {\n        rootSpan = rootSpanArg;\n\n        async function streamStep({\n          currentStep,\n          responseMessages,\n          usage,\n        }: {\n          currentStep: number;\n          responseMessages: Array<ResponseMessage>;\n          usage: LanguageModelUsage;\n        }) {\n          const includeRawChunks = self.includeRawChunks;\n\n          stepFinish = new DelayedPromise<void>();\n\n          const initialPrompt = await standardizePrompt({\n            system,\n            prompt,\n            messages,\n          });\n\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps: recordedSteps,\n            stepNumber: recordedSteps.length,\n          });\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: stepInputMessages,\n            },\n            supportedUrls: await model.supportedUrls,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          const {\n            result: { stream, response, request },\n            doStreamSpan,\n            startTimestampMs,\n          } = await retry(() =>\n            recordSpan({\n              name: 'ai.streamText.doStream',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.streamText.doStream',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty':\n                    callSettings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty':\n                    callSettings.presencePenalty,\n                  'gen_ai.request.stop_sequences': callSettings.stopSequences,\n                  'gen_ai.request.temperature': callSettings.temperature,\n                  'gen_ai.request.top_k': callSettings.topK,\n                  'gen_ai.request.top_p': callSettings.topP,\n                },\n              }),\n              tracer,\n              endWhenDone: false,\n              fn: async doStreamSpan => {\n                return {\n                  startTimestampMs: now(), // get before the call\n                  doStreamSpan,\n                  result: await stepModel.doStream({\n                    ...callSettings,\n                    tools: stepTools,\n                    toolChoice: stepToolChoice,\n                    responseFormat: output?.responseFormat,\n                    prompt: promptMessages,\n                    providerOptions,\n                    abortSignal,\n                    headers,\n                    includeRawChunks: includeRawChunks,\n                  }),\n                };\n              },\n            }),\n          );\n\n          const streamWithToolResults = runToolsTransformation({\n            tools,\n            generatorStream: stream,\n            tracer,\n            telemetry,\n            system,\n            messages: stepInputMessages,\n            repairToolCall,\n            abortSignal,\n          });\n\n          const stepRequest = request ?? {};\n          const stepToolCalls: ToolCallUnion<TOOLS>[] = [];\n          const stepToolResults: ToolResultUnion<TOOLS>[] = [];\n          let warnings: LanguageModelV2CallWarning[] | undefined;\n          const stepContent: Array<ContentPart<TOOLS>> = [];\n\n          let activeReasoningPart:\n            | undefined\n            | (ContentPart<TOOLS> & { type: 'reasoning' }) = undefined;\n\n          let stepFinishReason: FinishReason = 'unknown';\n          let stepUsage: LanguageModelUsage = {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n          let stepProviderMetadata: ProviderMetadata | undefined;\n          let stepFirstChunk = true;\n          let stepText = '';\n          let stepResponse: { id: string; timestamp: Date; modelId: string } = {\n            id: generateId(),\n            timestamp: currentDate(),\n            modelId: model.modelId,\n          };\n\n          async function publishTextChunk({\n            controller,\n            chunk,\n          }: {\n            controller: TransformStreamDefaultController<TextStreamPart<TOOLS>>;\n            chunk: TextStreamPart<TOOLS> & { type: 'text' };\n          }) {\n            controller.enqueue(chunk);\n\n            stepText += chunk.text;\n          }\n\n          self.addStream(\n            streamWithToolResults.pipeThrough(\n              new TransformStream<\n                SingleRequestTextStreamPart<TOOLS>,\n                TextStreamPart<TOOLS>\n              >({\n                async transform(chunk, controller): Promise<void> {\n                  if (chunk.type === 'stream-start') {\n                    warnings = chunk.warnings;\n                    return; // stream start chunks are sent immediately and do not count as first chunk\n                  }\n\n                  if (stepFirstChunk) {\n                    // Telemetry for first chunk:\n                    const msToFirstChunk = now() - startTimestampMs;\n\n                    stepFirstChunk = false;\n\n                    doStreamSpan.addEvent('ai.stream.firstChunk', {\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    doStreamSpan.setAttributes({\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    // Step start:\n                    controller.enqueue({\n                      type: 'start-step',\n                      request: stepRequest,\n                      warnings: warnings ?? [],\n                    });\n                  }\n\n                  // Filter out empty text deltas\n                  if (chunk.type === 'text' && chunk.text.length === 0) {\n                    return;\n                  }\n\n                  const chunkType = chunk.type;\n                  switch (chunkType) {\n                    case 'text': {\n                      await publishTextChunk({ controller, chunk });\n                      break;\n                    }\n\n                    case 'reasoning': {\n                      controller.enqueue(chunk);\n\n                      if (activeReasoningPart == null) {\n                        activeReasoningPart = {\n                          type: 'reasoning',\n                          text: chunk.text,\n                          providerMetadata: chunk.providerMetadata,\n                        };\n                        stepContent.push(activeReasoningPart);\n                      } else {\n                        activeReasoningPart.text += chunk.text;\n                        activeReasoningPart.providerMetadata =\n                          chunk.providerMetadata;\n                      }\n\n                      break;\n                    }\n\n                    case 'reasoning-part-finish': {\n                      activeReasoningPart = undefined;\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-call': {\n                      controller.enqueue(chunk);\n                      // store tool calls for onFinish callback and toolCalls promise:\n                      stepToolCalls.push(chunk);\n                      stepContent.push(chunk);\n                      break;\n                    }\n\n                    case 'tool-result': {\n                      controller.enqueue(chunk);\n                      // store tool results for onFinish callback and toolResults promise:\n                      stepToolResults.push(chunk);\n                      stepContent.push(chunk);\n                      break;\n                    }\n\n                    case 'response-metadata': {\n                      stepResponse = {\n                        id: chunk.id ?? stepResponse.id,\n                        timestamp: chunk.timestamp ?? stepResponse.timestamp,\n                        modelId: chunk.modelId ?? stepResponse.modelId,\n                      };\n                      break;\n                    }\n\n                    case 'finish': {\n                      // Note: tool executions might not be finished yet when the finish event is emitted.\n                      // store usage and finish reason for promises and onFinish callback:\n                      stepUsage = chunk.usage;\n                      stepFinishReason = chunk.finishReason;\n                      stepProviderMetadata = chunk.providerMetadata;\n\n                      // Telemetry for finish event timing\n                      // (since tool executions can take longer and distort calculations)\n                      const msToFinish = now() - startTimestampMs;\n                      doStreamSpan.addEvent('ai.stream.finish');\n                      doStreamSpan.setAttributes({\n                        'ai.response.msToFinish': msToFinish,\n                        'ai.response.avgOutputTokensPerSecond':\n                          (1000 * (stepUsage.outputTokens ?? 0)) / msToFinish,\n                      });\n\n                      break;\n                    }\n\n                    case 'file': {\n                      stepContent.push(chunk);\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'source': {\n                      stepContent.push(chunk);\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-call-streaming-start': {\n                      const tool = tools?.[chunk.toolName];\n\n                      if (tool?.onArgsStreamingStart != null) {\n                        await tool.onArgsStreamingStart({\n                          toolCallId: chunk.toolCallId,\n                          messages: stepInputMessages,\n                          abortSignal,\n                        });\n                      }\n\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-call-delta': {\n                      const tool = tools?.[chunk.toolName];\n\n                      if (tool?.onArgsStreamingDelta != null) {\n                        await tool.onArgsStreamingDelta({\n                          argsTextDelta: chunk.argsTextDelta,\n                          toolCallId: chunk.toolCallId,\n                          messages: stepInputMessages,\n                          abortSignal,\n                        });\n                      }\n\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'error': {\n                      controller.enqueue(chunk);\n                      stepFinishReason = 'error';\n                      break;\n                    }\n\n                    case 'raw': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    default: {\n                      const exhaustiveCheck: never = chunkType;\n                      throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n                    }\n                  }\n                },\n\n                // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n                async flush(controller) {\n                  const stepToolCallsJson =\n                    stepToolCalls.length > 0\n                      ? JSON.stringify(stepToolCalls)\n                      : undefined;\n\n                  // record telemetry information first to ensure best effort timing\n                  try {\n                    doStreamSpan.setAttributes(\n                      selectTelemetryAttributes({\n                        telemetry,\n                        attributes: {\n                          'ai.response.finishReason': stepFinishReason,\n                          'ai.response.text': { output: () => stepText },\n                          'ai.response.toolCalls': {\n                            output: () => stepToolCallsJson,\n                          },\n                          'ai.response.id': stepResponse.id,\n                          'ai.response.model': stepResponse.modelId,\n                          'ai.response.timestamp':\n                            stepResponse.timestamp.toISOString(),\n\n                          'ai.usage.inputTokens': stepUsage.inputTokens,\n                          'ai.usage.outputTokens': stepUsage.outputTokens,\n                          'ai.usage.totalTokens': stepUsage.totalTokens,\n                          'ai.usage.reasoningTokens': stepUsage.reasoningTokens,\n                          'ai.usage.cachedInputTokens':\n                            stepUsage.cachedInputTokens,\n\n                          // standardized gen-ai llm span attributes:\n                          'gen_ai.response.finish_reasons': [stepFinishReason],\n                          'gen_ai.response.id': stepResponse.id,\n                          'gen_ai.response.model': stepResponse.modelId,\n                          'gen_ai.usage.input_tokens': stepUsage.inputTokens,\n                          'gen_ai.usage.output_tokens': stepUsage.outputTokens,\n                        },\n                      }),\n                    );\n                  } catch (error) {\n                    // ignore error setting telemetry attributes\n                  } finally {\n                    // finish doStreamSpan before other operations for correct timing:\n                    doStreamSpan.end();\n                  }\n\n                  controller.enqueue({\n                    type: 'finish-step',\n                    finishReason: stepFinishReason,\n                    usage: stepUsage,\n                    providerMetadata: stepProviderMetadata,\n                    response: {\n                      ...stepResponse,\n                      headers: response?.headers,\n                    },\n                  });\n\n                  const combinedUsage = addLanguageModelUsage(usage, stepUsage);\n\n                  // wait for the step to be fully processed by the event processor\n                  // to ensure that the recorded steps are complete:\n                  await stepFinish.promise;\n\n                  if (\n                    stepToolCalls.length > 0 &&\n                    // all current tool calls have results:\n                    stepToolResults.length === stepToolCalls.length &&\n                    // continue until a stop condition is met:\n                    !(await isStopConditionMet({\n                      stopConditions,\n                      steps: recordedSteps,\n                    }))\n                  ) {\n                    // append to messages for the next step:\n                    responseMessages.push(\n                      ...toResponseMessages({\n                        content: stepContent,\n                        tools: tools ?? ({} as TOOLS),\n                      }),\n                    );\n\n                    await streamStep({\n                      currentStep: currentStep + 1,\n                      responseMessages,\n                      usage: combinedUsage,\n                    });\n                  } else {\n                    controller.enqueue({\n                      type: 'finish',\n                      finishReason: stepFinishReason,\n                      totalUsage: combinedUsage,\n                    });\n\n                    self.closeStream(); // close the stitchable stream\n                  }\n                },\n              }),\n            ),\n          );\n        }\n\n        // add the initial stream to the stitchable stream\n        await streamStep({\n          currentStep: 0,\n          responseMessages: [],\n          usage: {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          },\n        });\n      },\n    }).catch(error => {\n      // add an error stream part and close the streams:\n      self.addStream(\n        new ReadableStream({\n          start(controller) {\n            controller.enqueue({ type: 'error', error });\n            controller.close();\n          },\n        }),\n      );\n      self.closeStream();\n    });\n  }\n\n  get steps() {\n    return this._steps.promise;\n  }\n\n  private get finalStep() {\n    return this.steps.then(steps => steps[steps.length - 1]);\n  }\n\n  get content() {\n    return this.finalStep.then(step => step.content);\n  }\n\n  get warnings() {\n    return this.finalStep.then(step => step.warnings);\n  }\n\n  get providerMetadata() {\n    return this.finalStep.then(step => step.providerMetadata);\n  }\n\n  get text() {\n    return this.finalStep.then(step => step.text);\n  }\n\n  get reasoningText() {\n    return this.finalStep.then(step => step.reasoningText);\n  }\n\n  get reasoning() {\n    return this.finalStep.then(step => step.reasoning);\n  }\n\n  get sources() {\n    return this.finalStep.then(step => step.sources);\n  }\n\n  get files() {\n    return this.finalStep.then(step => step.files);\n  }\n\n  get toolCalls() {\n    return this.finalStep.then(step => step.toolCalls);\n  }\n\n  get toolResults() {\n    return this.finalStep.then(step => step.toolResults);\n  }\n\n  get usage() {\n    return this.finalStep.then(step => step.usage);\n  }\n\n  get request() {\n    return this.finalStep.then(step => step.request);\n  }\n\n  get response() {\n    return this.finalStep.then(step => step.response);\n  }\n\n  get totalUsage() {\n    return this._totalUsage.promise;\n  }\n\n  get finishReason() {\n    return this._finishReason.promise;\n  }\n\n  /**\nSplit out a new stream from the original stream.\nThe original stream is replaced to allow for further splitting,\nsince we do not know how many times the stream will be split.\n\nNote: this leads to buffering the stream content on the server.\nHowever, the LLM results are expected to be small enough to not cause issues.\n   */\n  private teeStream() {\n    const [stream1, stream2] = this.baseStream.tee();\n    this.baseStream = stream2;\n    return stream1;\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>, string>({\n          transform({ part }, controller) {\n            if (part.type === 'text') {\n              controller.enqueue(part.text);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<TextStreamPart<TOOLS>> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          TextStreamPart<TOOLS>\n        >({\n          transform({ part }, controller) {\n            controller.enqueue(part);\n          },\n        }),\n      ),\n    );\n  }\n\n  async consumeStream(options?: ConsumeStreamOptions): Promise<void> {\n    try {\n      await consumeStream({\n        stream: this.fullStream,\n        onError: options?.onError,\n      });\n    } catch (error) {\n      options?.onError?.(error);\n    }\n  }\n\n  get experimental_partialOutputStream(): AsyncIterableStream<PARTIAL_OUTPUT> {\n    if (this.output == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          PARTIAL_OUTPUT\n        >({\n          transform({ partialOutput }, controller) {\n            if (partialOutput != null) {\n              controller.enqueue(partialOutput);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  toUIMessageStream<UI_MESSAGE extends UIMessage>({\n    newMessageId,\n    originalMessages = [],\n    onFinish,\n    messageMetadata,\n    sendReasoning = false,\n    sendSources = false,\n    sendStart = true,\n    sendFinish = true,\n    onError = () => 'An error occurred.', // mask error messages for safety by default\n  }: UIMessageStreamOptions<UI_MESSAGE> = {}): ReadableStream<\n    InferUIMessageStreamPart<UI_MESSAGE>\n  > {\n    const lastMessage = originalMessages[originalMessages.length - 1];\n    const isContinuation = lastMessage?.role === 'assistant';\n    const messageId = isContinuation ? lastMessage.id : newMessageId;\n\n    const baseStream = this.fullStream.pipeThrough(\n      new TransformStream<\n        TextStreamPart<TOOLS>,\n        UIMessageStreamPart<InferUIMessageMetadata<UI_MESSAGE>, UIDataTypes>\n      >({\n        transform: async (part, controller) => {\n          const partType = part.type;\n          switch (partType) {\n            case 'text': {\n              controller.enqueue({\n                type: 'text',\n                text: part.text,\n              });\n              break;\n            }\n\n            case 'reasoning': {\n              if (sendReasoning) {\n                controller.enqueue({\n                  type: 'reasoning',\n                  text: part.text,\n                  providerMetadata: part.providerMetadata,\n                });\n              }\n              break;\n            }\n\n            case 'reasoning-part-finish': {\n              if (sendReasoning) {\n                controller.enqueue({ type: 'reasoning-part-finish' });\n              }\n              break;\n            }\n\n            case 'file': {\n              controller.enqueue({\n                type: 'file',\n                mediaType: part.file.mediaType,\n                url: `data:${part.file.mediaType};base64,${part.file.base64}`,\n              });\n              break;\n            }\n\n            case 'source': {\n              if (sendSources && part.sourceType === 'url') {\n                controller.enqueue({\n                  type: 'source-url',\n                  sourceId: part.id,\n                  url: part.url,\n                  title: part.title,\n                  providerMetadata: part.providerMetadata,\n                });\n              }\n\n              if (sendSources && part.sourceType === 'document') {\n                controller.enqueue({\n                  type: 'source-document',\n                  sourceId: part.id,\n                  mediaType: part.mediaType,\n                  title: part.title,\n                  filename: part.filename,\n                  providerMetadata: part.providerMetadata,\n                });\n              }\n              break;\n            }\n\n            case 'tool-call-streaming-start': {\n              controller.enqueue({\n                type: 'tool-call-streaming-start',\n                toolCallId: part.toolCallId,\n                toolName: part.toolName,\n              });\n              break;\n            }\n\n            case 'tool-call-delta': {\n              controller.enqueue({\n                type: 'tool-call-delta',\n                toolCallId: part.toolCallId,\n                argsTextDelta: part.argsTextDelta,\n              });\n              break;\n            }\n\n            case 'tool-call': {\n              controller.enqueue({\n                type: 'tool-call',\n                toolCallId: part.toolCallId,\n                toolName: part.toolName,\n                args: part.args,\n              });\n              break;\n            }\n\n            case 'tool-result': {\n              controller.enqueue({\n                type: 'tool-result',\n                toolCallId: part.toolCallId,\n                result: part.result,\n              });\n              break;\n            }\n\n            case 'error': {\n              controller.enqueue({\n                type: 'error',\n                errorText: onError(part.error),\n              });\n              break;\n            }\n\n            case 'start-step': {\n              const metadata = messageMetadata?.({ part });\n              controller.enqueue({\n                type: 'start-step',\n                metadata,\n              });\n              break;\n            }\n\n            case 'finish-step': {\n              const metadata = messageMetadata?.({ part });\n              controller.enqueue({\n                type: 'finish-step',\n                metadata,\n              });\n\n              break;\n            }\n\n            case 'start': {\n              if (sendStart) {\n                const metadata = messageMetadata?.({ part });\n                controller.enqueue({\n                  type: 'start',\n                  messageId,\n                  metadata,\n                });\n              }\n              break;\n            }\n\n            case 'finish': {\n              if (sendFinish) {\n                const metadata = messageMetadata?.({ part });\n                controller.enqueue({\n                  type: 'finish',\n                  metadata,\n                });\n              }\n              break;\n            }\n\n            case 'raw': {\n              // Raw chunks are not included in UI message streams\n              // as they contain provider-specific data for developer use\n              break;\n            }\n\n            default: {\n              const exhaustiveCheck: never = partType;\n              throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n            }\n          }\n        },\n      }),\n    );\n\n    return handleUIMessageStreamFinish<UI_MESSAGE>({\n      stream: baseStream,\n      newMessageId: messageId ?? this.generateId(),\n      originalMessages,\n      onFinish,\n    });\n  }\n\n  pipeUIMessageStreamToResponse<UI_MESSAGE extends UIMessage>(\n    response: ServerResponse,\n    {\n      newMessageId,\n      originalMessages,\n      onFinish,\n      messageMetadata,\n      sendReasoning,\n      sendSources,\n      sendFinish,\n      sendStart,\n      onError,\n      ...init\n    }: ResponseInit & UIMessageStreamOptions<UI_MESSAGE> = {},\n  ) {\n    pipeUIMessageStreamToResponse({\n      response,\n      stream: this.toUIMessageStream({\n        newMessageId,\n        originalMessages,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toUIMessageStreamResponse<UI_MESSAGE extends UIMessage>({\n    newMessageId,\n    originalMessages,\n    onFinish,\n    messageMetadata,\n    sendReasoning,\n    sendSources,\n    sendFinish,\n    sendStart,\n    onError,\n    ...init\n  }: ResponseInit & UIMessageStreamOptions<UI_MESSAGE> = {}): Response {\n    return createUIMessageStreamResponse({\n      stream: this.toUIMessageStream({\n        newMessageId,\n        originalMessages,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n","import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport { generateId } from '@ai-sdk/provider-utils';\nimport { Tracer } from '@opentelemetry/api';\nimport { ToolExecutionError } from '../../src/error/tool-execution-error';\nimport { ModelMessage } from '../prompt/message';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { FinishReason, LanguageModelUsage, ProviderMetadata } from '../types';\nimport { ContentPart } from './content-part';\nimport { DefaultGeneratedFileWithType } from './generated-file';\nimport { parseToolCall } from './parse-tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair';\nimport { ToolSet } from './tool-set';\n\nexport type SingleRequestTextStreamPart<TOOLS extends ToolSet> =\n  | ContentPart<TOOLS>\n  | { type: 'stream-start'; warnings: LanguageModelV2CallWarning[] }\n  | { type: 'reasoning-part-finish' }\n  | {\n      type: 'tool-call-streaming-start';\n      toolCallId: string;\n      toolName: string;\n    }\n  | {\n      type: 'tool-call-delta';\n      toolCallId: string;\n      toolName: string;\n      argsTextDelta: string;\n    }\n  | {\n      type: 'response-metadata';\n      id?: string;\n      timestamp?: Date;\n      modelId?: string;\n    }\n  | {\n      type: 'finish';\n      finishReason: FinishReason;\n      usage: LanguageModelUsage;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'error';\n      error: unknown;\n    }\n  | {\n      type: 'raw';\n      rawValue: unknown;\n    };\n\nexport function runToolsTransformation<TOOLS extends ToolSet>({\n  tools,\n  generatorStream,\n  tracer,\n  telemetry,\n  system,\n  messages,\n  abortSignal,\n  repairToolCall,\n}: {\n  tools: TOOLS | undefined;\n  generatorStream: ReadableStream<LanguageModelV2StreamPart>;\n  tracer: Tracer;\n  telemetry: TelemetrySettings | undefined;\n  system: string | undefined;\n  messages: ModelMessage[];\n  abortSignal: AbortSignal | undefined;\n  repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n}): ReadableStream<SingleRequestTextStreamPart<TOOLS>> {\n  // tool results stream\n  let toolResultsStreamController: ReadableStreamDefaultController<\n    SingleRequestTextStreamPart<TOOLS>\n  > | null = null;\n  const toolResultsStream = new ReadableStream<\n    SingleRequestTextStreamPart<TOOLS>\n  >({\n    start(controller) {\n      toolResultsStreamController = controller;\n    },\n  });\n\n  // keep track of active tool calls for tool call streaming:\n  const activeToolCalls: Record<string, boolean> = {};\n\n  // keep track of outstanding tool results for stream closing:\n  const outstandingToolResults = new Set<string>();\n\n  let canClose = false;\n  let finishChunk:\n    | (SingleRequestTextStreamPart<TOOLS> & { type: 'finish' })\n    | undefined = undefined;\n\n  function attemptClose() {\n    // close the tool results controller if no more outstanding tool calls\n    if (canClose && outstandingToolResults.size === 0) {\n      // we delay sending the finish chunk until all tool results (incl. delayed ones)\n      // are received to ensure that the frontend receives tool results before a message\n      // finish event arrives.\n      if (finishChunk != null) {\n        toolResultsStreamController!.enqueue(finishChunk);\n      }\n\n      toolResultsStreamController!.close();\n    }\n  }\n\n  // forward stream\n  const forwardStream = new TransformStream<\n    LanguageModelV2StreamPart,\n    SingleRequestTextStreamPart<TOOLS>\n  >({\n    async transform(\n      chunk: LanguageModelV2StreamPart,\n      controller: TransformStreamDefaultController<\n        SingleRequestTextStreamPart<TOOLS>\n      >,\n    ) {\n      const chunkType = chunk.type;\n\n      switch (chunkType) {\n        // forward:\n        case 'stream-start':\n        case 'finish':\n        case 'text':\n        case 'reasoning':\n        case 'reasoning-part-finish':\n        case 'source':\n        case 'response-metadata':\n        case 'error': {\n          controller.enqueue(chunk);\n          break;\n        }\n\n        // forward raw chunks to be part of the fullStream\n        case 'raw': {\n          controller.enqueue(chunk);\n          break;\n        }\n\n        case 'file': {\n          controller.enqueue({\n            type: 'file',\n            file: new DefaultGeneratedFileWithType({\n              data: chunk.data,\n              mediaType: chunk.mediaType,\n            }),\n          });\n          break;\n        }\n\n        // forward with less information:\n        case 'tool-call-delta': {\n          if (!activeToolCalls[chunk.toolCallId]) {\n            controller.enqueue({\n              type: 'tool-call-streaming-start',\n              toolCallId: chunk.toolCallId,\n              toolName: chunk.toolName,\n            });\n\n            activeToolCalls[chunk.toolCallId] = true;\n          }\n\n          controller.enqueue({\n            type: 'tool-call-delta',\n            toolCallId: chunk.toolCallId,\n            toolName: chunk.toolName,\n            argsTextDelta: chunk.argsTextDelta,\n          });\n\n          break;\n        }\n\n        // process tool call:\n        case 'tool-call': {\n          try {\n            const toolCall = await parseToolCall({\n              toolCall: chunk,\n              tools,\n              repairToolCall,\n              system,\n              messages,\n            });\n\n            controller.enqueue(toolCall);\n\n            const tool = tools![toolCall.toolName];\n\n            if (tool.onArgsAvailable != null) {\n              await tool.onArgsAvailable({\n                args: toolCall.args,\n                toolCallId: toolCall.toolCallId,\n                messages,\n                abortSignal,\n              });\n            }\n\n            if (tool.execute != null) {\n              const toolExecutionId = generateId(); // use our own id to guarantee uniqueness\n              outstandingToolResults.add(toolExecutionId);\n\n              // Note: we don't await the tool execution here (by leaving out 'await' on recordSpan),\n              // because we want to process the next chunk as soon as possible.\n              // This is important for the case where the tool execution takes a long time.\n              recordSpan({\n                name: 'ai.toolCall',\n                attributes: selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    ...assembleOperationName({\n                      operationId: 'ai.toolCall',\n                      telemetry,\n                    }),\n                    'ai.toolCall.name': toolCall.toolName,\n                    'ai.toolCall.id': toolCall.toolCallId,\n                    'ai.toolCall.args': {\n                      output: () => JSON.stringify(toolCall.args),\n                    },\n                  },\n                }),\n                tracer,\n                fn: async span =>\n                  tool.execute!(toolCall.args, {\n                    toolCallId: toolCall.toolCallId,\n                    messages,\n                    abortSignal,\n                  }).then(\n                    (result: any) => {\n                      toolResultsStreamController!.enqueue({\n                        ...toolCall,\n                        type: 'tool-result',\n                        result,\n                      } as any);\n\n                      outstandingToolResults.delete(toolExecutionId);\n\n                      attemptClose();\n\n                      // record telemetry\n                      try {\n                        span.setAttributes(\n                          selectTelemetryAttributes({\n                            telemetry,\n                            attributes: {\n                              'ai.toolCall.result': {\n                                output: () => JSON.stringify(result),\n                              },\n                            },\n                          }),\n                        );\n                      } catch (ignored) {\n                        // JSON stringify might fail if the result is not serializable,\n                        // in which case we just ignore it. In the future we might want to\n                        // add an optional serialize method to the tool interface and warn\n                        // if the result is not serializable.\n                      }\n                    },\n                    (error: any) => {\n                      toolResultsStreamController!.enqueue({\n                        type: 'error',\n                        error: new ToolExecutionError({\n                          toolCallId: toolCall.toolCallId,\n                          toolName: toolCall.toolName,\n                          toolArgs: toolCall.args,\n                          cause: error,\n                        }),\n                      });\n\n                      outstandingToolResults.delete(toolExecutionId);\n                      attemptClose();\n                    },\n                  ),\n              });\n            }\n          } catch (error) {\n            toolResultsStreamController!.enqueue({\n              type: 'error',\n              error,\n            });\n          }\n\n          break;\n        }\n\n        default: {\n          const _exhaustiveCheck: never = chunkType;\n          throw new Error(`Unhandled chunk type: ${_exhaustiveCheck}`);\n        }\n      }\n    },\n\n    flush() {\n      canClose = true;\n      attemptClose();\n    },\n  });\n\n  // combine the generator stream and the tool results stream\n  return new ReadableStream<SingleRequestTextStreamPart<TOOLS>>({\n    async start(controller) {\n      // need to wait for both pipes so there are no dangling promises that\n      // can cause uncaught promise rejections when the stream is aborted\n      return Promise.all([\n        generatorStream.pipeThrough(forwardStream).pipeTo(\n          new WritableStream({\n            write(chunk) {\n              controller.enqueue(chunk);\n            },\n            close() {\n              // the generator stream controller is automatically closed when it's consumed\n            },\n          }),\n        ),\n        toolResultsStream.pipeTo(\n          new WritableStream({\n            write(chunk) {\n              controller.enqueue(chunk);\n            },\n            close() {\n              controller.close();\n            },\n          }),\n        ),\n      ]);\n    },\n  });\n}\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2Middleware,\n} from '@ai-sdk/provider';\nimport { mergeObjects } from '../../src/util/merge-objects';\n\n/**\n * Applies default settings for a language model.\n */\nexport function defaultSettingsMiddleware({\n  settings,\n}: {\n  settings: Partial<{\n    maxOutputTokens?: LanguageModelV2CallOptions['maxOutputTokens'];\n    temperature?: LanguageModelV2CallOptions['temperature'];\n    stopSequences?: LanguageModelV2CallOptions['stopSequences'];\n    topP?: LanguageModelV2CallOptions['topP'];\n    topK?: LanguageModelV2CallOptions['topK'];\n    presencePenalty?: LanguageModelV2CallOptions['presencePenalty'];\n    frequencyPenalty?: LanguageModelV2CallOptions['frequencyPenalty'];\n    responseFormat?: LanguageModelV2CallOptions['responseFormat'];\n    seed?: LanguageModelV2CallOptions['seed'];\n    tools?: LanguageModelV2CallOptions['tools'];\n    toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n    headers?: LanguageModelV2CallOptions['headers'];\n    providerOptions?: LanguageModelV2CallOptions['providerOptions'];\n  }>;\n}): LanguageModelV2Middleware {\n  return {\n    middlewareVersion: 'v2',\n    transformParams: async ({ params }) => {\n      return mergeObjects(settings, params) as LanguageModelV2CallOptions;\n    },\n  };\n}\n","/**\n * Returns the index of the start of the searchedText in the text, or null if it\n * is not found.\n */\nexport function getPotentialStartIndex(\n  text: string,\n  searchedText: string,\n): number | null {\n  // Return null immediately if searchedText is empty.\n  if (searchedText.length === 0) {\n    return null;\n  }\n\n  // Check if the searchedText exists as a direct substring of text.\n  const directIndex = text.indexOf(searchedText);\n  if (directIndex !== -1) {\n    return directIndex;\n  }\n\n  // Otherwise, look for the largest suffix of \"text\" that matches\n  // a prefix of \"searchedText\". We go from the end of text inward.\n  for (let i = text.length - 1; i >= 0; i--) {\n    const suffix = text.substring(i);\n    if (searchedText.startsWith(suffix)) {\n      return i;\n    }\n  }\n\n  return null;\n}\n","import type {\n  LanguageModelV2Content,\n  LanguageModelV2Middleware,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport { getPotentialStartIndex } from '../../src/util/get-potential-start-index';\n\n/**\n * Extract an XML-tagged reasoning section from the generated text and exposes it\n * as a `reasoning` property on the result.\n *\n * @param tagName - The name of the XML tag to extract reasoning from.\n * @param separator - The separator to use between reasoning and text sections.\n * @param startWithReasoning - Whether to start with reasoning tokens.\n */\nexport function extractReasoningMiddleware({\n  tagName,\n  separator = '\\n',\n  startWithReasoning = false,\n}: {\n  tagName: string;\n  separator?: string;\n  startWithReasoning?: boolean;\n}): LanguageModelV2Middleware {\n  const openingTag = `<${tagName}>`;\n  const closingTag = `<\\/${tagName}>`;\n\n  return {\n    middlewareVersion: 'v2',\n    wrapGenerate: async ({ doGenerate }) => {\n      const { content, ...rest } = await doGenerate();\n\n      const transformedContent: LanguageModelV2Content[] = [];\n      for (const part of content) {\n        if (part.type !== 'text') {\n          transformedContent.push(part);\n          continue;\n        }\n\n        const text = startWithReasoning ? openingTag + part.text : part.text;\n\n        const regexp = new RegExp(`${openingTag}(.*?)${closingTag}`, 'gs');\n        const matches = Array.from(text.matchAll(regexp));\n\n        if (!matches.length) {\n          transformedContent.push(part);\n          continue;\n        }\n\n        const reasoningText = matches.map(match => match[1]).join(separator);\n\n        let textWithoutReasoning = text;\n        for (let i = matches.length - 1; i >= 0; i--) {\n          const match = matches[i];\n\n          const beforeMatch = textWithoutReasoning.slice(0, match.index);\n          const afterMatch = textWithoutReasoning.slice(\n            match.index! + match[0].length,\n          );\n\n          textWithoutReasoning =\n            beforeMatch +\n            (beforeMatch.length > 0 && afterMatch.length > 0 ? separator : '') +\n            afterMatch;\n        }\n\n        transformedContent.push({\n          type: 'reasoning',\n          text: reasoningText,\n        });\n\n        transformedContent.push({\n          type: 'text',\n          text: textWithoutReasoning,\n        });\n      }\n\n      return { content: transformedContent, ...rest };\n    },\n\n    wrapStream: async ({ doStream }) => {\n      const { stream, ...rest } = await doStream();\n\n      let isFirstReasoning = true;\n      let isFirstText = true;\n      let afterSwitch = false;\n      let isReasoning = startWithReasoning;\n      let buffer = '';\n\n      return {\n        stream: stream.pipeThrough(\n          new TransformStream<\n            LanguageModelV2StreamPart,\n            LanguageModelV2StreamPart\n          >({\n            transform: (chunk, controller) => {\n              if (chunk.type !== 'text') {\n                controller.enqueue(chunk);\n                return;\n              }\n\n              buffer += chunk.text;\n\n              function publish(text: string) {\n                if (text.length > 0) {\n                  const prefix =\n                    afterSwitch &&\n                    (isReasoning ? !isFirstReasoning : !isFirstText)\n                      ? separator\n                      : '';\n\n                  controller.enqueue(\n                    isReasoning\n                      ? {\n                          type: 'reasoning',\n                          text: prefix + text,\n                        }\n                      : {\n                          type: 'text',\n                          text: prefix + text,\n                        },\n                  );\n                  afterSwitch = false;\n\n                  if (isReasoning) {\n                    isFirstReasoning = false;\n                  } else {\n                    isFirstText = false;\n                  }\n                }\n              }\n\n              do {\n                const nextTag = isReasoning ? closingTag : openingTag;\n                const startIndex = getPotentialStartIndex(buffer, nextTag);\n\n                // no opening or closing tag found, publish the buffer\n                if (startIndex == null) {\n                  publish(buffer);\n                  buffer = '';\n                  break;\n                }\n\n                // publish text before the tag\n                publish(buffer.slice(0, startIndex));\n\n                const foundFullMatch =\n                  startIndex + nextTag.length <= buffer.length;\n\n                if (foundFullMatch) {\n                  buffer = buffer.slice(startIndex + nextTag.length);\n\n                  // reasoning part finished:\n                  if (isReasoning) {\n                    controller.enqueue({ type: 'reasoning-part-finish' });\n                  }\n\n                  isReasoning = !isReasoning;\n                  afterSwitch = true;\n                } else {\n                  buffer = buffer.slice(startIndex);\n                  break;\n                }\n              } while (true);\n            },\n          }),\n        ),\n        ...rest,\n      };\n    },\n  };\n}\n","import type {\n  LanguageModelV2Middleware,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\n\n/**\n * Simulates streaming chunks with the response from a generate call.\n */\nexport function simulateStreamingMiddleware(): LanguageModelV2Middleware {\n  return {\n    middlewareVersion: 'v2',\n    wrapStream: async ({ doGenerate }) => {\n      const result = await doGenerate();\n\n      const simulatedStream = new ReadableStream<LanguageModelV2StreamPart>({\n        start(controller) {\n          controller.enqueue({\n            type: 'stream-start',\n            warnings: result.warnings,\n          });\n\n          controller.enqueue({ type: 'response-metadata', ...result.response });\n\n          for (const part of result.content) {\n            controller.enqueue(part);\n          }\n\n          controller.enqueue({\n            type: 'finish',\n            finishReason: result.finishReason,\n            usage: result.usage,\n            providerMetadata: result.providerMetadata,\n          });\n\n          controller.close();\n        },\n      });\n\n      return {\n        stream: simulatedStream,\n        request: result.request,\n        response: result.response,\n      };\n    },\n  };\n}\n","import {\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2Middleware,\n} from '@ai-sdk/provider';\nimport { asArray } from '../../src/util/as-array';\n\n/**\n * Wraps a LanguageModelV2 instance with middleware functionality.\n * This function allows you to apply middleware to transform parameters,\n * wrap generate operations, and wrap stream operations of a language model.\n *\n * @param options - Configuration options for wrapping the language model.\n * @param options.model - The original LanguageModelV2 instance to be wrapped.\n * @param options.middleware - The middleware to be applied to the language model. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.\n * @param options.modelId - Optional custom model ID to override the original model's ID.\n * @param options.providerId - Optional custom provider ID to override the original model's provider.\n * @returns A new LanguageModelV2 instance with middleware applied.\n */\nexport const wrapLanguageModel = ({\n  model,\n  middleware: middlewareArg,\n  modelId,\n  providerId,\n}: {\n  model: LanguageModelV2;\n  middleware: LanguageModelV2Middleware | LanguageModelV2Middleware[];\n  modelId?: string;\n  providerId?: string;\n}): LanguageModelV2 => {\n  return asArray(middlewareArg)\n    .reverse()\n    .reduce((wrappedModel, middleware) => {\n      return doWrap({ model: wrappedModel, middleware, modelId, providerId });\n    }, model);\n};\n\nconst doWrap = ({\n  model,\n  middleware: { transformParams, wrapGenerate, wrapStream },\n  modelId,\n  providerId,\n}: {\n  model: LanguageModelV2;\n  middleware: LanguageModelV2Middleware;\n  modelId?: string;\n  providerId?: string;\n}): LanguageModelV2 => {\n  async function doTransform({\n    params,\n    type,\n  }: {\n    params: LanguageModelV2CallOptions;\n    type: 'generate' | 'stream';\n  }) {\n    return transformParams ? await transformParams({ params, type }) : params;\n  }\n\n  return {\n    specificationVersion: 'v2',\n\n    provider: providerId ?? model.provider,\n    modelId: modelId ?? model.modelId,\n\n    // TODO middleware should be able to modify the supported urls\n    get supportedUrls(): LanguageModelV2['supportedUrls'] {\n      return model.supportedUrls;\n    },\n\n    async doGenerate(\n      params: LanguageModelV2CallOptions,\n    ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n      const transformedParams = await doTransform({ params, type: 'generate' });\n      const doGenerate = async () => model.doGenerate(transformedParams);\n      const doStream = async () => model.doStream(transformedParams);\n      return wrapGenerate\n        ? wrapGenerate({\n            doGenerate,\n            doStream,\n            params: transformedParams,\n            model,\n          })\n        : doGenerate();\n    },\n\n    async doStream(\n      params: LanguageModelV2CallOptions,\n    ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n      const transformedParams = await doTransform({ params, type: 'stream' });\n      const doGenerate = async () => model.doGenerate(transformedParams);\n      const doStream = async () => model.doStream(transformedParams);\n      return wrapStream\n        ? wrapStream({ doGenerate, doStream, params: transformedParams, model })\n        : doStream();\n    },\n  };\n};\n","import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  NoSuchModelError,\n  ProviderV2,\n} from '@ai-sdk/provider';\n\n/**\n * Creates a custom provider with specified language models, text embedding models, and an optional fallback provider.\n *\n * @param {Object} options - The options for creating the custom provider.\n * @param {Record<string, LanguageModel>} [options.languageModels] - A record of language models, where keys are model IDs and values are LanguageModel instances.\n * @param {Record<string, EmbeddingModel<string>>} [options.textEmbeddingModels] - A record of text embedding models, where keys are model IDs and values are EmbeddingModel<string> instances.\n * @param {Record<string, ImageModel>} [options.imageModels] - A record of image models, where keys are model IDs and values are ImageModel instances.\n * @param {Provider} [options.fallbackProvider] - An optional fallback provider to use when a requested model is not found in the custom provider.\n * @returns {Provider} A Provider object with languageModel, textEmbeddingModel, and imageModel methods.\n *\n * @throws {NoSuchModelError} Throws when a requested model is not found and no fallback provider is available.\n */\nexport function customProvider<\n  LANGUAGE_MODELS extends Record<string, LanguageModelV2>,\n  EMBEDDING_MODELS extends Record<string, EmbeddingModelV2<string>>,\n  IMAGE_MODELS extends Record<string, ImageModelV2>,\n>({\n  languageModels,\n  textEmbeddingModels,\n  imageModels,\n  fallbackProvider,\n}: {\n  languageModels?: LANGUAGE_MODELS;\n  textEmbeddingModels?: EMBEDDING_MODELS;\n  imageModels?: IMAGE_MODELS;\n  fallbackProvider?: ProviderV2;\n}): ProviderV2 & {\n  languageModel(modelId: ExtractModelId<LANGUAGE_MODELS>): LanguageModelV2;\n  textEmbeddingModel(\n    modelId: ExtractModelId<EMBEDDING_MODELS>,\n  ): EmbeddingModelV2<string>;\n  imageModel(modelId: ExtractModelId<IMAGE_MODELS>): ImageModelV2;\n} {\n  return {\n    languageModel(modelId: ExtractModelId<LANGUAGE_MODELS>): LanguageModelV2 {\n      if (languageModels != null && modelId in languageModels) {\n        return languageModels[modelId];\n      }\n\n      if (fallbackProvider) {\n        return fallbackProvider.languageModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'languageModel' });\n    },\n\n    textEmbeddingModel(\n      modelId: ExtractModelId<EMBEDDING_MODELS>,\n    ): EmbeddingModelV2<string> {\n      if (textEmbeddingModels != null && modelId in textEmbeddingModels) {\n        return textEmbeddingModels[modelId];\n      }\n\n      if (fallbackProvider) {\n        return fallbackProvider.textEmbeddingModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'textEmbeddingModel' });\n    },\n\n    imageModel(modelId: ExtractModelId<IMAGE_MODELS>): ImageModelV2 {\n      if (imageModels != null && modelId in imageModels) {\n        return imageModels[modelId];\n      }\n\n      if (fallbackProvider?.imageModel) {\n        return fallbackProvider.imageModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'imageModel' });\n    },\n  };\n}\n\n/**\n * @deprecated Use `customProvider` instead.\n */\nexport const experimental_customProvider = customProvider;\n\ntype ExtractModelId<MODELS extends Record<string, unknown>> = Extract<\n  keyof MODELS,\n  string\n>;\n","import { AISDKError, NoSuchModelError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoSuchProviderError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class NoSuchProviderError extends NoSuchModelError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly providerId: string;\n  readonly availableProviders: string[];\n\n  constructor({\n    modelId,\n    modelType,\n    providerId,\n    availableProviders,\n    message = `No such provider: ${providerId} (available providers: ${availableProviders.join()})`,\n  }: {\n    modelId: string;\n    modelType: 'languageModel' | 'textEmbeddingModel';\n    providerId: string;\n    availableProviders: string[];\n    message?: string;\n  }) {\n    super({ errorName: name, modelId, modelType, message });\n\n    this.providerId = providerId;\n    this.availableProviders = availableProviders;\n  }\n\n  static isInstance(error: unknown): error is NoSuchProviderError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n","import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  NoSuchModelError,\n  ProviderV2,\n} from '@ai-sdk/provider';\nimport { NoSuchProviderError } from './no-such-provider-error';\n\ntype ExtractLiteralUnion<T> = T extends string\n  ? string extends T\n    ? never\n    : T\n  : never;\n\nexport interface ProviderRegistryProvider<\n  PROVIDERS extends Record<string, ProviderV2> = Record<string, ProviderV2>,\n  SEPARATOR extends string = ':',\n> {\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['languageModel']>>[0]>}`\n      : never,\n  ): LanguageModelV2;\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): LanguageModelV2;\n\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['textEmbeddingModel']>>[0]>}`\n      : never,\n  ): EmbeddingModelV2<string>;\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): EmbeddingModelV2<string>;\n\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['imageModel']>>[0]>}`\n      : never,\n  ): ImageModelV2;\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): ImageModelV2;\n}\n\n/**\n * Creates a registry for the given providers.\n */\nexport function createProviderRegistry<\n  PROVIDERS extends Record<string, ProviderV2>,\n  SEPARATOR extends string = ':',\n>(\n  providers: PROVIDERS,\n  {\n    separator = ':' as SEPARATOR,\n  }: {\n    separator?: SEPARATOR;\n  } = {},\n): ProviderRegistryProvider<PROVIDERS, SEPARATOR> {\n  const registry = new DefaultProviderRegistry<PROVIDERS, SEPARATOR>({\n    separator,\n  });\n\n  for (const [id, provider] of Object.entries(providers)) {\n    registry.registerProvider({ id, provider } as {\n      id: keyof PROVIDERS;\n      provider: PROVIDERS[keyof PROVIDERS];\n    });\n  }\n\n  return registry;\n}\n\n/**\n * @deprecated Use `createProviderRegistry` instead.\n */\nexport const experimental_createProviderRegistry = createProviderRegistry;\n\nclass DefaultProviderRegistry<\n  PROVIDERS extends Record<string, ProviderV2>,\n  SEPARATOR extends string,\n> implements ProviderRegistryProvider<PROVIDERS, SEPARATOR>\n{\n  private providers: PROVIDERS = {} as PROVIDERS;\n  private separator: SEPARATOR;\n\n  constructor({ separator }: { separator: SEPARATOR }) {\n    this.separator = separator;\n  }\n\n  registerProvider<K extends keyof PROVIDERS>({\n    id,\n    provider,\n  }: {\n    id: K;\n    provider: PROVIDERS[K];\n  }): void {\n    this.providers[id] = provider;\n  }\n\n  private getProvider(id: string): ProviderV2 {\n    const provider = this.providers[id as keyof PROVIDERS];\n\n    if (provider == null) {\n      throw new NoSuchProviderError({\n        modelId: id,\n        modelType: 'languageModel',\n        providerId: id,\n        availableProviders: Object.keys(this.providers),\n      });\n    }\n\n    return provider;\n  }\n\n  private splitId(\n    id: string,\n    modelType: 'languageModel' | 'textEmbeddingModel' | 'imageModel',\n  ): [string, string] {\n    const index = id.indexOf(this.separator);\n\n    if (index === -1) {\n      throw new NoSuchModelError({\n        modelId: id,\n        modelType,\n        message:\n          `Invalid ${modelType} id for registry: ${id} ` +\n          `(must be in the format \"providerId${this.separator}modelId\")`,\n      });\n    }\n\n    return [id.slice(0, index), id.slice(index + this.separator.length)];\n  }\n\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): LanguageModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'languageModel');\n    const model = this.getProvider(providerId).languageModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({ modelId: id, modelType: 'languageModel' });\n    }\n\n    return model;\n  }\n\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): EmbeddingModelV2<string> {\n    const [providerId, modelId] = this.splitId(id, 'textEmbeddingModel');\n    const provider = this.getProvider(providerId);\n\n    const model = provider.textEmbeddingModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({\n        modelId: id,\n        modelType: 'textEmbeddingModel',\n      });\n    }\n\n    return model;\n  }\n\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): ImageModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'imageModel');\n    const provider = this.getProvider(providerId);\n\n    const model = provider.imageModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({ modelId: id, modelType: 'imageModel' });\n    }\n\n    return model;\n  }\n}\n","import { JSONSchema7 } from '@ai-sdk/provider';\nimport { jsonSchema } from '@ai-sdk/provider-utils';\nimport { z, ZodType } from 'zod';\nimport { MCPClientError } from '../../../src/error/mcp-client-error';\nimport { tool, Tool, ToolCallOptions } from '../tool';\nimport {\n  JSONRPCError,\n  JSONRPCNotification,\n  JSONRPCRequest,\n  JSONRPCResponse,\n} from './json-rpc-message';\nimport {\n  createMcpTransport,\n  isCustomMcpTransport,\n  MCPTransport,\n  MCPTransportConfig,\n} from './mcp-transport';\nimport {\n  CallToolResult,\n  CallToolResultSchema,\n  Configuration as ClientConfiguration,\n  InitializeResultSchema,\n  LATEST_PROTOCOL_VERSION,\n  ListToolsResult,\n  ListToolsResultSchema,\n  McpToolSet,\n  Notification,\n  PaginatedRequest,\n  Request,\n  RequestOptions,\n  ServerCapabilities,\n  SUPPORTED_PROTOCOL_VERSIONS,\n  ToolSchemas,\n} from './types';\n\nconst CLIENT_VERSION = '1.0.0';\n\ninterface MCPClientConfig {\n  /** Transport configuration for connecting to the MCP server */\n  transport: MCPTransportConfig | MCPTransport;\n  /** Optional callback for uncaught errors */\n  onUncaughtError?: (error: unknown) => void;\n  /** Optional client name, defaults to 'ai-sdk-mcp-client' */\n  name?: string;\n}\n\nexport async function createMCPClient(\n  config: MCPClientConfig,\n): Promise<MCPClient> {\n  const client = new MCPClient(config);\n  await client.init();\n  return client;\n}\n\n/**\n * A lightweight MCP Client implementation\n *\n * The primary purpose of this client is tool conversion between MCP<>AI SDK\n * but can later be extended to support other MCP features\n *\n * Tool parameters are automatically inferred from the server's JSON schema\n * if not explicitly provided in the tools configuration\n *\n * This client is meant to be used to communicate with a single server. To communicate and fetch tools across multiple servers, it's recommended to create a new client instance per server.\n *\n * Not supported:\n * - Client options (e.g. sampling, roots) as they are not needed for tool conversion\n * - Accepting notifications\n * - Session management (when passing a sessionId to an instance of the Streamable HTTP transport)\n * - Resumable SSE streams\n */\nclass MCPClient {\n  private transport: MCPTransport;\n  private onUncaughtError?: (error: unknown) => void;\n  private clientInfo: ClientConfiguration;\n  private requestMessageId = 0;\n  private responseHandlers: Map<\n    number,\n    (response: JSONRPCResponse | Error) => void\n  > = new Map();\n  private serverCapabilities: ServerCapabilities = {};\n  private isClosed = true;\n\n  constructor({\n    transport: transportConfig,\n    name = 'ai-sdk-mcp-client',\n    onUncaughtError,\n  }: MCPClientConfig) {\n    this.onUncaughtError = onUncaughtError;\n\n    if (isCustomMcpTransport(transportConfig)) {\n      this.transport = transportConfig;\n    } else {\n      this.transport = createMcpTransport(transportConfig);\n    }\n\n    this.transport.onclose = () => this.onClose();\n    this.transport.onerror = (error: Error) => this.onError(error);\n    this.transport.onmessage = message => {\n      if ('method' in message) {\n        // This lightweight client implementation does not support\n        // receiving notifications or requests from server.\n        // If we get an unsupported message, we can safely ignore it and pass to the onError handler:\n        this.onError(\n          new MCPClientError({\n            message: 'Unsupported message type',\n          }),\n        );\n        return;\n      }\n\n      this.onResponse(message);\n    };\n\n    this.clientInfo = {\n      name,\n      version: CLIENT_VERSION,\n    };\n  }\n\n  async init(): Promise<this> {\n    try {\n      await this.transport.start();\n      this.isClosed = false;\n\n      const result = await this.request({\n        request: {\n          method: 'initialize',\n          params: {\n            protocolVersion: LATEST_PROTOCOL_VERSION,\n            capabilities: {},\n            clientInfo: this.clientInfo,\n          },\n        },\n        resultSchema: InitializeResultSchema,\n      });\n\n      if (result === undefined) {\n        throw new MCPClientError({\n          message: 'Server sent invalid initialize result',\n        });\n      }\n\n      if (!SUPPORTED_PROTOCOL_VERSIONS.includes(result.protocolVersion)) {\n        throw new MCPClientError({\n          message: `Server's protocol version is not supported: ${result.protocolVersion}`,\n        });\n      }\n\n      this.serverCapabilities = result.capabilities;\n\n      // Complete initialization handshake:\n      await this.notification({\n        method: 'notifications/initialized',\n      });\n\n      return this;\n    } catch (error) {\n      await this.close();\n      throw error;\n    }\n  }\n\n  async close(): Promise<void> {\n    if (this.isClosed) return;\n    await this.transport?.close();\n    this.onClose();\n  }\n\n  private assertCapability(method: string): void {\n    switch (method) {\n      case 'initialize':\n        break;\n      case 'tools/list':\n      case 'tools/call':\n        if (!this.serverCapabilities.tools) {\n          throw new MCPClientError({\n            message: `Server does not support tools`,\n          });\n        }\n        break;\n      default:\n        throw new MCPClientError({\n          message: `Unsupported method: ${method}`,\n        });\n    }\n  }\n\n  private async request<T extends ZodType<object>>({\n    request,\n    resultSchema,\n    options,\n  }: {\n    request: Request;\n    resultSchema: T;\n    options?: RequestOptions;\n  }): Promise<z.infer<T>> {\n    return new Promise((resolve, reject) => {\n      if (this.isClosed) {\n        return reject(\n          new MCPClientError({\n            message: 'Attempted to send a request from a closed client',\n          }),\n        );\n      }\n\n      this.assertCapability(request.method);\n\n      const signal = options?.signal;\n      signal?.throwIfAborted();\n\n      const messageId = this.requestMessageId++;\n      const jsonrpcRequest: JSONRPCRequest = {\n        ...request,\n        jsonrpc: '2.0',\n        id: messageId,\n      };\n\n      const cleanup = () => {\n        this.responseHandlers.delete(messageId);\n      };\n\n      this.responseHandlers.set(messageId, response => {\n        if (signal?.aborted) {\n          return reject(\n            new MCPClientError({\n              message: 'Request was aborted',\n              cause: signal.reason,\n            }),\n          );\n        }\n\n        if (response instanceof Error) {\n          return reject(response);\n        }\n\n        try {\n          const result = resultSchema.parse(response.result);\n          resolve(result);\n        } catch (error) {\n          const parseError = new MCPClientError({\n            message: 'Failed to parse server response',\n            cause: error,\n          });\n          reject(parseError);\n        }\n      });\n\n      this.transport.send(jsonrpcRequest).catch(error => {\n        cleanup();\n        reject(error);\n      });\n    });\n  }\n\n  private async listTools({\n    params,\n    options,\n  }: {\n    params?: PaginatedRequest['params'];\n    options?: RequestOptions;\n  } = {}): Promise<ListToolsResult> {\n    try {\n      return this.request({\n        request: { method: 'tools/list', params },\n        resultSchema: ListToolsResultSchema,\n        options,\n      });\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  private async callTool({\n    name,\n    args,\n    options,\n  }: {\n    name: string;\n    args: Record<string, unknown>;\n    options?: ToolCallOptions;\n  }): Promise<CallToolResult> {\n    try {\n      return this.request({\n        request: { method: 'tools/call', params: { name, arguments: args } },\n        resultSchema: CallToolResultSchema,\n        options: {\n          signal: options?.abortSignal,\n        },\n      });\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  private async notification(notification: Notification): Promise<void> {\n    const jsonrpcNotification: JSONRPCNotification = {\n      ...notification,\n      jsonrpc: '2.0',\n    };\n    await this.transport.send(jsonrpcNotification);\n  }\n\n  /**\n   * Returns a set of AI SDK tools from the MCP server\n   * @returns A record of tool names to their implementations\n   */\n  async tools<TOOL_SCHEMAS extends ToolSchemas = 'automatic'>({\n    schemas = 'automatic',\n  }: {\n    schemas?: TOOL_SCHEMAS;\n  } = {}): Promise<McpToolSet<TOOL_SCHEMAS>> {\n    const tools: Record<string, Tool> = {};\n\n    try {\n      const listToolsResult = await this.listTools();\n\n      for (const { name, description, inputSchema } of listToolsResult.tools) {\n        if (schemas !== 'automatic' && !(name in schemas)) {\n          continue;\n        }\n\n        const parameters =\n          schemas === 'automatic'\n            ? jsonSchema({\n                ...inputSchema,\n                properties: inputSchema.properties ?? {},\n                additionalProperties: false,\n              } as JSONSchema7)\n            : schemas[name].parameters;\n\n        const self = this;\n        const toolWithExecute = tool({\n          description,\n          parameters,\n          execute: async (\n            args: any,\n            options: ToolCallOptions,\n          ): Promise<CallToolResult> => {\n            options?.abortSignal?.throwIfAborted();\n\n            return self.callTool({\n              name,\n              args,\n              options,\n            });\n          },\n        });\n\n        tools[name] = toolWithExecute;\n      }\n\n      return tools as McpToolSet<TOOL_SCHEMAS>;\n    } catch (error) {\n      throw error;\n    }\n  }\n\n  private onClose(): void {\n    if (this.isClosed) return;\n\n    this.isClosed = true;\n    const error = new MCPClientError({\n      message: 'Connection closed',\n    });\n\n    for (const handler of this.responseHandlers.values()) {\n      handler(error);\n    }\n\n    this.responseHandlers.clear();\n  }\n\n  private onError(error: unknown): void {\n    if (this.onUncaughtError) {\n      this.onUncaughtError(error);\n    }\n  }\n\n  private onResponse(response: JSONRPCResponse | JSONRPCError): void {\n    const messageId = Number(response.id);\n    const handler = this.responseHandlers.get(messageId);\n\n    if (handler === undefined) {\n      throw new MCPClientError({\n        message: `Protocol error: Received a response for an unknown message ID: ${JSON.stringify(\n          response,\n        )}`,\n      });\n    }\n\n    this.responseHandlers.delete(messageId);\n\n    handler(\n      'result' in response\n        ? response\n        : new MCPClientError({\n            message: response.error.message,\n            cause: response.error,\n          }),\n    );\n  }\n}\n","import { JSONObject, JSONValue } from '@ai-sdk/provider';\nimport { Schema } from '@ai-sdk/provider-utils';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4/core';\nimport { ModelMessage } from '../prompt/message';\nimport { ToolResultContent } from '../prompt/tool-result-content';\n\nexport type ToolParameters<T = JSONObject> =\n  | z4.$ZodType<T>\n  | z3.Schema<T>\n  | Schema<T>;\n\nexport interface ToolCallOptions {\n  /**\n   * The ID of the tool call. You can use it e.g. when sending tool-call related information with stream data.\n   */\n  toolCallId: string;\n\n  /**\n   * Messages that were sent to the language model to initiate the response that contained the tool call.\n   * The messages **do not** include the system prompt nor the assistant response that contained the tool call.\n   */\n  messages: ModelMessage[];\n\n  /**\n   * An optional abort signal that indicates that the overall operation should be aborted.\n   */\n  abortSignal?: AbortSignal;\n}\n\ntype NeverOptional<N, T> = 0 extends 1 & N\n  ? Partial<T>\n  : [N] extends [never]\n    ? Partial<Record<keyof T, undefined>>\n    : T;\n\n/**\nA tool contains the description and the schema of the input that the tool expects.\nThis enables the language model to generate the input.\n\nThe tool can also contain an optional execute function for the actual execution function of the tool.\n */\nexport type Tool<\n  PARAMETERS extends JSONValue | unknown | never = any,\n  RESULT = any,\n> = {\n  /**\nAn optional description of what the tool does.\nWill be used by the language model to decide whether to use the tool.\nNot used for provider-defined tools.\n   */\n  description?: string;\n} & NeverOptional<\n  PARAMETERS,\n  {\n    /**\nThe schema of the input that the tool expects. The language model will use this to generate the input.\nIt is also used to validate the output of the language model.\nUse descriptions to make the input understandable for the language model.\n   */\n    parameters: ToolParameters<PARAMETERS>;\n  }\n> &\n  NeverOptional<\n    RESULT,\n    {\n      /**\nAn async function that is called with the arguments from the tool call and produces a result.\nIf not provided, the tool will not be executed automatically.\n\n@args is the input of the tool call.\n@options.abortSignal is a signal that can be used to abort the tool call.\n      */\n      execute: (\n        args: [PARAMETERS] extends [never] ? undefined : PARAMETERS,\n        options: ToolCallOptions,\n      ) => PromiseLike<RESULT>;\n\n      /**\n  Optional conversion function that maps the tool result to multi-part tool content for LLMs.\n      */\n      experimental_toToolResultContent?: (result: RESULT) => ToolResultContent;\n\n      /**\n       * Optional function that is called when the argument streaming starts.\n       * Only called when the tool is used in a streaming context.\n       */\n      onArgsStreamingStart?: (\n        options: ToolCallOptions,\n      ) => void | PromiseLike<void>;\n\n      /**\n       * Optional function that is called when an argument streaming delta is available.\n       * Only called when the tool is used in a streaming context.\n       */\n      onArgsStreamingDelta?: (\n        options: {\n          argsTextDelta: string;\n        } & ToolCallOptions,\n      ) => void | PromiseLike<void>;\n\n      /**\n       * Optional function that is called when a tool call can be started,\n       * even if the execute function is not provided.\n       */\n      onArgsAvailable?: (\n        options: {\n          args: [PARAMETERS] extends [never] ? undefined : PARAMETERS;\n        } & ToolCallOptions,\n      ) => void | PromiseLike<void>;\n    }\n  > &\n  (\n    | {\n        /**\nFunction tool.\n     */\n        type?: undefined | 'function';\n      }\n    | {\n        /**\nProvider-defined tool.\n     */\n        type: 'provider-defined';\n\n        /**\nThe ID of the tool. Should follow the format `<provider-name>.<tool-name>`.\n     */\n        id: `${string}.${string}`;\n\n        /**\nThe arguments for configuring the tool. Must match the expected arguments defined by the provider for this tool.\n     */\n        args: Record<string, unknown>;\n      }\n  );\n\n/**\nHelper function for inferring the execute args of a tool.\n */\n// Note: overload order is important for auto-completion\nexport function tool<PARAMETERS, RESULT>(\n  tool: Tool<PARAMETERS, RESULT>,\n): Tool<PARAMETERS, RESULT>;\nexport function tool<PARAMETERS>(\n  tool: Tool<PARAMETERS, never>,\n): Tool<PARAMETERS, never>;\nexport function tool<RESULT>(tool: Tool<never, RESULT>): Tool<never, RESULT>;\nexport function tool(tool: Tool<never, never>): Tool<never, never>;\nexport function tool(tool: any): any {\n  return tool;\n}\n\nexport type MappedTool<T extends Tool | JSONObject, RESULT extends any> =\n  T extends Tool<infer P>\n    ? Tool<P, RESULT>\n    : T extends JSONObject\n      ? Tool<T, RESULT>\n      : never;\n","import { createEventSourceParserStream } from '@ai-sdk/provider-utils';\nimport { MCPClientError } from '../../../src/error/mcp-client-error';\nimport { JSONRPCMessage, JSONRPCMessageSchema } from './json-rpc-message';\nimport { MCPTransport } from './mcp-transport';\n\nexport class SseMCPTransport implements MCPTransport {\n  private endpoint?: URL;\n  private abortController?: AbortController;\n  private url: URL;\n  private connected = false;\n  private sseConnection?: {\n    close: () => void;\n  };\n  private headers?: Record<string, string>;\n\n  onclose?: () => void;\n  onerror?: (error: unknown) => void;\n  onmessage?: (message: JSONRPCMessage) => void;\n\n  constructor({\n    url,\n    headers,\n  }: {\n    url: string;\n    headers?: Record<string, string>;\n  }) {\n    this.url = new URL(url);\n    this.headers = headers;\n  }\n\n  async start(): Promise<void> {\n    return new Promise<void>((resolve, reject) => {\n      if (this.connected) {\n        return resolve();\n      }\n\n      this.abortController = new AbortController();\n\n      const establishConnection = async () => {\n        try {\n          const headers = new Headers(this.headers);\n          headers.set('Accept', 'text/event-stream');\n          const response = await fetch(this.url.href, {\n            headers,\n            signal: this.abortController?.signal,\n          });\n\n          if (!response.ok || !response.body) {\n            const error = new MCPClientError({\n              message: `MCP SSE Transport Error: ${response.status} ${response.statusText}`,\n            });\n            this.onerror?.(error);\n            return reject(error);\n          }\n\n          const stream = response.body\n            .pipeThrough(new TextDecoderStream())\n            .pipeThrough(createEventSourceParserStream());\n\n          const reader = stream.getReader();\n\n          const processEvents = async () => {\n            try {\n              while (true) {\n                const { done, value } = await reader.read();\n\n                if (done) {\n                  if (this.connected) {\n                    this.connected = false;\n                    throw new MCPClientError({\n                      message:\n                        'MCP SSE Transport Error: Connection closed unexpectedly',\n                    });\n                  }\n                  return;\n                }\n\n                const { event, data } = value;\n\n                if (event === 'endpoint') {\n                  this.endpoint = new URL(data, this.url);\n\n                  if (this.endpoint.origin !== this.url.origin) {\n                    throw new MCPClientError({\n                      message: `MCP SSE Transport Error: Endpoint origin does not match connection origin: ${this.endpoint.origin}`,\n                    });\n                  }\n\n                  this.connected = true;\n                  resolve();\n                } else if (event === 'message') {\n                  try {\n                    const message = JSONRPCMessageSchema.parse(\n                      JSON.parse(data),\n                    );\n                    this.onmessage?.(message);\n                  } catch (error) {\n                    const e = new MCPClientError({\n                      message:\n                        'MCP SSE Transport Error: Failed to parse message',\n                      cause: error,\n                    });\n                    this.onerror?.(e);\n                    // We do not throw here so we continue processing events after reporting the error\n                  }\n                }\n              }\n            } catch (error) {\n              if (error instanceof Error && error.name === 'AbortError') {\n                return;\n              }\n\n              this.onerror?.(error);\n              reject(error);\n            }\n          };\n\n          this.sseConnection = {\n            close: () => reader.cancel(),\n          };\n\n          processEvents();\n        } catch (error) {\n          if (error instanceof Error && error.name === 'AbortError') {\n            return;\n          }\n\n          this.onerror?.(error);\n          reject(error);\n        }\n      };\n\n      establishConnection();\n    });\n  }\n\n  async close(): Promise<void> {\n    this.connected = false;\n    this.sseConnection?.close();\n    this.abortController?.abort();\n    this.onclose?.();\n  }\n\n  async send(message: JSONRPCMessage): Promise<void> {\n    if (!this.endpoint || !this.connected) {\n      throw new MCPClientError({\n        message: 'MCP SSE Transport Error: Not connected',\n      });\n    }\n\n    try {\n      const headers = new Headers(this.headers);\n      headers.set('Content-Type', 'application/json');\n      const init = {\n        method: 'POST',\n        headers,\n        body: JSON.stringify(message),\n        signal: this.abortController?.signal,\n      };\n\n      const response = await fetch(this.endpoint, init);\n\n      if (!response.ok) {\n        const text = await response.text().catch(() => null);\n        const error = new MCPClientError({\n          message: `MCP SSE Transport Error: POSTing to endpoint (HTTP ${response.status}): ${text}`,\n        });\n        this.onerror?.(error);\n        return;\n      }\n    } catch (error) {\n      this.onerror?.(error);\n      return;\n    }\n  }\n}\n\nexport function deserializeMessage(line: string): JSONRPCMessage {\n  return JSONRPCMessageSchema.parse(JSON.parse(line));\n}\n","import { z } from 'zod';\nimport { BaseParamsSchema, RequestSchema, ResultSchema } from './types';\n\nconst JSONRPC_VERSION = '2.0';\n\nconst JSONRPCRequestSchema = z\n  .object({\n    jsonrpc: z.literal(JSONRPC_VERSION),\n    id: z.union([z.string(), z.number().int()]),\n  })\n  .merge(RequestSchema)\n  .strict();\n\nexport type JSONRPCRequest = z.infer<typeof JSONRPCRequestSchema>;\n\nconst JSONRPCResponseSchema = z\n  .object({\n    jsonrpc: z.literal(JSONRPC_VERSION),\n    id: z.union([z.string(), z.number().int()]),\n    result: ResultSchema,\n  })\n  .strict();\n\nexport type JSONRPCResponse = z.infer<typeof JSONRPCResponseSchema>;\n\nconst JSONRPCErrorSchema = z\n  .object({\n    jsonrpc: z.literal(JSONRPC_VERSION),\n    id: z.union([z.string(), z.number().int()]),\n    error: z.object({\n      code: z.number().int(),\n      message: z.string(),\n      data: z.optional(z.unknown()),\n    }),\n  })\n  .strict();\n\nexport type JSONRPCError = z.infer<typeof JSONRPCErrorSchema>;\n\nconst JSONRPCNotificationSchema = z\n  .object({\n    jsonrpc: z.literal(JSONRPC_VERSION),\n  })\n  .merge(\n    z.object({\n      method: z.string(),\n      params: z.optional(BaseParamsSchema),\n    }),\n  )\n  .strict();\n\nexport type JSONRPCNotification = z.infer<typeof JSONRPCNotificationSchema>;\n\nexport const JSONRPCMessageSchema = z.union([\n  JSONRPCRequestSchema,\n  JSONRPCNotificationSchema,\n  JSONRPCResponseSchema,\n  JSONRPCErrorSchema,\n]);\n\nexport type JSONRPCMessage = z.infer<typeof JSONRPCMessageSchema>;\n","import { z } from 'zod';\nimport { MappedTool, Tool, ToolParameters } from '../tool';\nimport { JSONObject } from '@ai-sdk/provider';\n\nexport const LATEST_PROTOCOL_VERSION = '2024-11-05';\nexport const SUPPORTED_PROTOCOL_VERSIONS = [\n  LATEST_PROTOCOL_VERSION,\n  '2024-10-07',\n];\n\nexport type ToolSchemas =\n  | Record<string, { parameters: ToolParameters<JSONObject | unknown> }>\n  | 'automatic'\n  | undefined;\n\nexport type McpToolSet<TOOL_SCHEMAS extends ToolSchemas = 'automatic'> =\n  TOOL_SCHEMAS extends Record<string, { parameters: ToolParameters<unknown> }>\n    ? {\n        [K in keyof TOOL_SCHEMAS]: MappedTool<TOOL_SCHEMAS[K], CallToolResult> &\n          Required<\n            Pick<MappedTool<TOOL_SCHEMAS[K], CallToolResult>, 'execute'>\n          >;\n      }\n    : McpToolSet<Record<string, { parameters: ToolParameters<unknown> }>>;\n\nconst ClientOrServerImplementationSchema = z\n  .object({\n    name: z.string(),\n    version: z.string(),\n  })\n  .passthrough();\nexport type Configuration = z.infer<typeof ClientOrServerImplementationSchema>;\n\nexport const BaseParamsSchema = z\n  .object({\n    _meta: z.optional(z.object({}).passthrough()),\n  })\n  .passthrough();\ntype BaseParams = z.infer<typeof BaseParamsSchema>;\nexport const ResultSchema = BaseParamsSchema;\n\nexport const RequestSchema = z.object({\n  method: z.string(),\n  params: z.optional(BaseParamsSchema),\n});\nexport type Request = z.infer<typeof RequestSchema>;\nexport type RequestOptions = {\n  signal?: AbortSignal;\n  timeout?: number;\n  maxTotalTimeout?: number;\n};\n\nexport type Notification = z.infer<typeof RequestSchema>;\n\nconst ServerCapabilitiesSchema = z\n  .object({\n    experimental: z.optional(z.object({}).passthrough()),\n    logging: z.optional(z.object({}).passthrough()),\n    prompts: z.optional(\n      z\n        .object({\n          listChanged: z.optional(z.boolean()),\n        })\n        .passthrough(),\n    ),\n    resources: z.optional(\n      z\n        .object({\n          subscribe: z.optional(z.boolean()),\n          listChanged: z.optional(z.boolean()),\n        })\n        .passthrough(),\n    ),\n    tools: z.optional(\n      z\n        .object({\n          listChanged: z.optional(z.boolean()),\n        })\n        .passthrough(),\n    ),\n  })\n  .passthrough();\nexport type ServerCapabilities = z.infer<typeof ServerCapabilitiesSchema>;\n\nexport const InitializeResultSchema = ResultSchema.extend({\n  protocolVersion: z.string(),\n  capabilities: ServerCapabilitiesSchema,\n  serverInfo: ClientOrServerImplementationSchema,\n  instructions: z.optional(z.string()),\n});\nexport type InitializeResult = z.infer<typeof InitializeResultSchema>;\n\nexport type PaginatedRequest = Request & {\n  params?: BaseParams & {\n    cursor?: string;\n  };\n};\n\nconst PaginatedResultSchema = ResultSchema.extend({\n  nextCursor: z.optional(z.string()),\n});\n\nconst ToolSchema = z\n  .object({\n    name: z.string(),\n    description: z.optional(z.string()),\n    inputSchema: z\n      .object({\n        type: z.literal('object'),\n        properties: z.optional(z.object({}).passthrough()),\n      })\n      .passthrough(),\n  })\n  .passthrough();\nexport type MCPTool = z.infer<typeof ToolSchema>;\nexport const ListToolsResultSchema = PaginatedResultSchema.extend({\n  tools: z.array(ToolSchema),\n});\nexport type ListToolsResult = z.infer<typeof ListToolsResultSchema>;\n\nconst TextContentSchema = z\n  .object({\n    type: z.literal('text'),\n    text: z.string(),\n  })\n  .passthrough();\nconst ImageContentSchema = z\n  .object({\n    type: z.literal('image'),\n    data: z.string().base64(),\n    mimeType: z.string(),\n  })\n  .passthrough();\nconst ResourceContentsSchema = z\n  .object({\n    /**\n     * The URI of this resource.\n     */\n    uri: z.string(),\n    /**\n     * The MIME type of this resource, if known.\n     */\n    mimeType: z.optional(z.string()),\n  })\n  .passthrough();\nconst TextResourceContentsSchema = ResourceContentsSchema.extend({\n  text: z.string(),\n});\nconst BlobResourceContentsSchema = ResourceContentsSchema.extend({\n  blob: z.string().base64(),\n});\nconst EmbeddedResourceSchema = z\n  .object({\n    type: z.literal('resource'),\n    resource: z.union([TextResourceContentsSchema, BlobResourceContentsSchema]),\n  })\n  .passthrough();\n\nexport const CallToolResultSchema = ResultSchema.extend({\n  content: z.array(\n    z.union([TextContentSchema, ImageContentSchema, EmbeddedResourceSchema]),\n  ),\n  isError: z.boolean().default(false).optional(),\n}).or(\n  ResultSchema.extend({\n    toolResult: z.unknown(),\n  }),\n);\nexport type CallToolResult = z.infer<typeof CallToolResultSchema>;\n","import { MCPClientError } from '../../../src/error/mcp-client-error';\nimport { JSONRPCMessage } from './json-rpc-message';\nimport { SseMCPTransport } from './mcp-sse-transport';\n\n/**\n * Transport interface for MCP (Model Context Protocol) communication.\n * Maps to the `Transport` interface in the MCP spec.\n */\nexport interface MCPTransport {\n  /**\n   * Initialize and start the transport\n   */\n  start(): Promise<void>;\n\n  /**\n   * Send a JSON-RPC message through the transport\n   * @param message The JSON-RPC message to send\n   */\n  send(message: JSONRPCMessage): Promise<void>;\n\n  /**\n   * Clean up and close the transport\n   */\n  close(): Promise<void>;\n\n  /**\n   * Event handler for transport closure\n   */\n  onclose?: () => void;\n\n  /**\n   * Event handler for transport errors\n   */\n  onerror?: (error: Error) => void;\n\n  /**\n   * Event handler for received messages\n   */\n  onmessage?: (message: JSONRPCMessage) => void;\n}\n\nexport type MCPTransportConfig = {\n  type: 'sse';\n\n  /**\n   * The URL of the MCP server.\n   */\n  url: string;\n\n  /**\n   * Additional HTTP headers to be sent with requests.\n   */\n  headers?: Record<string, string>;\n};\n\nexport function createMcpTransport(config: MCPTransportConfig): MCPTransport {\n  if (config.type !== 'sse') {\n    throw new MCPClientError({\n      message:\n        'Unsupported or invalid transport configuration. If you are using a custom transport, make sure it implements the MCPTransport interface.',\n    });\n  }\n\n  return new SseMCPTransport(config);\n}\n\nexport function isCustomMcpTransport(\n  transport: MCPTransportConfig | MCPTransport,\n): transport is MCPTransport {\n  return (\n    'start' in transport &&\n    typeof transport.start === 'function' &&\n    'send' in transport &&\n    typeof transport.send === 'function' &&\n    'close' in transport &&\n    typeof transport.close === 'function'\n  );\n}\n","import { AISDKError } from '@ai-sdk/provider';\nimport { TranscriptionModelResponseMetadata } from '../../core/types/transcription-model-response-metadata';\n\n/**\nError that is thrown when no transcript was generated.\n */\nexport class NoTranscriptGeneratedError extends AISDKError {\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n\n  constructor(options: {\n    responses: Array<TranscriptionModelResponseMetadata>;\n  }) {\n    super({\n      name: 'AI_NoTranscriptGeneratedError',\n      message: 'No transcript generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n","import { JSONValue, TranscriptionModelV1 } from '@ai-sdk/provider';\nimport { NoTranscriptGeneratedError } from '../../src/error/no-transcript-generated-error';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../../src/util/detect-media-type';\nimport { download } from '../../src/util/download';\nimport { prepareRetries } from '../../src/util/prepare-retries';\nimport { DataContent } from '../prompt';\nimport { convertDataContentToUint8Array } from '../prompt/data-content';\nimport { ProviderOptions } from '../types/provider-metadata';\nimport { TranscriptionWarning } from '../types/transcription-model';\nimport { TranscriptionModelResponseMetadata } from '../types/transcription-model-response-metadata';\nimport { TranscriptionResult } from './transcribe-result';\n\n/**\nGenerates transcripts using a transcription model.\n\n@param model - The transcription model to use.\n@param audio - The audio data to transcribe as DataContent (string | Uint8Array | ArrayBuffer | Buffer) or a URL.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated transcript.\n */\nexport async function transcribe({\n  model,\n  audio,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe transcription model to use.\n     */\n  model: TranscriptionModelV1;\n\n  /**\nThe audio data to transcribe.\n   */\n  audio: DataContent | URL;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {\n    \"temperature\": 0\n  }\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per transcript model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<TranscriptionResult> {\n  const { retry } = prepareRetries({ maxRetries: maxRetriesArg });\n  const audioData =\n    audio instanceof URL\n      ? (await download({ url: audio })).data\n      : convertDataContentToUint8Array(audio);\n\n  const result = await retry(() =>\n    model.doGenerate({\n      audio: audioData,\n      abortSignal,\n      headers,\n      providerOptions,\n      mediaType:\n        detectMediaType({\n          data: audioData,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/wav',\n    }),\n  );\n\n  if (!result.text) {\n    throw new NoTranscriptGeneratedError({ responses: [result.response] });\n  }\n\n  return new DefaultTranscriptionResult({\n    text: result.text,\n    segments: result.segments,\n    language: result.language,\n    durationInSeconds: result.durationInSeconds,\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultTranscriptionResult implements TranscriptionResult {\n  readonly text: string;\n  readonly segments: Array<{\n    text: string;\n    startSecond: number;\n    endSecond: number;\n  }>;\n  readonly language: string | undefined;\n  readonly durationInSeconds: number | undefined;\n  readonly warnings: Array<TranscriptionWarning>;\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    text: string;\n    segments: Array<{\n      text: string;\n      startSecond: number;\n      endSecond: number;\n    }>;\n    language: string | undefined;\n    durationInSeconds: number | undefined;\n    warnings: Array<TranscriptionWarning>;\n    responses: Array<TranscriptionModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.text = options.text;\n    this.segments = options.segments;\n    this.language = options.language;\n    this.durationInSeconds = options.durationInSeconds;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n"],"names":["asSchema","createIdGenerator","generateId","jsonSchema","AISDKError","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","text","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","getErrorMessage","name","marker","symbol","_a","AISDKError","getErrorMessage","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","AISDKError","name","marker","symbol","_a","fetch","_a","name","_a","parseJsonEventStream","getOriginalFetch","fetch","_a","parseJsonEventStream","part","generateId","_a","_a","processBlock","tool","getOriginalFetch","fetch","_a","isContinuation","_a","delay","APICallError","getErrorMessage","getErrorMessage","APICallError","_a","name","name","attributes","_a","embedding","usage","embeddings","_a","usage","convertBase64ToUint8Array","_a","JSONParseError","TypeValidationError","safeParseJSON","content","_a","AISDKError","convertBase64ToUint8Array","convertUint8ArrayToBase64","z","z","_a","AISDKError","convertUint8ArrayToBase64","convertBase64ToUint8Array","_a","InvalidPromptError","z","z","z","z","z","z","z","z","z","InvalidPromptError","z","AISDKError","TypeValidationError","UnsupportedFunctionalityError","safeValidateTypes","UnsupportedFunctionalityError","safeValidateTypes","_a","TypeValidationError","generateId","_a","span","result","text","safeParseJSON","object","JSONParseError","TypeValidationError","createIdGenerator","_a","_a","originalGenerateId","createIdGenerator","generateId","now","doStreamSpan","object","_a","error","AISDKError","text","_a","createIdGenerator","asSchema","object","name","tool","asSchema","asSchema","safeParseJSON","safeValidateTypes","asSchema","tool","safeValidateTypes","safeParseJSON","_a","tool","originalGenerateId","createIdGenerator","generateId","_a","callSettings","tool","span","_b","_c","_d","_e","result","asSchema","safeParseJSON","safeValidateTypes","text","asSchema","safeParseJSON","safeValidateTypes","InvalidArgumentError","delay","createIdGenerator","tool","originalGenerateId","createIdGenerator","now","generateId","text","_a","includeRawChunks","stream","tool","doStreamSpan","activeReasoningPart","_b","_c","_d","text","text","NoSuchModelError","AISDKError","NoSuchModelError","name","marker","symbol","_a","NoSuchModelError","NoSuchModelError","_a","tool","z","z","z","_a","_b","_c","text","name","_a","AISDKError","_a"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AEAA,SAAS,kBAAkB;;AmBA3B,SAAS,4BAAyC;;;ACAlD,SAAS,SAAS;;A8BAlB,SAAiB,aAAa;;AiBA9B,SAAS,eAAe;;;;;;;;;;;AnEExB,IAAM,OAAO;AACb,IAAM,SAAS,CAAA,gBAAA,EAAmB,IAAI,EAAA;AACtC,IAAM,SAAS,OAAO,GAAA,CAAI,MAAM;AAJhC,IAAA;AAMO,IAAM,uBAAN,wKAAmC,aAAA,CAAW;IAMnD,YAAY,EACV,SAAA,EACA,KAAA,EACA,OAAA,EACF,CAIG;QACD,KAAA,CAAM;YACJ;YACA,SAAS,CAAA,+BAAA,EAAkC,SAAS,CAAA,EAAA,EAAK,OAAO,EAAA;QAClE,CAAC;QAjBH,IAAA,CAAkB,GAAA,GAAU;QAmB1B,IAAA,CAAK,SAAA,GAAY;QACjB,IAAA,CAAK,KAAA,GAAQ;IACf;IAEA,OAAO,WAAW,KAAA,EAA+C;QAC/D,gKAAO,cAAA,CAAW,SAAA,CAAU,OAAO,MAAM;IAC3C;AACF;AA1BoB,KAAA;;ACJpB,IAAMM,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AALhC,IAAAE;AAOO,IAAM,yBAAN,wKAAqCJ,aAAAA,CAAW;IAKrD,YAAY,EACV,KAAA,EACA,OAAA,EACF,CAGG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAXzB,IAAA,CAAkBG,IAAAA,GAAU;QAa1B,IAAA,CAAK,KAAA,GAAQ;IACf;IAEA,OAAO,WAAW,KAAA,EAAiD;QACjE,OAAOJ,uKAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AAnBoBE,MAAAD;;ACNpB,IAAMG,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AAJhC,IAAAE;AAMO,IAAM,4BAAN,wKAAwCJ,aAAAA,CAAW;IAMxD,YAAY,EACV,QAAA,EACA,QAAA,EACA,KAAA,EACA,UAAU,CAAA,2BAAA,EAA8B,QAAQ,CAAA,EAAA,+JAAK,mBAAA,EACnD,QACD,EACH,CAKG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QAlBhC,IAAA,CAAkBG,IAAAA,GAAU;QAoB1B,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,QAAA,GAAW;IAClB;IAEA,OAAO,WAAW,KAAA,EAAoD;QACpE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AA3BoBE,MAAAD;;ACLpB,IAAMG,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AAJhC,IAAAE;AASO,IAAM,iBAAN,wKAA6BJ,aAAAA,CAAW;IAG7C,YAAY,EACV,MAAAC,SAAO,gBAAA,EACP,OAAA,EACA,KAAA,EACF,CAIG;QACD,KAAA,CAAM;YAAE,MAAAA;YAAM;YAAS;QAAM,CAAC;QAXhC,IAAA,CAAkBG,IAAAA,GAAU;IAY5B;IAEA,OAAO,WAAW,KAAA,EAAyC;QACzD,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AAjBoBE,MAAAD;;ACPpB,IAAMG,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AALhC,IAAAE;AAaO,IAAM,wBAAN,wKAAoCJ,aAAAA,CAAW;IAQpD,YAAY,EACV,UAAU,qBAAA,EACV,KAAA,EACA,SAAA,EACF,CAIG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QAhBhC,IAAA,CAAkBG,IAAAA,GAAU;QAkB1B,IAAA,CAAK,SAAA,GAAY;IACnB;IAEA,OAAO,WAAW,KAAA,EAAgD;QAChE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AAxBoBE,MAAAD;;ACTpB,IAAMG,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AAPhC,IAAAE;AAoBO,IAAM,yBAAN,cAAqCJ,uKAAAA,CAAW;IAuBrD,YAAY,EACV,UAAU,sBAAA,EACV,KAAA,EACA,MAAAK,KAAAA,EACA,QAAA,EACA,KAAA,EACA,YAAA,EACF,CAOG;QACD,KAAA,CAAM;YAAE,MAAAJ;YAAM;YAAS;QAAM,CAAC;QArChC,IAAA,CAAkBG,IAAAA,GAAU;QAuC1B,IAAA,CAAK,IAAA,GAAOC;QACZ,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,KAAA,GAAQ;QACb,IAAA,CAAK,YAAA,GAAe;IACtB;IAEA,OAAO,WAAW,KAAA,EAAiD;QACjE,iKAAOL,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AAhDoBE,MAAAD;;ACnBpB,IAAMI,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AAJhC,IAAAE;AASO,IAAM,yBAAN,wKAAqCJ,aAAAA,CAAW;IAAA,qBAAA;IAGrD,YAAY,EAAE,UAAU,sBAAA,CAAuB,CAAA,GAA0B,CAAC,CAAA,CAAG;QAC3E,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAHzB,IAAA,CAAkBG,IAAAA,GAAU;IAI5B;IAEA,OAAO,WAAW,KAAA,EAAiD;QACjE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AAToBE,MAAAD;;ACRpB,IAAMG,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AAJhC,IAAAE;AAMO,IAAM,kBAAN,wKAA8BJ,aAAAA,CAAW;IAM9C,YAAY,EACV,QAAA,EACA,iBAAiB,KAAA,CAAA,EACjB,UAAU,CAAA,sCAAA,EAAyC,QAAQ,CAAA,GAAA,EACzD,mBAAmB,KAAA,IACf,4BACA,CAAA,iBAAA,EAAoB,eAAe,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CACnD,EAAA,EACF,CAIG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAlBzB,IAAA,CAAkBG,IAAAA,GAAU;QAoB1B,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,cAAA,GAAiB;IACxB;IAEA,OAAO,WAAW,KAAA,EAA0C;QAC1D,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,OAAM;IAC3C;AACF;AA3BoBE,MAAAD;;ACHpB,IAAMI,QAAO;AACb,IAAMC,UAAS,CAAA,gBAAA,EAAmBD,KAAI,EAAA;AACtC,IAAME,UAAS,OAAO,GAAA,CAAID,OAAM;AANhC,IAAAE;AAQO,IAAM,sBAAN,wKAAkCL,aAAAA,CAAW;IAKlD,YAAY,EACV,KAAA,EACA,aAAA,EACA,UAAU,CAAA,2BAAA,gKAA8BC,kBAAAA,EAAgB,KAAK,CAAC,EAAA,EAChE,CAIG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QAbhC,IAAA,CAAkBG,IAAAA,GAAU;QAc1B,IAAA,CAAK,aAAA,GAAgB;IACvB;IAEA,OAAO,WAAW,KAAA,EAA8C;QAC9D,iKAAOL,aAAAA,CAAW,SAAA,CAAU,OAAOG,OAAM;IAC3C;AACF;AApBoBE,MAAAD;;ACPpB,IAAMI,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAMO,IAAM,qBAAN,wKAAiCL,aAAAA,CAAW;IAOjD,YAAY,EACV,QAAA,EACA,QAAA,EACA,UAAA,EACA,KAAA,EACA,UAAU,CAAA,qBAAA,EAAwB,QAAQ,CAAA,EAAA,+JAAKC,mBAAAA,EAAgB,KAAK,CAAC,EAAA,EACvE,CAMG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QAnBhC,IAAA,CAAkBG,KAAAA,GAAU;QAqB1B,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,UAAA,GAAa;IACpB;IAEA,OAAO,WAAW,KAAA,EAA6C;QAC7D,iKAAOL,aAAAA,CAAW,SAAA,CAAU,OAAOG,QAAM;IAC3C;AACF;AA7BoBE,OAAAD;;ACLpB,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAMO,IAAM,0BAAN,wKAAsCJ,aAAAA,CAAW;IAKtD,YAAY,EACV,OAAA,EACA,KAAA,EACA,UAAU,CAAA,4FAAA,EAA+F,OAAO,OAAO,CAAA,CAAA,CAAA,EACzH,CAIG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QAbhC,IAAA,CAAkBG,KAAAA,GAAU;QAe1B,IAAA,CAAK,OAAA,GAAU;IACjB;IAEA,OAAO,WAAW,KAAA,EAAkD;QAClE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,QAAM;IAC3C;AACF;AArBoBE,OAAAD;;ACLpB,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAMO,IAAM,0BAAN,cAAsCJ,uKAAAA,CAAW;IAKtD,YAAY,EACV,IAAA,EACA,UAAU,CAAA,uBAAA,EAA0B,IAAI,CAAA,yDAAA,CAAA,EAC1C,CAGG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAXzB,IAAA,CAAkBG,KAAAA,GAAU;QAa1B,IAAA,CAAK,IAAA,GAAO;IACd;IAEA,OAAO,WAAW,KAAA,EAAkD;QAClE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,QAAM;IAC3C;AACF;AAnBoBE,OAAAD;;ACJpB,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AALhC,IAAAE;AAOO,IAAM,yBAAN,wKAAqCJ,aAAAA,CAAW;IAKrD,YAAY,EACV,eAAA,EACA,OAAA,EACF,CAGG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAXzB,IAAA,CAAkBG,KAAAA,GAAU;QAa1B,IAAA,CAAK,eAAA,GAAkB;IACzB;IAEA,OAAO,WAAW,KAAA,EAAiD;QACjE,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,QAAM;IAC3C;AACF;AAnBoBE,OAAAD;;ACNpB,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAMO,IAAM,gBAAN,wKAA4BJ,aAAAA,CAAW;IAO5C,YAAY,EACV,GAAA,EACA,UAAA,EACA,UAAA,EACA,KAAA,EACA,UAAU,SAAS,OACf,CAAA,mBAAA,EAAsB,GAAG,CAAA,EAAA,EAAK,UAAU,CAAA,CAAA,EAAI,UAAU,EAAA,GACtD,CAAA,mBAAA,EAAsB,GAAG,CAAA,EAAA,EAAK,KAAK,EAAA,EACzC,CAMG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;YAAS;QAAM,CAAC;QArBhC,IAAA,CAAkBG,KAAAA,GAAU;QAuB1B,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,UAAA,GAAa;QAClB,IAAA,CAAK,UAAA,GAAa;IACpB;IAEA,OAAO,WAAW,KAAA,EAAwC;QACxD,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,QAAM;IAC3C;AACF;AA/BoBE,OAAAD;;ACLpB,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAWO,IAAM,aAAN,cAAyBJ,uKAAAA,CAAW;IAQzC,YAAY,EACV,OAAA,EACA,MAAA,EACA,MAAA,EACF,CAIG;QACD,KAAA,CAAM;YAAE,MAAAC;YAAM;QAAQ,CAAC;QAhBzB,IAAA,CAAkBG,KAAAA,GAAU;QAkB1B,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,MAAA,GAAS;QAGd,IAAA,CAAK,SAAA,GAAY,MAAA,CAAO,OAAO,MAAA,GAAS,CAAC,CAAA;IAC3C;IAEA,OAAO,WAAW,KAAA,EAAqC;QACrD,iKAAOJ,aAAAA,CAAW,SAAA,CAAU,OAAOE,QAAM;IAC3C;AACF;AA5BoBE,OAAAD;;ACZb,SAAS,eACd,OAAA,EACA,cAAA,EACS;IACT,MAAM,kBAAkB,IAAI,QAAQ,WAAA,OAAA,UAAW,CAAC,CAAC;IAEjD,KAAA,MAAW,CAAC,KAAK,KAAK,CAAA,IAAK,OAAO,OAAA,CAAQ,cAAc,EAAG;QACzD,IAAI,CAAC,gBAAgB,GAAA,CAAI,GAAG,GAAG;YAC7B,gBAAgB,GAAA,CAAI,KAAK,KAAK;QAChC;IACF;IAEA,OAAO;AACT;;ACXO,SAAS,yBAAyB,EACvC,MAAA,EACA,UAAA,EACA,OAAA,EACA,UAAA,EACF,EAEa;IACX,OAAO,IAAI,SAAS,WAAW,WAAA,CAAY,IAAI,kBAAkB,CAAC,GAAG;QACnE,QAAQ,UAAA,OAAA,SAAU;QAClB;QACA,SAAS,eAAe,SAAS;YAC/B,gBAAgB;QAClB,CAAC;IACH,CAAC;AACH;;ACZO,SAAS,sBAAsB,EACpC,QAAA,EACA,MAAA,EACA,UAAA,EACA,OAAA,EACA,MAAA,EACF,EAMS;IACP,SAAS,SAAA,CAAU,UAAA,OAAA,SAAU,KAAK,YAAY,OAAO;IAErD,MAAM,SAAS,OAAO,SAAA,CAAU;IAChC,MAAM,OAAO,YAAY;QACvB,IAAI;YACF,MAAO,KAAM;gBACX,MAAM,EAAE,IAAA,EAAM,KAAA,CAAM,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;gBAC1C,IAAI,MAAM;gBACV,SAAS,KAAA,CAAM,KAAK;YACtB;QACF,EAAA,OAAS,OAAO;YACd,MAAM;QACR,SAAE;YACA,SAAS,GAAA,CAAI;QACf;IACF;IAEA,KAAK;AACP;;AChCO,SAAS,yBAAyB,EACvC,QAAA,EACA,MAAA,EACA,UAAA,EACA,OAAA,EACA,UAAA,EACF,EAGwB;IACtB,sBAAsB;QACpB;QACA;QACA;QACA,SAAS,OAAO,WAAA,CACd,eAAe,SAAS;YACtB,gBAAgB;QAClB,CAAC,EAAE,OAAA,CAAQ;QAEb,QAAQ,WAAW,WAAA,CAAY,IAAI,kBAAkB,CAAC;IACxD,CAAC;AACH;;;AEfO,IAAM,8MAA4B,IAAA,CAAE,KAAA,CAAM;sLAC/C,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,MAAM;QACtB,wLAAM,IAAA,CAAE,MAAA,CAAO;IACjB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,OAAO;QACvB,6LAAW,IAAA,CAAE,MAAA,CAAO;IACtB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,2BAA2B;QAC3C,8LAAY,IAAA,CAAE,MAAA,CAAO;QACrB,4LAAU,IAAA,CAAE,MAAA,CAAO;IACrB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,iBAAiB;QACjC,8LAAY,IAAA,CAAE,MAAA,CAAO;QACrB,iMAAe,IAAA,CAAE,MAAA,CAAO;IAC1B,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,WAAW;QAC3B,6LAAY,KAAA,CAAE,MAAA,CAAO;QACrB,4LAAU,IAAA,CAAE,MAAA,CAAO;QACnB,wLAAM,IAAA,CAAE,OAAA,CAAQ;IAClB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,aAAa;QAC7B,8LAAY,IAAA,CAAE,MAAA,CAAO;QACrB,0LAAQ,IAAA,CAAE,OAAA,CAAQ;QAClB,oMAAkB,IAAA,CAAE,GAAA,CAAI,EAAE,QAAA,CAAS;IACrC,CAAC;qLACD,KAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,WAAW;QAC3B,wLAAM,IAAA,CAAE,MAAA,CAAO;QACf,oMAAkB,IAAA,CAAE,MAAA,CAAO,sLAAA,CAAE,GAAA,CAAI,CAAC,EAAE,QAAA,CAAS;IAC/C,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,YAAY;QAC5B,4LAAU,IAAA,CAAE,MAAA,CAAO;QACnB,uLAAK,IAAA,CAAE,MAAA,CAAO;QACd,yLAAO,IAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAC3B,oMAAkB,IAAA,CAAE,GAAA,CAAI,EAAE,QAAA,CAAS;IACrC,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,iBAAiB;QACjC,4LAAU,IAAA,CAAE,MAAA,CAAO;QACnB,4LAAW,KAAA,CAAE,MAAA,CAAO;QACpB,yLAAO,IAAA,CAAE,MAAA,CAAO;QAChB,4LAAU,IAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAC9B,oMAAkB,IAAA,CAAE,GAAA,CAAI,EAAE,QAAA,CAAS;IACrC,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,MAAM;QACtB,uLAAK,IAAA,CAAE,MAAA,CAAO;QACd,4LAAW,KAAA,CAAE,MAAA,CAAO;IACtB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,MAAA,CAAO,EAAE,UAAA,CAAW,OAAO;QACnC,sLAAI,IAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QACxB,wLAAM,IAAA,CAAE,OAAA,CAAQ;IAClB,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,UAAU;QAC1B,yLAAO,IAAA,CAAE,MAAA,CAAO;YAAE,4LAAU,IAAA,CAAE,OAAA,CAAQ;QAAE,CAAC;IAC3C,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,YAAY;QAC5B,4LAAU,IAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IACjC,CAAC;qLACD,KAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,aAAa;QAC7B,4LAAU,IAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IACjC,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,OAAO;QACvB,6LAAW,IAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAC/B,4LAAU,IAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IACjC,CAAC;qLACD,KAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,QAAQ;QACxB,4LAAU,IAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IACjC,CAAC;sLACD,IAAA,CAAE,MAAA,CAAO;QACP,wLAAM,IAAA,CAAE,OAAA,CAAQ,uBAAuB;IACzC,CAAC;CACF;AA+FM,SAAS,0BACd,IAAA,EAC8C;IAC9C,OAAO,KAAK,IAAA,CAAK,UAAA,CAAW,OAAO;AACrC;;ACxLA,eAAsB,cAAc,EAClC,MAAA,EACA,OAAA,EACF,EAGkB;IAChB,MAAM,SAAS,OAAO,SAAA,CAAU;IAChC,IAAI;QACF,MAAO,KAAM;YACX,MAAM,EAAE,IAAA,CAAK,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;YACnC,IAAI,MAAM;QACZ;IACF,EAAA,OAAS,OAAO;QACd,WAAA,OAAA,KAAA,IAAA,QAAU;IACZ,SAAE;QACA,OAAO,WAAA,CAAY;IACrB;AACF;;AC5BA,eAAsB,kBAAkB,EACtC,MAAA,EACA,UAAA,EACF,EAGkB;IAChB,MAAM,SAAS,OAAO,WAAA,CAAY,IAAI,kBAAkB,CAAC,EAAE,SAAA,CAAU;IACrE,MAAO,KAAM;QACX,MAAM,EAAE,IAAA,EAAM,KAAA,CAAM,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;QAC1C,IAAI,MAAM;YACR;QACF;QACA,MAAM,WAAW,KAAK;IACxB;AACF;;AHLA,IAAM,mBAAmB,IAAM;AAE/B,eAAsB,kBAAkB,EACtC,GAAA,EACA,MAAA,EACA,WAAA,EACA,OAAA,EACA,IAAA,EACA,iBAAiB,MAAA,EACjB,aAAA,EACA,UAAA,EACA,QAAA,EACA,kBAAA,EACA,QAAA,EACA,OAAA,EACA,OAAAE,SAAQ,iBAAiB,CAAA,EAC3B,EAcG;IAxCH,IAAAC;IAyCE,IAAI;QACF,WAAW,IAAI;QACf,SAAS,KAAA,CAAS;QAElB,MAAM,kBAAkB,IAAI,gBAAgB;QAC5C,mBAAmB,eAAe;QAGlC,cAAc,EAAE;QAEhB,MAAM,WAAW,MAAMD,OAAM,KAAK;YAChC,QAAQ;YACR,MAAM,KAAK,SAAA,CAAU;gBACnB;gBACA,GAAG,IAAA;YACL,CAAC;YACD;YACA,SAAS;gBACP,gBAAgB;gBAChB,GAAG,OAAA;YACL;YACA,QAAQ,gBAAgB,MAAA;QAC1B,CAAC,EAAE,KAAA,CAAM,CAAA,QAAO;YACd,MAAM;QACR,CAAC;QAED,IAAI,CAAC,SAAS,EAAA,EAAI;YAChB,MAAM,IAAI,MAAA,CACPC,OAAA,MAAM,SAAS,IAAA,CAAK,CAAA,KAApB,OAAAA,OAA0B;QAE/B;QAEA,IAAI,CAAC,SAAS,IAAA,EAAM;YAClB,MAAM,IAAI,MAAM,6BAA6B;QAC/C;QAEA,IAAI,SAAS;QAEb,OAAQ,gBAAgB;YACtB,KAAK;gBAAQ;oBACX,MAAM,kBAAkB;wBACtB,QAAQ,SAAS,IAAA;wBACjB,YAAY,CAAA,UAAS;4BACnB,UAAU;4BACV,cAAc,MAAM;wBACtB;oBACF,CAAC;oBACD;gBACF;YACA,KAAK;gBAAQ;oBACX,MAAM,cAAc;wBAClB,+LAAQ,uBAAA,EAAqB;4BAC3B,QAAQ,SAAS,IAAA;4BACjB,QAAQ;wBACV,CAAC,EAAE,WAAA,CACD,IAAI,gBAGF;4BACA,MAAM,WAAU,IAAA,EAAM;gCACpB,IAAI,CAAC,KAAK,OAAA,EAAS;oCACjB,MAAM,KAAK,KAAA;gCACb;gCAEA,MAAM,aAAa,KAAK,KAAA;gCACxB,IAAI,WAAW,IAAA,KAAS,QAAQ;oCAC9B,UAAU,WAAW,IAAA;oCACrB,cAAc,MAAM;gCACtB,OAAA,IAAW,WAAW,IAAA,KAAS,SAAS;oCACtC,MAAM,IAAI,MAAM,WAAW,SAAS;gCACtC;4BACF;wBACF,CAAC;wBAEH,SAAS,CAAA,UAAS;4BAChB,MAAM;wBACR;oBACF,CAAC;oBACD;gBACF;YACA;gBAAS;oBACP,MAAM,kBAAyB;oBAC/B,MAAM,IAAI,MAAM,CAAA,yBAAA,EAA4B,eAAe,EAAE;gBAC/D;QACF;QAEA,IAAI,UAAU;YACZ,SAAS,QAAQ,MAAM;QACzB;QAEA,mBAAmB,IAAI;QACvB,OAAO;IACT,EAAA,OAAS,KAAK;QAEZ,IAAK,IAAY,IAAA,KAAS,cAAc;YACtC,mBAAmB,IAAI;YACvB,OAAO;QACT;QAEA,IAAI,eAAe,OAAO;YACxB,IAAI,SAAS;gBACX,QAAQ,GAAG;YACb;QACF;QAEA,SAAS,GAAY;IACvB,SAAE;QACA,WAAW,KAAK;IAClB;AACF;;;AKpJO,IAAM,oBAAN,MAAwB;IAAxB,aAAA;QACL,IAAA,CAAQ,KAAA,GAAoB,CAAC,CAAA;QAC7B,IAAA,CAAQ,YAAA,GAAe;IAAA;IAEvB,MAAc,eAAe;QAC3B,IAAI,IAAA,CAAK,YAAA,EAAc;YACrB;QACF;QAEA,IAAA,CAAK,YAAA,GAAe;QAEpB,MAAO,IAAA,CAAK,KAAA,CAAM,MAAA,GAAS,EAAG;YAC5B,MAAM,IAAA,CAAK,KAAA,CAAM,CAAC,CAAA,CAAE;YACpB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM;QACnB;QAEA,IAAA,CAAK,YAAA,GAAe;IACtB;IAEA,MAAM,IAAI,GAAA,EAAyB;QACjC,OAAO,IAAI,QAAc,CAAC,SAAS,WAAW;YAC5C,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,YAAY;gBAC1B,IAAI;oBACF,MAAM,IAAI;oBACV,QAAQ;gBACV,EAAA,OAAS,OAAO;oBACd,OAAO,KAAK;gBACd;YACF,CAAC;YAED,KAAK,IAAA,CAAK,YAAA,CAAa;QACzB,CAAC;IACH;AACF;;ACjCA,eAAsB,6BACpB,KAAA,EAC4B;IAC5B,IAAI,SAAS,MAAM;QACjB,OAAO,CAAC,CAAA;IACV;IAGA,IAAI,CAAC,WAAW,QAAA,IAAY,CAAA,CAAE,iBAAiB,WAAW,QAAA,GAAW;QACnE,MAAM,IAAI,MAAM,sDAAsD;IACxE;IAEA,OAAO,QAAQ,GAAA,CACb,MAAM,IAAA,CAAK,KAAK,EAAE,GAAA,CAAI,OAAM,SAAQ;QAClC,MAAM,EAAE,MAAAC,MAAAA,EAAM,IAAA,CAAK,CAAA,GAAI;QAEvB,MAAM,UAAU,MAAM,IAAI,QAAgB,CAAC,SAAS,WAAW;YAC7D,MAAM,SAAS,IAAI,WAAW;YAC9B,OAAO,MAAA,GAAS,CAAA,gBAAe;gBApBvC,IAAAC;gBAqBU,QAAA,CAAQA,OAAA,YAAY,MAAA,KAAZ,OAAA,KAAA,IAAAA,KAAoB,MAAgB;YAC9C;YACA,OAAO,OAAA,GAAU,CAAA,QAAS,OAAO,KAAK;YACtC,OAAO,aAAA,CAAc,IAAI;QAC3B,CAAC;QAED,OAAO;YACL,MAAM;YACN,WAAW;YACX,UAAUD;YACV,KAAK;QACP;IACF,CAAC;AAEL;;ACrBA,IAAMG,oBAAmB,IAAM;AAE/B,eAAe,qBAAqB,EAClC,GAAA,EACA,IAAA,EACA,WAAA,EACA,OAAA,EACA,WAAA,EACA,OAAAC,SAAQD,kBAAiB,CAAA,EACzB,cAAc,UAAA,EAChB,EAQiD;IAhCjD,IAAAE;IAiCE,MAAM,WACJ,gBAAgB,WACZ,MAAMD,OAAM,GAAG,GAAG,CAAA,IAAA,EAAO,KAAK,EAAE,EAAA,EAAI;QAClC,QAAQ;QACR,SAAS;YACP,gBAAgB;YAChB,GAAG,OAAA;QACL;QACA,QAAQ;QACR;IACF,CAAC,IACD,MAAMA,OAAM,KAAK;QACf,QAAQ;QACR,MAAM,KAAK,SAAA,CAAU,IAAI;QACzB,SAAS;YACP,gBAAgB;YAChB,GAAG,OAAA;QACL;QACA,QAAQ;QACR;IACF,CAAC;IAEP,IAAI,CAAC,SAAS,EAAA,EAAI;QAChB,MAAM,IAAI,MAAA,CACPC,OAAA,MAAM,SAAS,IAAA,CAAK,CAAA,KAApB,OAAAA,OAA0B;IAE/B;IAEA,IAAI,CAAC,SAAS,IAAA,EAAM;QAClB,MAAM,IAAI,MAAM,6BAA6B;IAC/C;IAEA,OAAOC,8MAAAA,EAAqB;QAC1B,QAAQ,SAAS,IAAA;QACjB,QAAQ;IACV,CAAC,EAAE,WAAA,CACD,IAAI,gBAAuE;QACzE,MAAM,WAAU,IAAA,EAAM,UAAA,EAAY;YAChC,IAAI,CAAC,KAAK,OAAA,EAAS;gBACjB,MAAM,KAAK,KAAA;YACb;YACA,WAAW,OAAA,CAAQ,KAAK,KAAK;QAC/B;IACF,CAAC;AAEL;AAEO,IAAM,uBAAN,MAIP;IAQE,YAAY,EACV,MAAM,WAAA,EACN,WAAA,EACA,OAAA,EACA,IAAA,EACA,OAAAF,MAAAA,EACA,cAAA,EACF,GA6CI,CAAC,CAAA,CAAG;QACN,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,WAAA,GAAc;QACnB,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,KAAA,GAAQA;QACb,IAAA,CAAK,cAAA,GAAiB;IACxB;IAEA,eAAe,EACb,MAAA,EACA,QAAA,EACA,WAAA,EACA,QAAA,EACA,OAAA,EACA,IAAA,EACA,WAAA,EACF,EAEM;QAnKR,IAAAC,MAAA;QAoKI,MAAM,kBAAA,CAAkBA,OAAA,IAAA,CAAK,cAAA,KAAL,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,IAAA,EAAsB;YAC5C,IAAI;YACJ;YACA,MAAM;gBAAE,GAAG,IAAA,CAAK,IAAA;gBAAM,GAAG,IAAA;YAAK;YAC9B,SAAS;gBAAE,GAAG,IAAA,CAAK,OAAA;gBAAS,GAAG,OAAA;YAAQ;YACvC,aAAa,IAAA,CAAK,WAAA;YAClB,iBAAiB;QACnB;QAEA,OAAO,qBAAqB;YAC1B,KAAK,IAAA,CAAK,GAAA;YACV,MAAA,CACE,mBAAA,OAAA,KAAA,IAAA,gBAAiB,IAAA,MAAS,KAAA,IACtB,gBAAgB,IAAA,GAChB;gBAAE,GAAG,IAAA,CAAK,IAAA;gBAAM,GAAG,IAAA;gBAAM,IAAI;gBAAQ;YAAS;YACpD,SAAA,CACE,mBAAA,OAAA,KAAA,IAAA,gBAAiB,OAAA,MAAY,KAAA,IACzB,gBAAgB,OAAA,GAChB;gBAAE,GAAG,IAAA,CAAK,OAAA;gBAAS,GAAG,OAAA;YAAQ;YACpC,aAAA,CAAa,KAAA,mBAAA,OAAA,KAAA,IAAA,gBAAiB,WAAA,KAAjB,OAAA,KAAgC,IAAA,CAAK,WAAA;YAClD;YACA,OAAO,IAAA,CAAK,KAAA;YACZ;QACF,CAAC;IACH;AACF;;;AEhLO,SAAS,aACd,IAAA,EACA,SAAA,EAC6B;IAE7B,IAAI,SAAS,KAAA,KAAa,cAAc,KAAA,GAAW;QACjD,OAAO,KAAA;IACT;IAGA,IAAI,SAAS,KAAA,GAAW;QACtB,OAAO;IACT;IAGA,IAAI,cAAc,KAAA,GAAW;QAC3B,OAAO;IACT;IAGA,MAAM,SAAS;QAAE,GAAG,IAAA;IAAK;IAGzB,IAAA,MAAW,OAAO,UAAW;QAC3B,IAAI,OAAO,SAAA,CAAU,cAAA,CAAe,IAAA,CAAK,WAAW,GAAG,GAAG;YACxD,MAAM,iBAAiB,SAAA,CAAU,GAAG,CAAA;YAGpC,IAAI,mBAAmB,KAAA,GAAW;YAGlC,MAAM,YACJ,OAAO,OAAO,IAAA,CAAK,GAAyB,CAAA,GAAI,KAAA;YAGlD,MAAM,iBACJ,mBAAmB,QACnB,OAAO,mBAAmB,YAC1B,CAAC,MAAM,OAAA,CAAQ,cAAc,KAC7B,CAAA,CAAE,0BAA0B,IAAA,KAC5B,CAAA,CAAE,0BAA0B,MAAA;YAE9B,MAAM,iBACJ,cAAc,QACd,cAAc,KAAA,KACd,OAAO,cAAc,YACrB,CAAC,MAAM,OAAA,CAAQ,SAAS,KACxB,CAAA,CAAE,qBAAqB,IAAA,KACvB,CAAA,CAAE,qBAAqB,MAAA;YAGzB,IAAI,kBAAkB,gBAAgB;gBACpC,MAAA,CAAO,GAAoB,CAAA,GAAI,aAC7B,WACA;YAEJ,OAAO;gBAGL,MAAA,CAAO,GAAoB,CAAA,GAAI;YACjC;QACF;IACF;IAEA,OAAO;AACT;;;AEpDO,SAAS,QAAQ,KAAA,EAAuB;IAC7C,MAAM,QAAiB;QAAC,MAAM;KAAA;IAC9B,IAAI,iBAAiB,CAAA;IACrB,IAAI,eAA8B;IAElC,SAAS,kBAAkB,IAAA,EAAc,CAAA,EAAW,SAAA,EAAkB;QACpE;YACE,OAAQ,MAAM;gBACZ,KAAK;oBAAK;wBACR,iBAAiB;wBACjB,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,eAAe;wBAC1B;oBACF;gBAEA,KAAK;gBACL,KAAK;gBACL,KAAK;oBAAK;wBACR,iBAAiB;wBACjB,eAAe;wBACf,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,gBAAgB;wBAC3B;oBACF;gBAEA,KAAK;oBAAK;wBACR,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,eAAe;wBAC1B;oBACF;gBACA,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;oBAAK;wBACR,iBAAiB;wBACjB,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,eAAe;wBAC1B;oBACF;gBAEA,KAAK;oBAAK;wBACR,iBAAiB;wBACjB,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,qBAAqB;wBAChC;oBACF;gBAEA,KAAK;oBAAK;wBACR,iBAAiB;wBACjB,MAAM,GAAA,CAAI;wBACV,MAAM,IAAA,CAAK,SAAS;wBACpB,MAAM,IAAA,CAAK,oBAAoB;wBAC/B;oBACF;YACF;QACF;IACF;IAEA,SAAS,wBAAwB,IAAA,EAAc,CAAA,EAAW;QACxD,OAAQ,MAAM;YACZ,KAAK;gBAAK;oBACR,MAAM,GAAA,CAAI;oBACV,MAAM,IAAA,CAAK,2BAA2B;oBACtC;gBACF;YACA,KAAK;gBAAK;oBACR,iBAAiB;oBACjB,MAAM,GAAA,CAAI;oBACV;gBACF;QACF;IACF;IAEA,SAAS,uBAAuB,IAAA,EAAc,CAAA,EAAW;QACvD,OAAQ,MAAM;YACZ,KAAK;gBAAK;oBACR,MAAM,GAAA,CAAI;oBACV,MAAM,IAAA,CAAK,0BAA0B;oBACrC;gBACF;YACA,KAAK;gBAAK;oBACR,iBAAiB;oBACjB,MAAM,GAAA,CAAI;oBACV;gBACF;QACF;IACF;IAEA,IAAA,IAAS,IAAI,GAAG,IAAI,MAAM,MAAA,EAAQ,IAAK;QACrC,MAAM,OAAO,KAAA,CAAM,CAAC,CAAA;QACpB,MAAM,eAAe,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA;QAE3C,OAAQ,cAAc;YACpB,KAAK;gBACH,kBAAkB,MAAM,GAAG,QAAQ;gBACnC;YAEF,KAAK;gBAAuB;oBAC1B,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,MAAM,IAAA,CAAK,mBAAmB;gCAC9B;4BACF;wBACA,KAAK;4BAAK;gCACR,iBAAiB;gCACjB,MAAM,GAAA,CAAI;gCACV;4BACF;oBACF;oBACA;gBACF;YAEA,KAAK;gBAA6B;oBAChC,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,MAAM,IAAA,CAAK,mBAAmB;gCAC9B;4BACF;oBACF;oBACA;gBACF;YAEA,KAAK;gBAAqB;oBACxB,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,MAAM,IAAA,CAAK,yBAAyB;gCACpC;4BACF;oBACF;oBACA;gBACF;YAEA,KAAK;gBAA2B;oBAC9B,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,MAAM,IAAA,CAAK,4BAA4B;gCAEvC;4BACF;oBACF;oBACA;gBACF;YAEA,KAAK;gBAA8B;oBACjC,kBAAkB,MAAM,GAAG,2BAA2B;oBACtD;gBACF;YAEA,KAAK;gBAA6B;oBAChC,wBAAwB,MAAM,CAAC;oBAC/B;gBACF;YAEA,KAAK;gBAAiB;oBACpB,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,iBAAiB;gCACjB;4BACF;wBAEA,KAAK;4BAAM;gCACT,MAAM,IAAA,CAAK,sBAAsB;gCACjC;4BACF;wBAEA;4BAAS;gCACP,iBAAiB;4BACnB;oBACF;oBAEA;gBACF;YAEA,KAAK;gBAAsB;oBACzB,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,iBAAiB;gCACjB,MAAM,GAAA,CAAI;gCACV;4BACF;wBAEA;4BAAS;gCACP,iBAAiB;gCACjB,kBAAkB,MAAM,GAAG,0BAA0B;gCACrD;4BACF;oBACF;oBACA;gBACF;YAEA,KAAK;gBAA4B;oBAC/B,OAAQ,MAAM;wBACZ,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCACV,MAAM,IAAA,CAAK,0BAA0B;gCACrC;4BACF;wBAEA,KAAK;4BAAK;gCACR,iBAAiB;gCACjB,MAAM,GAAA,CAAI;gCACV;4BACF;wBAEA;4BAAS;gCACP,iBAAiB;gCACjB;4BACF;oBACF;oBAEA;gBACF;YAEA,KAAK;gBAA4B;oBAC/B,kBAAkB,MAAM,GAAG,0BAA0B;oBACrD;gBACF;YAEA,KAAK;gBAAwB;oBAC3B,MAAM,GAAA,CAAI;oBACV,iBAAiB;oBAEjB;gBACF;YAEA,KAAK;gBAAiB;oBACpB,OAAQ,MAAM;wBACZ,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;4BAAK;gCACR,iBAAiB;gCACjB;4BACF;wBAEA,KAAK;wBACL,KAAK;wBACL,KAAK;wBACL,KAAK;4BAAK;gCACR;4BACF;wBAEA,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCAEV,IAAI,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,4BAA4B;oCAC1D,uBAAuB,MAAM,CAAC;gCAChC;gCAEA,IAAI,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,6BAA6B;oCAC3D,wBAAwB,MAAM,CAAC;gCACjC;gCAEA;4BACF;wBAEA,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCAEV,IAAI,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,6BAA6B;oCAC3D,wBAAwB,MAAM,CAAC;gCACjC;gCAEA;4BACF;wBAEA,KAAK;4BAAK;gCACR,MAAM,GAAA,CAAI;gCAEV,IAAI,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,4BAA4B;oCAC1D,uBAAuB,MAAM,CAAC;gCAChC;gCAEA;4BACF;wBAEA;4BAAS;gCACP,MAAM,GAAA,CAAI;gCACV;4BACF;oBACF;oBAEA;gBACF;YAEA,KAAK;gBAAkB;oBACrB,MAAM,iBAAiB,MAAM,SAAA,CAAU,cAAe,IAAI,CAAC;oBAE3D,IACE,CAAC,QAAQ,UAAA,CAAW,cAAc,KAClC,CAAC,OAAO,UAAA,CAAW,cAAc,KACjC,CAAC,OAAO,UAAA,CAAW,cAAc,GACjC;wBACA,MAAM,GAAA,CAAI;wBAEV,IAAI,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,6BAA6B;4BAC3D,wBAAwB,MAAM,CAAC;wBACjC,OAAA,IAAW,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAM,4BAA4B;4BACjE,uBAAuB,MAAM,CAAC;wBAChC;oBACF,OAAO;wBACL,iBAAiB;oBACnB;oBAEA;gBACF;QACF;IACF;IAEA,IAAI,SAAS,MAAM,KAAA,CAAM,GAAG,iBAAiB,CAAC;IAE9C,IAAA,IAAS,IAAI,MAAM,MAAA,GAAS,GAAG,KAAK,GAAG,IAAK;QAC1C,MAAM,QAAQ,KAAA,CAAM,CAAC,CAAA;QAErB,OAAQ,OAAO;YACb,KAAK;gBAAiB;oBACpB,UAAU;oBACV;gBACF;YAEA,KAAK;YACL,KAAK;YACL,KAAK;YACL,KAAK;YACL,KAAK;YACL,KAAK;gBAA6B;oBAChC,UAAU;oBACV;gBACF;YAEA,KAAK;YACL,KAAK;YACL,KAAK;gBAA4B;oBAC/B,UAAU;oBACV;gBACF;YAEA,KAAK;gBAAkB;oBACrB,MAAM,iBAAiB,MAAM,SAAA,CAAU,cAAe,MAAM,MAAM;oBAElE,IAAI,OAAO,UAAA,CAAW,cAAc,GAAG;wBACrC,UAAU,OAAO,KAAA,CAAM,eAAe,MAAM;oBAC9C,OAAA,IAAW,QAAQ,UAAA,CAAW,cAAc,GAAG;wBAC7C,UAAU,QAAQ,KAAA,CAAM,eAAe,MAAM;oBAC/C,OAAA,IAAW,OAAO,UAAA,CAAW,cAAc,GAAG;wBAC5C,UAAU,OAAO,KAAA,CAAM,eAAe,MAAM;oBAC9C;gBACF;QACF;IACF;IAEA,OAAO;AACT;;AD5YA,eAAsB,iBAAiB,QAAA,EAOpC;IACD,IAAI,aAAa,KAAA,GAAW;QAC1B,OAAO;YAAE,OAAO,KAAA;YAAW,OAAO;QAAkB;IACtD;IAEA,IAAI,SAAS,6LAAM,gBAAA,EAAc;QAAE,MAAM;IAAS,CAAC;IAEnD,IAAI,OAAO,OAAA,EAAS;QAClB,OAAO;YAAE,OAAO,OAAO,KAAA;YAAO,OAAO;QAAmB;IAC1D;IAEA,SAAS,6LAAM,gBAAA,EAAc;QAAE,MAAM,QAAQ,QAAQ;IAAE,CAAC;IAExD,IAAI,OAAO,OAAA,EAAS;QAClB,OAAO;YAAE,OAAO,OAAO,KAAA;YAAO,OAAO;QAAiB;IACxD;IAEA,OAAO;QAAE,OAAO,KAAA;QAAW,OAAO;IAAe;AACnD;;AE3BO,SAAS,mBAAmB,OAAA,EAAsC;IACvE,OAAO,QAAQ,KAAA,CACZ,MAAA,CACC,CAAC,OAAuC,KAAK,IAAA,KAAS,mBAEvD,GAAA,CAAI,CAAA,OAAQ,KAAK,cAAc;AACpC;;AJ6BO,SAAS,8BAGd,EACA,WAAA,EACA,eAAe,EAAA,EACjB,GAGI,CAAC,CAAA,EAAwE;IAC3E,MAAM,iBAAA,CAAiB,eAAA,OAAA,KAAA,IAAA,YAAa,IAAA,MAAS;IAE7C,MAAM,UAAsD,iBACxD,cACA;QACE,IAAI;QACJ,UAAU,CAAC;QACX,MAAM;QACN,OAAO,CAAC,CAAA;IACV;IAEJ,OAAO;QACL;QACA,gBAAgB,KAAA;QAChB,qBAAqB,KAAA;QACrB,kBAAkB,CAAC;IACrB;AACF;AAEO,SAAS,uBAAqD,EACnE,MAAA,EACA,UAAA,EACA,qBAAA,EACA,eAAA,EACA,mBAAA,EACF,EAqByD;IACvD,OAAO,OAAO,WAAA,CACZ,IAAI,gBAGF;QACA,MAAM,WAAU,IAAA,EAAM,UAAA,EAAY;YAChC,MAAM,oBAAoB,OAAO,EAAE,KAAA,EAAO,KAAA,CAAM,CAAA,KAAM;gBACpD,SAAS,yBACP,UAAA,EACA,UAAA,EACA;oBACA,MAAME,QAAO,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAC/B,CAAAA,QACE,uBAAuBA,KAAI,KAC3BA,MAAK,cAAA,CAAe,UAAA,KAAe;oBAGvC,IAAIA,SAAQ,MAAM;wBAChBA,MAAK,cAAA,GAAiB;oBACxB,OAAO;wBACL,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK;4BACvB,MAAM;4BACN,gBAAgB;wBAClB,CAAC;oBACH;gBACF;gBAEA,eAAe,sBAAsB,QAAA,EAAmB;oBACtD,IAAI,YAAY,MAAM;wBACpB,MAAM,iBACJ,MAAM,OAAA,CAAQ,QAAA,IAAY,OACtB,aAAa,MAAM,OAAA,CAAQ,QAAA,EAAU,QAAQ,IAC7C;wBAEN,IAAI,yBAAyB,MAAM;4BACjC,6LAAM,gBAAA,EAAc;gCAClB,OAAO;gCACP,QAAQ;4BACV,CAAC;wBACH;wBAEA,MAAM,OAAA,CAAQ,QAAA,GACZ;oBACJ;gBACF;gBAEA,OAAQ,KAAK,IAAA,EAAM;oBACjB,KAAK;wBAAQ;4BACX,IAAI,MAAM,cAAA,IAAkB,MAAM;gCAChC,MAAM,cAAA,GAAiB;oCACrB,MAAM;oCACN,MAAM,KAAK,IAAA;gCACb;gCACA,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK,MAAM,cAAc;4BAC/C,OAAO;gCACL,MAAM,cAAA,CAAe,IAAA,IAAQ,KAAK,IAAA;4BACpC;4BAEA,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAa;4BAChB,IAAI,MAAM,mBAAA,IAAuB,MAAM;gCACrC,MAAM,mBAAA,GAAsB;oCAC1B,MAAM;oCACN,MAAM,KAAK,IAAA;oCACX,kBAAkB,KAAK,gBAAA;gCACzB;gCACA,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK,MAAM,mBAAmB;4BACpD,OAAO;gCACL,MAAM,mBAAA,CAAoB,IAAA,IAAQ,KAAK,IAAA;gCACvC,MAAM,mBAAA,CAAoB,gBAAA,GACxB,KAAK,gBAAA;4BACT;4BAEA,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAyB;4BAC5B,IAAI,MAAM,mBAAA,IAAuB,MAAM;gCACrC,MAAM,mBAAA,GAAsB,KAAA;4BAC9B;4BACA;wBACF;oBAEA,KAAK;wBAAQ;4BACX,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK;gCACvB,MAAM;gCACN,WAAW,KAAK,SAAA;gCAChB,KAAK,KAAK,GAAA;4BACZ,CAAC;4BAED,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAc;4BACjB,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK;gCACvB,MAAM;gCACN,UAAU,KAAK,QAAA;gCACf,KAAK,KAAK,GAAA;gCACV,OAAO,KAAK,KAAA;gCACZ,kBAAkB,KAAK,gBAAA;4BACzB,CAAC;4BAED,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAmB;4BACtB,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK;gCACvB,MAAM;gCACN,UAAU,KAAK,QAAA;gCACf,WAAW,KAAK,SAAA;gCAChB,OAAO,KAAK,KAAA;gCACZ,UAAU,KAAK,QAAA;gCACf,kBAAkB,KAAK,gBAAA;4BACzB,CAAC;4BAED,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAA6B;4BAChC,MAAM,kBAAkB,mBAAmB,MAAM,OAAO;4BAGxD,MAAM,gBAAA,CAAiB,KAAK,UAAU,CAAA,GAAI;gCACxC,MAAM;gCACN,UAAU,KAAK,QAAA;gCACf,OAAO,gBAAgB,MAAA;4BACzB;4BAEA,yBAAyB,KAAK,UAAA,EAAY;gCACxC,OAAO;gCACP,YAAY,KAAK,UAAA;gCACjB,UAAU,KAAK,QAAA;gCACf,MAAM,KAAA;4BACR,CAAU;4BAEV,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAmB;4BACtB,MAAM,kBAAkB,MAAM,gBAAA,CAAiB,KAAK,UAAU,CAAA;4BAE9D,gBAAgB,IAAA,IAAQ,KAAK,aAAA;4BAE7B,MAAM,EAAE,OAAO,WAAA,CAAY,CAAA,GAAI,MAAM,iBACnC,gBAAgB,IAAA;4BAGlB,yBAAyB,KAAK,UAAA,EAAY;gCACxC,OAAO;gCACP,YAAY,KAAK,UAAA;gCACjB,UAAU,gBAAgB,QAAA;gCAC1B,MAAM;4BACR,CAAU;4BAEV,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAa;4BAChB,yBAAyB,KAAK,UAAA,EAAY;gCACxC,OAAO;gCACP,YAAY,KAAK,UAAA;gCACjB,UAAU,KAAK,QAAA;gCACf,MAAM,KAAK,IAAA;4BACb,CAAU;4BAEV,MAAM;4BAKN,IAAI,YAAY;gCACd,MAAM,SAAS,MAAM,WAAW;oCAC9B,UAAU;gCACZ,CAAC;gCACD,IAAI,UAAU,MAAM;oCAClB,yBAAyB,KAAK,UAAA,EAAY;wCACxC,OAAO;wCACP,YAAY,KAAK,UAAA;wCACjB,UAAU,KAAK,QAAA;wCACf,MAAM,KAAK,IAAA;wCACX;oCACF,CAAU;oCAEV,MAAM;gCACR;4BACF;4BACA;wBACF;oBAEA,KAAK;wBAAe;4BAClB,MAAM,kBAAkB,mBAAmB,MAAM,OAAO;4BAExD,IAAI,mBAAmB,MAAM;gCAC3B,MAAM,IAAI,MAAM,6CAA6C;4BAC/D;4BAIA,MAAM,sBAAsB,gBAAgB,SAAA,CAC1C,CAAA,aAAc,WAAW,UAAA,KAAe,KAAK,UAAA;4BAG/C,IAAI,wBAAwB,CAAA,GAAI;gCAC9B,MAAM,IAAI,MACR;4BAEJ;4BAEA,yBAAyB,KAAK,UAAA,EAAY;gCACxC,GAAG,eAAA,CAAgB,mBAAmB,CAAA;gCACtC,OAAO;gCACP,QAAQ,KAAK,MAAA;4BACf,CAAU;4BAEV,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAc;4BAEjB,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK;gCAAE,MAAM;4BAAa,CAAC;4BAE/C,MAAM,sBAAsB,KAAK,QAAQ;4BACzC,MAAM;4BACN;wBACF;oBAEA,KAAK;wBAAe;4BAElB,MAAM,cAAA,GAAiB,KAAA;4BACvB,MAAM,mBAAA,GAAsB,KAAA;4BAE5B,MAAM,sBAAsB,KAAK,QAAQ;4BACzC,IAAI,KAAK,QAAA,IAAY,MAAM;gCACzB,MAAM;4BACR;4BACA;wBACF;oBAEA,KAAK;wBAAS;4BACZ,IAAI,KAAK,SAAA,IAAa,MAAM;gCAC1B,MAAM,OAAA,CAAQ,EAAA,GAAK,KAAK,SAAA;4BAC1B;4BAEA,MAAM,sBAAsB,KAAK,QAAQ;4BAEzC,IAAI,KAAK,SAAA,IAAa,QAAQ,KAAK,QAAA,IAAY,MAAM;gCACnD,MAAM;4BACR;4BACA;wBACF;oBAEA,KAAK;wBAAU;4BACb,MAAM,sBAAsB,KAAK,QAAQ;4BACzC,IAAI,KAAK,QAAA,IAAY,MAAM;gCACzB,MAAM;4BACR;4BACA;wBACF;oBAEA,KAAK;wBAAY;4BACf,MAAM,sBAAsB,KAAK,QAAQ;4BACzC,IAAI,KAAK,QAAA,IAAY,MAAM;gCACzB,MAAM;4BACR;4BACA;wBACF;oBAEA,KAAK;wBAAS;4BACZ,MAAM,IAAI,MAAM,KAAK,SAAS;wBAChC;oBAEA;wBAAS;4BACP,IAAI,0BAA0B,IAAI,GAAG;gCAEnC,MAAM,eACJ,KAAK,EAAA,IAAM,OACP,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAClB,CAAC,UACC,KAAK,IAAA,KAAS,QAAQ,IAAA,IAAQ,KAAK,EAAA,KAAO,QAAQ,EAAA,IAEtD,KAAA;gCAEN,IAAI,gBAAgB,MAAM;oCAExB,aAAa,IAAA,GACX,SAAS,aAAa,IAAI,KAAK,SAAS,KAAK,IAAI,IAC7C,aAAa,aAAa,IAAA,EAAM,KAAK,IAAI,IACzC,KAAK,IAAA;gCACb,OAAO;oCAEL,MAAM,OAAA,CAAQ,KAAA,CAAM,IAAA,CAAK,IAAW;gCACtC;gCACA,MAAM;4BACR;wBACF;gBACF;gBAEA,WAAW,OAAA,CAAQ,IAA4C;YACjE,CAAC;QACH;IACF,CAAC;AAEL;AAGA,SAAS,uBACP,IAAA,EAC8B;IAC9B,OAAO,KAAK,IAAA,KAAS;AACvB;AAEA,SAAS,SAAS,KAAA,EAAiC;IACjD,OAAO,OAAO,UAAU,YAAY,UAAU;AAChD;;AK/ZO,SAAS,uBAAuB,EACrC,6BAAA,EACA,oBAAA,EACA,QAAA,EACA,QAAA,EACF,EAKG;IACD,MAAM,cAAc,QAAA,CAAS,SAAS,MAAA,GAAS,CAAC,CAAA;IAGhD,MAAM,4BAA4B,YAAY,KAAA,CAAM,MAAA,CAClD,CAAA,OAAQ,KAAK,IAAA,KAAS,cACtB,MAAA;IAEF,OAAA,mCAAA;IAEE,WAAW,KAAA,kCAAA;IAEX,eAAe,QAAA,mFAAA;IAAA,CAEd,SAAS,MAAA,GAAS,wBACjB,8BAA8B,6BAAA,KAAA,oCAAA;IAEhC,yCAAyC,WAAW,KAAA,uCAAA;IAEpD,4BAA4B;AAEhC;AAOO,SAAS,yCACd,OAAA,EAGA;IACA,IAAI,CAAC,SAAS;QACZ,OAAO;IACT;IAEA,IAAI,QAAQ,IAAA,KAAS,aAAa;QAChC,OAAO;IACT;IAEA,MAAM,qBAAqB,QAAQ,KAAA,CAAM,MAAA,CAAO,CAAC,WAAW,MAAM,UAAU;QAC1E,OAAO,KAAK,IAAA,KAAS,eAAe,QAAQ;IAC9C,GAAG,CAAA,CAAE;IAEL,MAAM,0BAA0B,QAAQ,KAAA,CACrC,KAAA,CAAM,qBAAqB,CAAC,EAC5B,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,iBAAiB;IAEjD,OACE,wBAAwB,MAAA,GAAS,KACjC,wBAAwB,KAAA,CAAM,CAAA,OAAQ,YAAY,KAAK,cAAc;AAEzE;;ATmEO,IAAe,eAAf,MAGL;IAoCA,YAAY,EACV,YAAAC,iMAAa,aAAA,EACb,KAAKA,YAAW,CAAA,EAChB,YAAY,IAAI,qBAAqB,CAAA,EACrC,WAAW,CAAA,EACX,qBAAA,EACA,eAAA,EACA,KAAA,EACA,OAAA,EACA,UAAA,EACA,QAAA,EACF,CAEG;QApBH,IAAA,CAAQ,cAAA,GAIQ,KAAA;QAChB,IAAA,CAAQ,WAAA,GAAc,IAAI,kBAAkB;QA+E5C,IAAA,CAAA,uBAAA,GAA0B,MAAM;YAC9B,MAAM,cAAc,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,MAAA,GAAS,CAAC,CAAA;YAEtE,IAAI,eAAe,MAAM;gBACvB,MAAM,IAAI,MAAM,kDAAkD;YACpE;YAEA,IAAI,YAAY,IAAA,KAAS,aAAa;gBACpC,MAAM,IAAI,MAAM,0CAA0C;YAC5D;YAEA,IAAA,CAAK,KAAA,CAAM,UAAA,CAAW;QACxB;QAMA;;;KAAA,GAAA,IAAA,CAAA,WAAA,GAAc,OACZ,SAgBA,UAA8B,CAAC,CAAA,KACb;YA5RtB,IAAAC,MAAA;YA6RI,IAAI;YAKJ,IAAI,UAAU,WAAW,WAAW,SAAS;gBAC3C,MAAM,YAAY,MAAM,OAAA,CAAQ,QAAQ,KAAK,IACzC,QAAQ,KAAA,GACR,MAAM,6BAA6B,QAAQ,KAAK;gBAEpD,YAAY;oBACV,OAAO;2BACF;2BACC,UAAU,WAAW,QAAQ,IAAA,IAAQ,OACrC;4BAAC;gCAAE,MAAM;gCAAiB,MAAM,QAAQ,IAAA;4BAAK,CAAC;yBAAA,GAC9C,CAAC,CAAA;qBACP;gBACF;YACF,OAAO;gBACL,YAAY;YACd;YAEA,IAAA,CAAK,KAAA,CAAM,WAAA,CAAY;gBACrB,GAAG,SAAA;gBACH,IAAA,CAAIA,OAAA,UAAU,EAAA,KAAV,OAAAA,OAAgB,IAAA,CAAK,UAAA,CAAW;gBACpC,MAAA,CAAM,KAAA,UAAU,IAAA,KAAV,OAAA,KAAkB;YAC1B,CAAC;YAED,MAAM,IAAA,CAAK,cAAA,CAAe;gBAAE,aAAa;gBAAY,GAAG,OAAA;YAAQ,CAAC;QACnE;QAKA;;KAAA,GAAA,IAAA,CAAA,MAAA,GAAS,OAAO,UAA8B,CAAC,CAAA,KAAqB;YAElE,IAAI,IAAA,CAAK,WAAA,KAAgB,KAAA,GAAW;gBAClC;YACF;YAEA,IAAI,IAAA,CAAK,WAAA,CAAY,IAAA,KAAS,aAAa;gBACzC,IAAA,CAAK,KAAA,CAAM,UAAA,CAAW;YACxB;YAEA,MAAM,IAAA,CAAK,cAAA,CAAe;gBAAE,aAAa;gBAAY,GAAG,OAAA;YAAQ,CAAC;QACnE;QAKA;;KAAA,GAAA,IAAA,CAAA,mBAAA,GAAsB,OACpB,UAA8B,CAAC,CAAA,KACb;YAClB,MAAM,IAAA,CAAK,cAAA,CAAe;gBAAE,aAAa;gBAAU,GAAG,OAAA;YAAQ,CAAC;QACjE;QAEA,IAAA,CAAA,aAAA,GAAgB,OAAO,EACrB,UAAA,EACA,MAAA,EACF,KAGM;YACJ,IAAA,CAAK,WAAA,CAAY,GAAA,CAAI,YAAY;gBAC/B,qBAAqB;oBACnB,UAAU,IAAA,CAAK,KAAA,CAAM,QAAA;oBACrB;oBACA,YAAY;gBACd,CAAC;gBAED,IAAA,CAAK,QAAA,GAAW,IAAA,CAAK,KAAA,CAAM,QAAA;gBAG3B,IAAI,IAAA,CAAK,MAAA,KAAW,eAAe,IAAA,CAAK,MAAA,KAAW,aAAa;oBAC9D;gBACF;gBAGA,MAAM,cAAc,IAAA,CAAK,WAAA;gBACzB,IAAI,yCAAyC,WAAW,GAAG;oBAEzD,IAAA,CAAK,cAAA,CAAe;wBAClB,aAAa;oBACf,CAAC;gBACH;YACF,CAAC;QACH;QAKA;;KAAA,GAAA,IAAA,CAAA,IAAA,GAAO,YAAY;YAxXrB,IAAAA;YAyXI,IAAI,IAAA,CAAK,MAAA,KAAW,eAAe,IAAA,CAAK,MAAA,KAAW,aAAa;YAEhE,IAAA,CAAIA,OAAA,IAAA,CAAK,cAAA,KAAL,OAAA,KAAA,IAAAA,KAAqB,eAAA,EAAiB;gBACxC,IAAA,CAAK,cAAA,CAAe,eAAA,CAAgB,KAAA,CAAM;gBAC1C,IAAA,CAAK,cAAA,CAAe,eAAA,GAAkB,KAAA;YACxC;QACF;QAtME,IAAA,CAAK,EAAA,GAAK;QACV,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,SAAA,GAAY;QACjB,IAAA,CAAK,UAAA,GAAaD;QAClB,IAAA,CAAK,qBAAA,GAAwB;QAC7B,IAAA,CAAK,eAAA,GAAkB;QACvB,IAAA,CAAK,KAAA,GAAQ;QACb,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,UAAA,GAAa;QAClB,IAAA,CAAK,QAAA,GAAW;IAClB;IAAA;;;;;;;GAAA,GAUA,IAAI,SAAqB;QACvB,OAAO,IAAA,CAAK,KAAA,CAAM,MAAA;IACpB;IAEU,UAAU,EAClB,MAAA,EACA,KAAA,EACF,EAGG;QACD,IAAI,IAAA,CAAK,MAAA,KAAW,QAAQ;QAE5B,IAAA,CAAK,KAAA,CAAM,MAAA,GAAS;QACpB,IAAA,CAAK,KAAA,CAAM,KAAA,GAAQ;IACrB;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,KAAA,CAAM,KAAA;IACpB;IAEA,IAAI,WAGA;QACF,OAAO,IAAA,CAAK,KAAA,CAAM,QAAA;IACpB;IAEA,IAAI,cAEU;QACZ,OAAO,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,MAAA,GAAS,CAAC,CAAA;IAC3D;IAEA,IAAI,SACF,QAAA,EAIA;QACA,IAAA,CAAK,KAAA,CAAM,QAAA,GAAW;IACxB;IA2IA,MAAc,eAAe,EAC3B,WAAA,EACA,QAAA,EACA,OAAA,EACA,IAAA,EACF,EAEwB;QAxY1B,IAAAC,MAAA;QAyYI,IAAA,CAAK,SAAA,CAAU;YAAE,QAAQ;YAAa,OAAO,KAAA;QAAU,CAAC;QAExD,MAAM,eAAe,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,MAAA;QACzC,MAAM,cAAc,IAAA,CAAK,WAAA;QACzB,MAAM,UAAA,CACJA,OAAA,eAAA,OAAA,KAAA,IAAA,YAAa,KAAA,CAAM,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,cAAc,MAAA,KAA9D,OAAAA,OAAwE;QAE1E,IAAI;YACF,MAAM,iBAAiB;gBACrB,OAAO,8BAA8B;oBACnC,aAAa,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,WAAW;oBAC5C,cAAc,IAAA,CAAK,UAAA,CAAW;gBAChC,CAAC;gBACD,iBAAiB,IAAI,gBAAgB;YACvC;YAEA,IAAA,CAAK,cAAA,GAAiB;YAEtB,MAAM,SAAS,MAAM,IAAA,CAAK,SAAA,CAAU,cAAA,CAAe;gBACjD,QAAQ,IAAA,CAAK,EAAA;gBACb,UAAU,IAAA,CAAK,KAAA,CAAM,QAAA;gBACrB,aAAa,eAAe,eAAA,CAAgB,MAAA;gBAC5C;gBACA;gBACA;gBACA;YACF,CAAC;YAED,MAAM,sBAAsB,CAC1B,MAAA,wDAAA;gBAQA,IAAA,CAAK,WAAA,CAAY,GAAA,CAAI,IACnB,IAAI;wBACF,OAAO,eAAe,KAAA;wBACtB,OAAO,MAAM;4BAjbzB,IAAAA;4BAmbc,IAAA,CAAK,SAAA,CAAU;gCAAE,QAAQ;4BAAY,CAAC;4BAEtC,MAAM,qBACJ,eAAe,KAAA,CAAM,OAAA,CAAQ,EAAA,KAAA,CAAA,CAAOA,OAAA,IAAA,CAAK,WAAA,KAAL,OAAA,KAAA,IAAAA,KAAkB,EAAA;4BAExD,IAAI,oBAAoB;gCACtB,IAAA,CAAK,KAAA,CAAM,cAAA,CACT,IAAA,CAAK,KAAA,CAAM,QAAA,CAAS,MAAA,GAAS,GAC7B,eAAe,KAAA,CAAM,OAAA;4BAEzB,OAAO;gCACL,IAAA,CAAK,KAAA,CAAM,WAAA,CAAY,eAAe,KAAA,CAAM,OAAO;4BACrD;wBACF;oBACF,CAAC;YAGL,MAAM,cAAc;gBAClB,QAAQ,uBAAuB;oBAC7B;oBACA,YAAY,IAAA,CAAK,UAAA;oBACjB,uBAAuB,IAAA,CAAK,qBAAA;oBAC5B,iBAAiB,IAAA,CAAK,eAAA;oBACtB;gBACF,CAAC;gBACD,SAAS,CAAA,UAAS;oBAChB,MAAM;gBACR;YACF,CAAC;YAED,CAAA,KAAA,IAAA,CAAK,QAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA,EAAgB;gBAAE,SAAS,eAAe,KAAA,CAAM,OAAA;YAAQ;YAExD,IAAA,CAAK,SAAA,CAAU;gBAAE,QAAQ;YAAQ,CAAC;QACpC,EAAA,OAAS,KAAK;YACZ,QAAQ,KAAA,CAAM,GAAG;YAGjB,IAAK,IAAY,IAAA,KAAS,cAAc;gBACtC,IAAA,CAAK,SAAA,CAAU;oBAAE,QAAQ;gBAAQ,CAAC;gBAClC,OAAO;YACT;YAEA,IAAI,IAAA,CAAK,OAAA,IAAW,eAAe,OAAO;gBACxC,IAAA,CAAK,OAAA,CAAQ,GAAG;YAClB;YAEA,IAAA,CAAK,SAAA,CAAU;gBAAE,QAAQ;gBAAS,OAAO;YAAa,CAAC;QACzD,SAAE;YACA,IAAA,CAAK,cAAA,GAAiB,KAAA;QACxB;QAIA,IACE,uBAAuB;YACrB,+BAA+B;YAC/B,sBAAsB;YACtB,UAAU,IAAA,CAAK,QAAA;YACf,UAAU,IAAA,CAAK,KAAA,CAAM,QAAA;QACvB,CAAC,GACD;YACA,MAAM,IAAA,CAAK,cAAA,CAAe;gBACxB;gBACA;gBACA;gBACA;YACF,CAAC;QACH;IACF;AACF;AAWA,SAAS,qBAAqB,EAC5B,QAAA,EACA,UAAA,EACA,YAAY,MAAA,EACd,EAIG;IACD,MAAM,cAAc,QAAA,CAAS,SAAS,MAAA,GAAS,CAAC,CAAA;IAEhD,MAAM,iBAAiB,YAAY,KAAA,CAAM,IAAA,CACvC,CAAC,OACC,KAAK,IAAA,KAAS,qBACd,KAAK,cAAA,CAAe,UAAA,KAAe;IAGvC,IAAI,kBAAkB,MAAM;QAC1B;IACF;IAEA,eAAe,cAAA,GAAiB;QAC9B,GAAG,eAAe,cAAA;QAClB,OAAO;QACP;IACF;AACF;;AU7gBO,SAAS,uBACd,QAAA,EACA,OAAA,EACgB;IAnBlB,IAAAC;IAoBE,MAAM,QAAA,CAAQA,OAAA,WAAA,OAAA,KAAA,IAAA,QAAS,KAAA,KAAT,OAAAA,OAAmB,CAAC;IAClC,MAAM,gBAAgC,CAAC,CAAA;IAEvC,KAAA,MAAW,WAAW,SAAU;QAC9B,OAAQ,QAAQ,IAAA,EAAM;YACpB,KAAK;gBAAU;oBACb,cAAc,IAAA,CAAK;wBACjB,MAAM;wBACN,SAAS,QAAQ,KAAA,CACd,GAAA,CAAI,CAAA,OAAS,KAAK,IAAA,KAAS,SAAS,KAAK,IAAA,GAAO,EAAG,EACnD,IAAA,CAAK,EAAE;oBACZ,CAAC;oBACD;gBACF;YAEA,KAAK;gBAAQ;oBACX,cAAc,IAAA,CAAK;wBACjB,MAAM;wBACN,SAAS,QAAQ,KAAA,CACd,MAAA,CACC,CAAC,OACC,KAAK,IAAA,KAAS,UAAU,KAAK,IAAA,KAAS,QAEzC,GAAA,CAAI,CAAA,OACH,KAAK,IAAA,KAAS,SACV;gCACE,MAAM;gCACN,WAAW,KAAK,SAAA;gCAChB,UAAU,KAAK,QAAA;gCACf,MAAM,KAAK,GAAA;4BACb,IACA;oBAEV,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAa;oBAChB,IAAI,QAAQ,KAAA,IAAS,MAAM;wBAKzB,IAASC,gBAAT,WAAwB;4BACtB,IAAI,MAAM,MAAA,KAAW,GAAG;gCACtB;4BACF;4BAEA,MAAM,UAA4B,CAAC,CAAA;4BAEnC,KAAA,MAAW,QAAQ,MAAO;gCACxB,OAAQ,KAAK,IAAA,EAAM;oCACjB,KAAK;wCAAQ;4CACX,QAAQ,IAAA,CAAK,IAAI;4CACjB;wCACF;oCACA,KAAK;wCAAQ;4CACX,QAAQ,IAAA,CAAK;gDACX,MAAM;gDACN,WAAW,KAAK,SAAA;gDAChB,MAAM,KAAK,GAAA;4CACb,CAAC;4CACD;wCACF;oCACA,KAAK;wCAAa;4CAChB,QAAQ,IAAA,CAAK;gDACX,MAAM;gDACN,MAAM,KAAK,IAAA;gDACX,iBAAiB,KAAK,gBAAA;4CACxB,CAAC;4CACD;wCACF;oCACA,KAAK;wCACH,QAAQ,IAAA,CAAK;4CACX,MAAM;4CACN,YAAY,KAAK,cAAA,CAAe,UAAA;4CAChC,UAAU,KAAK,cAAA,CAAe,QAAA;4CAC9B,MAAM,KAAK,cAAA,CAAe,IAAA;wCAC5B,CAAC;wCACD;oCACF;wCAAS;4CACP,MAAM,mBAA0B;4CAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;wCACzD;gCACF;4BACF;4BAEA,cAAc,IAAA,CAAK;gCACjB,MAAM;gCACN;4BACF,CAAC;4BAGD,MAAM,kBAAkB,MACrB,MAAA,CACC,CACE,OAMA,KAAK,IAAA,KAAS,mBAEjB,GAAA,CAAI,CAAA,OAAQ,KAAK,cAAc;4BAGlC,IAAI,gBAAgB,MAAA,GAAS,GAAG;gCAC9B,cAAc,IAAA,CAAK;oCACjB,MAAM;oCACN,SAAS,gBAAgB,GAAA,CACvB,CAAC,mBAAmC;wCAClC,IAAI,CAAA,CAAE,YAAY,cAAA,GAAiB;4CACjC,MAAM,IAAI,uBAAuB;gDAC/B,iBAAiB;gDACjB,SACE,wCACA,KAAK,SAAA,CAAU,cAAc;4CACjC,CAAC;wCACH;wCAEA,MAAM,EAAE,UAAA,EAAY,QAAA,EAAU,MAAA,CAAO,CAAA,GAAI;wCAEzC,MAAMC,QAAO,KAAA,CAAM,QAAQ,CAAA;wCAC3B,OAAA,CAAOA,SAAA,OAAA,KAAA,IAAAA,MAAM,gCAAA,KAAoC,OAC7C;4CACE,MAAM;4CACN;4CACA;4CACA,QAAQA,MAAK,gCAAA,CAAiC,MAAM;4CACpD,sBACEA,MAAK,gCAAA,CAAiC,MAAM;wCAChD,IACA;4CACE,MAAM;4CACN;4CACA;4CACA;wCACF;oCACN;gCAEJ,CAAC;4BACH;4BAGA,QAAQ,CAAC,CAAA;wBACX;wBAvGS,IAAA,eAAAD;wBAJT,IAAI,QAEA,CAAC,CAAA;wBA2GL,KAAA,MAAW,QAAQ,QAAQ,KAAA,CAAO;4BAChC,OAAQ,KAAK,IAAA,EAAM;gCACjB,KAAK;gCACL,KAAK;gCACL,KAAK;gCACL,KAAK;oCAAmB;wCACtB,MAAM,IAAA,CAAK,IAAI;wCACf;oCACF;gCACA,KAAK;oCAAc;wCACjBA,cAAa;wCACb;oCACF;4BACF;wBACF;wBAEAA,cAAa;wBAEb;oBACF;oBAEA;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B,QAAQ,IAAA;oBACxC,MAAM,IAAI,uBAAuB;wBAC/B,iBAAiB;wBACjB,SAAS,CAAA,kBAAA,EAAqB,gBAAgB,EAAA;oBAChD,CAAC;gBACH;QACF;IACF;IAEA,OAAO;AACT;AAMO,IAAM,wBAAwB;;AChN9B,SAAS,+BAA+B,EAC7C,MAAA,EACF,EAEG;IACD,OAAO,OAAO,WAAA,CACZ,IAAI,gBAA2D;QAC7D,OAAM,UAAA,EAAY;YAChB,WAAW,OAAA,CAAQ;gBAAE,MAAM;YAAQ,CAAC;YACpC,WAAW,OAAA,CAAQ;gBAAE,MAAM;YAAa,CAAC;QAC3C;QAEA,MAAM,WAAU,IAAA,EAAM,UAAA,EAAY;YAChC,WAAW,OAAA,CAAQ;gBAAE,MAAM;gBAAQ,MAAM;YAAK,CAAC;QACjD;QAEA,MAAM,OAAM,UAAA,EAAY;YACtB,WAAW,OAAA,CAAQ;gBAAE,MAAM;YAAc,CAAC;YAC1C,WAAW,OAAA,CAAQ;gBAAE,MAAM;YAAS,CAAC;QACvC;IACF,CAAC;AAEL;;AChBA,IAAME,oBAAmB,IAAM;AAE/B,eAAe,gBAAgB,EAC7B,GAAA,EACA,IAAA,EACA,WAAA,EACA,OAAA,EACA,WAAA,EACA,OAAAC,SAAQD,kBAAiB,CAAA,EACzB,cAAc,UAAA,EAChB,EAQ+D;IA1B/D,IAAAE;IA2BE,MAAM,WACJ,gBAAgB,WACZ,MAAMD,OAAM,GAAG,GAAG,CAAA,QAAA,EAAW,KAAK,MAAM,EAAA,EAAI;QAC1C,QAAQ;QACR,SAAS;YACP,gBAAgB;YAChB,GAAG,OAAA;QACL;QACA,QAAQ;QACR;IACF,CAAC,IACD,MAAMA,OAAM,KAAK;QACf,QAAQ;QACR,MAAM,KAAK,SAAA,CAAU,IAAI;QACzB,SAAS;YACP,gBAAgB;YAChB,GAAG,OAAA;QACL;QACA,QAAQ;QACR;IACF,CAAC;IAEP,IAAI,CAAC,SAAS,EAAA,EAAI;QAChB,MAAM,IAAI,MAAA,CACPC,OAAA,MAAM,SAAS,IAAA,CAAK,CAAA,KAApB,OAAAA,OAA0B;IAE/B;IAEA,IAAI,CAAC,SAAS,IAAA,EAAM;QAClB,MAAM,IAAI,MAAM,6BAA6B;IAC/C;IAEA,OAAO,+BAA+B;QACpC,QAAQ,SAAS,IAAA,CAAK,WAAA,CAAY,IAAI,kBAAkB,CAAC;IAC3D,CAAC;AACH;AAEO,IAAM,0BAAN,MAIP;IAQE,YAAY,EACV,GAAA,EACA,WAAA,EACA,OAAA,EACA,IAAA,EACA,OAAAD,MAAAA,EACA,cAAA,EACF,CA6CG;QACD,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,WAAA,GAAc;QACnB,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,KAAA,GAAQA;QACb,IAAA,CAAK,cAAA,GAAiB;IACxB;IAEA,eAAe,EACb,MAAA,EACA,QAAA,EACA,WAAA,EACA,QAAA,EACA,OAAA,EACA,IAAA,EACA,WAAA,EACF,EAEM;QAnJR,IAAAC,MAAA;QAoJI,MAAM,kBAAA,CAAkBA,OAAA,IAAA,CAAK,cAAA,KAAL,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,IAAA,EAAsB;YAC5C,IAAI;YACJ;YACA,MAAM;gBAAE,GAAG,IAAA,CAAK,IAAA;gBAAM,GAAG,IAAA;YAAK;YAC9B,SAAS;gBAAE,GAAG,IAAA,CAAK,OAAA;gBAAS,GAAG,OAAA;YAAQ;YACvC,aAAa,IAAA,CAAK,WAAA;YAClB,iBAAiB;QACnB;QAEA,OAAO,gBAAgB;YACrB,KAAK,IAAA,CAAK,GAAA;YAEV,MAAA,CACE,mBAAA,OAAA,KAAA,IAAA,gBAAiB,IAAA,MAAS,KAAA,IACtB,gBAAgB,IAAA,GAChB;gBAAE,GAAG,IAAA,CAAK,IAAA;gBAAM,GAAG,IAAA;YAAK;YAC9B,SAAA,CACE,mBAAA,OAAA,KAAA,IAAA,gBAAiB,OAAA,MAAY,KAAA,IACzB,gBAAgB,OAAA,GAChB;gBAAE,GAAG,IAAA,CAAK,OAAA;gBAAS,GAAG,OAAA;YAAQ;YACpC,aAAA,CAAa,KAAA,mBAAA,OAAA,KAAA,IAAA,gBAAiB,WAAA,KAAjB,OAAA,KAAgC,IAAA,CAAK,WAAA;YAClD;YACA,OAAO,IAAA,CAAK,KAAA;YACZ;QACF,CAAC;IACH;AACF;;AClKO,SAAS,4BAA0D,EACxE,YAAA,EACA,mBAAmB,CAAC,CAAA,EACpB,QAAA,EACA,MAAA,EACF,EA4BG;IACD,IAAI,YAAY,MAAM;QACpB,OAAO;IACT;IAEA,MAAM,cAAc,gBAAA,CAAiB,iBAAiB,MAAA,GAAS,CAAC,CAAA;IAChE,MAAM,iBAAA,CAAiB,eAAA,OAAA,KAAA,IAAA,YAAa,IAAA,MAAS;IAC7C,MAAM,YAAY,iBAAiB,YAAY,EAAA,GAAK;IAEpD,MAAM,QAAQ,8BAGZ;QACA,aAAa,gBAAgB,WAAW;QACxC,cAAc;IAChB,CAAC;IAED,MAAM,sBAAsB,OAC1B,QASG;QACH,MAAM,IAAI;YAAE;YAAO,OAAO,KAAO,CAAD;QAAG,CAAC;IACtC;IAEA,OAAO,uBAAmC;QACxC;QACA;IACF,CAAC,EAAE,WAAA,CACD,IAAI,gBAAgB;QAClB,WAAU,KAAA,EAAO,UAAA,EAAY;YAC3B,WAAW,OAAA,CAAQ,KAAK;QAC1B;QAEA,QAAQ;YACN,MAAMC,kBAAiB,MAAM,OAAA,CAAQ,EAAA,KAAA,CAAO,eAAA,OAAA,KAAA,IAAA,YAAa,EAAA;YACzD,SAAS;gBACP,gBAAAA;gBACA,iBAAiB,MAAM,OAAA;gBACvB,UAAU;uBACJA,kBACA,iBAAiB,KAAA,CAAM,GAAG,CAAA,CAAE,IAC5B;oBACJ,MAAM,OAAA;iBACR;YACF,CAAC;QACH;IACF,CAAC;AAEL;;AC/FO,SAAS,sBAAoD,EAClE,OAAA,EACA,UAAU,IAAM,oBAAA,EAAA,4CAAA;AAChB,gBAAA,EACA,QAAA,EACF,EA6ByD;IACvD,IAAI;IAIJ,MAAM,wBAAyC,CAAC,CAAA;IAEhD,MAAM,SAAS,IAAI,eAAe;QAChC,OAAM,aAAA,EAAe;YACnB,aAAa;QACf;IACF,CAAC;IAED,SAAS,YAAY,IAAA,EAA4C;QAC/D,IAAI;YACF,WAAW,OAAA,CAAQ,IAAI;QACzB,EAAA,OAAS,OAAO,CAEhB;IACF;IAEA,IAAI;QACF,MAAM,SAAS,QAAQ;YACrB,QAAQ;gBACN,OAAM,IAAA,EAA4C;oBAChD,YAAY,IAAI;gBAClB;gBACA,OAAM,SAAA,EAAW;oBACf,sBAAsB,IAAA,CAAA,CACnB,YAAY;wBACX,MAAM,SAAS,UAAU,SAAA,CAAU;wBACnC,MAAO,KAAM;4BACX,MAAM,EAAE,IAAA,EAAM,KAAA,CAAM,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;4BAC1C,IAAI,MAAM;4BACV,YAAY,KAAK;wBACnB;oBACF,CAAA,EAAG,EAAE,KAAA,CAAM,CAAA,UAAS;wBAClB,YAAY;4BACV,MAAM;4BACN,WAAW,QAAQ,KAAK;wBAC1B,CAAyC;oBAC3C,CAAC;gBAEL;gBACA;YACF;QACF,CAAC;QAED,IAAI,QAAQ;YACV,sBAAsB,IAAA,CACpB,OAAO,KAAA,CAAM,CAAA,UAAS;gBACpB,YAAY;oBACV,MAAM;oBACN,WAAW,QAAQ,KAAK;gBAC1B,CAAyC;YAC3C,CAAC;QAEL;IACF,EAAA,OAAS,OAAO;QACd,YAAY;YACV,MAAM;YACN,WAAW,QAAQ,KAAK;QAC1B,CAAyC;IAC3C;IAMA,MAAM,iBAAgC,IAAI,QAAQ,OAAM,YAAW;QACjE,MAAO,sBAAsB,MAAA,GAAS,EAAG;YACvC,MAAM,sBAAsB,KAAA,CAAM;QACpC;QACA,QAAQ;IACV,CAAC;IAED,eAAe,OAAA,CAAQ,MAAM;QAC3B,IAAI;YACF,WAAW,KAAA,CAAM;QACnB,EAAA,OAAS,OAAO,CAEhB;IACF,CAAC;IAED,OAAO,4BAA4B;QACjC;QACA,cAAc;QACd;QACA;IACF,CAAC;AACH;;ACjIO,IAAM,2BAAN,cAAuC,gBAAiC;IAC7E,aAAc;QACZ,KAAA,CAAM;YACJ,WAAU,IAAA,EAAM,UAAA,EAAY;gBAC1B,WAAW,OAAA,CAAQ,CAAA,MAAA,EAAS,KAAK,SAAA,CAAU,IAAI,CAAC,CAAA;;AAAA,CAAM;YACxD;YACA,OAAM,UAAA,EAAY;gBAChB,WAAW,OAAA,CAAQ,kBAAkB;YACvC;QACF,CAAC;IACH;AACF;;ACXO,IAAM,yBAAyB;IACpC,gBAAgB;IAChB,iBAAiB;IACjB,YAAY;IACZ,iCAAiC;IACjC,qBAAqB;AACvB;;ACDO,SAAS,8BAA8B,EAC5C,MAAA,EACA,UAAA,EACA,OAAA,EACA,MAAA,EACF,EAEa;IACX,OAAO,IAAI,SACT,OACG,WAAA,CAAY,IAAI,yBAAyB,CAAC,EAC1C,WAAA,CAAY,IAAI,kBAAkB,CAAC,GACtC;QACE;QACA;QACA,SAAS,eAAe,SAAS,sBAAsB;IACzD;AAEJ;;AChBO,SAAS,8BAA8B,EAC5C,QAAA,EACA,MAAA,EACA,UAAA,EACA,OAAA,EACA,MAAA,EACF,EAGwB;IACtB,sBAAsB;QACpB;QACA;QACA;QACA,SAAS,OAAO,WAAA,CACd,eAAe,SAAS,sBAAsB,EAAE,OAAA,CAAQ;QAE1D,QAAQ,OACL,WAAA,CAAY,IAAI,yBAAyB,CAAC,EAC1C,WAAA,CAAY,IAAI,kBAAkB,CAAC;IACxC,CAAC;AACH;;ACdO,SAAS,iBAAiB,OAAA,EAAmB,OAAA,EAA2B;IAC7E,IAAI,QAAQ,MAAA,KAAW,QAAQ,MAAA,EAAQ;QACrC,MAAM,IAAI,qBAAqB;YAC7B,WAAW;YACX,OAAO;gBAAE,eAAe,QAAQ,MAAA;gBAAQ,eAAe,QAAQ,MAAA;YAAO;YACtE,SAAS,CAAA,iCAAA,CAAA;QACX,CAAC;IACH;IAEA,MAAM,IAAI,QAAQ,MAAA;IAElB,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IAEA,IAAI,oBAAoB;IACxB,IAAI,oBAAoB;IACxB,IAAI,aAAa;IAEjB,IAAA,IAAS,IAAI,GAAG,IAAI,GAAG,IAAK;QAC1B,MAAM,SAAS,OAAA,CAAQ,CAAC,CAAA;QACxB,MAAM,SAAS,OAAA,CAAQ,CAAC,CAAA;QAExB,qBAAqB,SAAS;QAC9B,qBAAqB,SAAS;QAC9B,cAAc,SAAS;IACzB;IAEA,OAAO,sBAAsB,KAAK,sBAAsB,IACpD,IACA,aAAA,CACG,KAAK,IAAA,CAAK,iBAAiB,IAAI,KAAK,IAAA,CAAK,iBAAiB,CAAA;AACnE;;AC3CO,SAAS,mBAAmB,OAAA,EAAyB;IAC1D,MAAM,CAAC,QAAQ,aAAa,CAAA,GAAI,QAAQ,KAAA,CAAM,GAAG;IACjD,MAAM,YAAY,OAAO,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA,CAAE,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA;IAEnD,IAAI,aAAa,QAAQ,iBAAiB,MAAM;QAC9C,MAAM,IAAI,MAAM,yBAAyB;IAC3C;IAEA,IAAI;QACF,OAAO,OAAO,IAAA,CAAK,aAAa;IAClC,EAAA,OAAS,OAAO;QACd,MAAM,IAAI,MAAM,CAAA,uBAAA,CAAyB;IAC3C;AACF;;ACTO,SAAS,gBAAgB,IAAA,EAAW,IAAA,EAAoB;IAE7D,IAAI,SAAS,MAAM,OAAO;IAG1B,IAAI,QAAQ,QAAQ,QAAQ,MAAM,OAAO;IAGzC,IAAI,OAAO,SAAS,YAAY,OAAO,SAAS,UAC9C,OAAO,SAAS;IAGlB,IAAI,KAAK,WAAA,KAAgB,KAAK,WAAA,EAAa,OAAO;IAGlD,IAAI,gBAAgB,QAAQ,gBAAgB,MAAM;QAChD,OAAO,KAAK,OAAA,CAAQ,MAAM,KAAK,OAAA,CAAQ;IACzC;IAGA,IAAI,MAAM,OAAA,CAAQ,IAAI,GAAG;QACvB,IAAI,KAAK,MAAA,KAAW,KAAK,MAAA,EAAQ,OAAO;QACxC,IAAA,IAAS,IAAI,GAAG,IAAI,KAAK,MAAA,EAAQ,IAAK;YACpC,IAAI,CAAC,gBAAgB,IAAA,CAAK,CAAC,CAAA,EAAG,IAAA,CAAK,CAAC,CAAC,GAAG,OAAO;QACjD;QACA,OAAO;IACT;IAGA,MAAM,QAAQ,OAAO,IAAA,CAAK,IAAI;IAC9B,MAAM,QAAQ,OAAO,IAAA,CAAK,IAAI;IAC9B,IAAI,MAAM,MAAA,KAAW,MAAM,MAAA,EAAQ,OAAO;IAG1C,KAAA,MAAW,OAAO,MAAO;QACvB,IAAI,CAAC,MAAM,QAAA,CAAS,GAAG,GAAG,OAAO;QACjC,IAAI,CAAC,gBAAgB,IAAA,CAAK,GAAG,CAAA,EAAG,IAAA,CAAK,GAAG,CAAC,GAAG,OAAO;IACrD;IAEA,OAAO;AACT;;ACpCO,SAAS,uBAA0B,EACxC,MAAA,EACA,mBAAmB,CAAA,EACnB,iBAAiB,CAAA,EACjB,SAAA,EACF,EAOsB;IAvBtB,IAAAC;IAwBE,MAAMC,SAAAA,CAAQD,OAAA,aAAA,OAAA,KAAA,IAAA,UAAW,KAAA,KAAX,OAAAA,OAAoB,2LAAA;IAElC,IAAI,QAAQ;IAEZ,OAAO,IAAI,eAAe;QACxB,MAAM,MAAK,UAAA,EAAY;YACrB,IAAI,QAAQ,OAAO,MAAA,EAAQ;gBACzB,MAAMC,OAAM,UAAU,IAAI,mBAAmB,cAAc;gBAC3D,WAAW,OAAA,CAAQ,MAAA,CAAO,OAAO,CAAC;YACpC,OAAO;gBACL,WAAW,KAAA,CAAM;YACnB;QACF;IACF,CAAC;AACH;;;AC1BO,IAAM,8BACX,CAAC,EACC,aAAa,CAAA,EACb,mBAAmB,GAAA,EACnB,gBAAgB,CAAA,EAClB,GAAI,CAAC,CAAA,GACL,OAAe,IACb,6BAA6B,GAAG;YAC9B;YACA,WAAW;YACX;QACF,CAAC;AAEL,eAAe,6BACb,CAAA,EACA,EACE,UAAA,EACA,SAAA,EACA,aAAA,EACF,EACA,SAAoB,CAAC,CAAA,EACJ;IACjB,IAAI;QACF,OAAO,MAAM,EAAE;IACjB,EAAA,OAAS,OAAO;QACd,2LAAI,eAAA,EAAa,KAAK,GAAG;YACvB,MAAM;QACR;QAEA,IAAI,eAAe,GAAG;YACpB,MAAM;QACR;QAEA,MAAM,sMAAeG,kBAAAA,EAAgB,KAAK;QAC1C,MAAM,YAAY,CAAC;eAAG;YAAQ,KAAK;SAAA;QACnC,MAAM,YAAY,UAAU,MAAA;QAE5B,IAAI,YAAY,YAAY;YAC1B,MAAM,IAAI,WAAW;gBACnB,SAAS,CAAA,aAAA,EAAgB,SAAS,CAAA,uBAAA,EAA0B,YAAY,EAAA;gBACxE,QAAQ;gBACR,QAAQ;YACV,CAAC;QACH;QAEA,IACE,iBAAiB,kKACjBC,gBAAAA,CAAa,UAAA,CAAW,KAAK,KAC7B,MAAM,WAAA,KAAgB,QACtB,aAAa,YACb;YACA,6LAAM,QAAA,EAAM,SAAS;YACrB,OAAO,6BACL,GACA;gBAAE;gBAAY,WAAW,gBAAgB;gBAAW;YAAc,GAClE;QAEJ;QAEA,IAAI,cAAc,GAAG;YACnB,MAAM;QACR;QAEA,MAAM,IAAI,WAAW;YACnB,SAAS,CAAA,aAAA,EAAgB,SAAS,CAAA,qCAAA,EAAwC,YAAY,CAAA,CAAA,CAAA;YACtF,QAAQ;YACR,QAAQ;QACV,CAAC;IACH;AACF;;ACxEO,SAAS,eAAe,EAC7B,UAAA,EACF,EAKE;IACA,IAAI,cAAc,MAAM;QACtB,IAAI,CAAC,OAAO,SAAA,CAAU,UAAU,GAAG;YACjC,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,aAAa,GAAG;YAClB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,MAAM,mBAAmB,cAAA,OAAA,aAAc;IAEvC,OAAO;QACL,YAAY;QACZ,OAAO,4BAA4B;YAAE,YAAY;QAAiB,CAAC;IACrE;AACF;;ACvCO,SAAS,sBAAsB,EACpC,WAAA,EACA,SAAA,EACF,EAGG;IACD,OAAO;QAAA,4CAAA;QAEL,kBAAkB,GAAG,WAAW,GAAA,CAC9B,aAAA,OAAA,KAAA,IAAA,UAAW,UAAA,KAAc,OAAO,CAAA,CAAA,EAAI,UAAU,UAAU,EAAA,GAAK,EAC/D,EAAA;QACA,iBAAiB,aAAA,OAAA,KAAA,IAAA,UAAW,UAAA;QAAA,kCAAA;QAG5B,kBAAkB;QAClB,2BAA2B,aAAA,OAAA,KAAA,IAAA,UAAW,UAAA;IACxC;AACF;;AChBO,SAAS,2BAA2B,EACzC,KAAA,EACA,QAAA,EACA,SAAA,EACA,OAAA,EACF,EAKe;IAdf,IAAAC;IAeE,OAAO;QACL,qBAAqB,MAAM,QAAA;QAC3B,eAAe,MAAM,OAAA;QAAA,YAAA;QAGrB,GAAG,OAAO,OAAA,CAAQ,QAAQ,EAAE,MAAA,CAAO,CAAC,YAAY,CAAC,KAAK,KAAK,CAAA,KAAM;YAC/D,UAAA,CAAW,CAAA,YAAA,EAAe,GAAG,EAAE,CAAA,GAAI;YACnC,OAAO;QACT,GAAG,CAAC,CAAe,CAAA;QAAA,8BAAA;QAGnB,GAAG,OAAO,OAAA,CAAA,CAAQA,OAAA,aAAA,OAAA,KAAA,IAAA,UAAW,QAAA,KAAX,OAAAA,OAAuB,CAAC,CAAC,EAAE,MAAA,CAC3C,CAAC,YAAY,CAAC,KAAK,KAAK,CAAA,KAAM;YAC5B,UAAA,CAAW,CAAA,sBAAA,EAAyB,GAAG,EAAE,CAAA,GAAI;YAC7C,OAAO;QACT,GACA,CAAC,EACH;QAAA,kBAAA;QAGA,GAAG,OAAO,OAAA,CAAQ,WAAA,OAAA,UAAW,CAAC,CAAC,EAAE,MAAA,CAAO,CAAC,YAAY,CAAC,KAAK,KAAK,CAAA,KAAM;YACpE,IAAI,UAAU,KAAA,GAAW;gBACvB,UAAA,CAAW,CAAA,mBAAA,EAAsB,GAAG,EAAE,CAAA,GAAI;YAC5C;YACA,OAAO;QACT,GAAG,CAAC,CAAe,CAAA;IACrB;AACF;;;AErCO,IAAM,aAAqB;IAChC,YAAkB;QAChB,OAAO;IACT;IAEA,iBACEC,MAAAA,EACA,IAAA,EACA,IAAA,EACA,IAAA,EACiB;QACjB,IAAI,OAAO,SAAS,YAAY;YAC9B,OAAO,KAAK,QAAQ;QACtB;QACA,IAAI,OAAO,SAAS,YAAY;YAC9B,OAAO,KAAK,QAAQ;QACtB;QACA,IAAI,OAAO,SAAS,YAAY;YAC9B,OAAO,KAAK,QAAQ;QACtB;IACF;AACF;AAEA,IAAM,WAAiB;IACrB,cAAc;QACZ,OAAO;IACT;IACA,eAAe;QACb,OAAO,IAAA;IACT;IACA,gBAAgB;QACd,OAAO,IAAA;IACT;IACA,WAAW;QACT,OAAO,IAAA;IACT;IACA,UAAU;QACR,OAAO,IAAA;IACT;IACA,WAAW;QACT,OAAO,IAAA;IACT;IACA,YAAY;QACV,OAAO,IAAA;IACT;IACA,aAAa;QACX,OAAO,IAAA;IACT;IACA,MAAM;QACJ,OAAO,IAAA;IACT;IACA,cAAc;QACZ,OAAO;IACT;IACA,kBAAkB;QAChB,OAAO,IAAA;IACT;AACF;AAEA,IAAM,kBAA+B;IACnC,SAAS;IACT,QAAQ;IACR,YAAY;AACd;;ADjEO,SAAS,UAAU,EACxB,YAAY,KAAA,EACZ,MAAA,EACF,GAGI,CAAC,CAAA,EAAW;IACd,IAAI,CAAC,WAAW;QACd,OAAO;IACT;IAEA,IAAI,QAAQ;QACV,OAAO;IACT;IAEA,6IAAO,QAAA,CAAM,SAAA,CAAU,IAAI;AAC7B;;AEjBO,SAAS,WAAc,EAC5B,MAAAC,MAAAA,EACA,MAAA,EACA,UAAA,EACA,EAAA,EACA,cAAc,IAAA,EAChB,EAMG;IACD,OAAO,OAAO,eAAA,CAAgBA,QAAM;QAAE;IAAW,GAAG,OAAM,SAAQ;QAChE,IAAI;YACF,MAAM,SAAS,MAAM,GAAG,IAAI;YAE5B,IAAI,aAAa;gBACf,KAAK,GAAA,CAAI;YACX;YAEA,OAAO;QACT,EAAA,OAAS,OAAO;YACd,IAAI;gBACF,IAAI,iBAAiB,OAAO;oBAC1B,KAAK,eAAA,CAAgB;wBACnB,MAAM,MAAM,IAAA;wBACZ,SAAS,MAAM,OAAA;wBACf,OAAO,MAAM,KAAA;oBACf,CAAC;oBACD,KAAK,SAAA,CAAU;wBACb,4IAAM,iBAAA,CAAe,KAAA;wBACrB,SAAS,MAAM,OAAA;oBACjB,CAAC;gBACH,OAAO;oBACL,KAAK,SAAA,CAAU;wBAAE,4IAAM,iBAAA,CAAe,KAAA;oBAAM,CAAC;gBAC/C;YACF,SAAE;gBAEA,KAAK,GAAA,CAAI;YACX;YAEA,MAAM;QACR;IACF,CAAC;AACH;;AC5CO,SAAS,0BAA0B,EACxC,SAAA,EACA,UAAA,EACF,EASe;IAEb,IAAA,CAAI,aAAA,OAAA,KAAA,IAAA,UAAW,SAAA,MAAc,MAAM;QACjC,OAAO,CAAC;IACV;IAEA,OAAO,OAAO,OAAA,CAAQ,UAAU,EAAE,MAAA,CAAO,CAACC,aAAY,CAAC,KAAK,KAAK,CAAA,KAAM;QACrE,IAAI,UAAU,KAAA,GAAW;YACvB,OAAOA;QACT;QAGA,IACE,OAAO,UAAU,YACjB,WAAW,SACX,OAAO,MAAM,KAAA,KAAU,YACvB;YAEA,IAAA,CAAI,aAAA,OAAA,KAAA,IAAA,UAAW,YAAA,MAAiB,OAAO;gBACrC,OAAOA;YACT;YAEA,MAAM,SAAS,MAAM,KAAA,CAAM;YAE3B,OAAO,WAAW,KAAA,IACdA,cACA;gBAAE,GAAGA,WAAAA;gBAAY,CAAC,GAAG,CAAA,EAAG;YAAO;QACrC;QAGA,IACE,OAAO,UAAU,YACjB,YAAY,SACZ,OAAO,MAAM,MAAA,KAAW,YACxB;YAEA,IAAA,CAAI,aAAA,OAAA,KAAA,IAAA,UAAW,aAAA,MAAkB,OAAO;gBACtC,OAAOA;YACT;YAEA,MAAM,SAAS,MAAM,MAAA,CAAO;YAE5B,OAAO,WAAW,KAAA,IACdA,cACA;gBAAE,GAAGA,WAAAA;gBAAY,CAAC,GAAG,CAAA,EAAG;YAAO;QACrC;QAGA,OAAO;YAAE,GAAGA,WAAAA;YAAY,CAAC,GAAG,CAAA,EAAG;QAAM;IACvC,GAAG,CAAC,CAAC;AACP;;AC3CA,eAAsB,MAAa,EACjC,KAAA,EACA,KAAA,EACA,eAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACA,wBAAwB,SAAA,EAC1B,EAwCgC;IAC9B,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAE1E,MAAM,0BAA0B,2BAA2B;QACzD;QACA;QACA;QACA,UAAU;YAAE;QAAW;IACzB,CAAC;IAED,MAAM,SAAS,UAAU,SAAS;IAElC,OAAO,WAAW;QAChB,MAAM;QACN,YAAY,0BAA0B;YACpC;YACA,YAAY;gBACV,GAAG,sBAAsB;oBAAE,aAAa;oBAAY;gBAAU,CAAC,CAAA;gBAC/D,GAAG,uBAAA;gBACH,YAAY;oBAAE,OAAO,IAAM,KAAK,SAAA,CAAU,KAAK;gBAAE;YACnD;QACF,CAAC;QACD;QACA,IAAI,OAAM,SAAQ;YAChB,MAAM,EAAE,SAAA,EAAW,KAAA,EAAO,QAAA,CAAS,CAAA,GAAI,MAAM,MAAM,IAAA,2DAAA;gBAEjD,WAAW;oBACT,MAAM;oBACN,YAAY,0BAA0B;wBACpC;wBACA,YAAY;4BACV,GAAG,sBAAsB;gCACvB,aAAa;gCACb;4BACF,CAAC,CAAA;4BACD,GAAG,uBAAA;4BAAA,6DAAA;4BAEH,aAAa;gCAAE,OAAO,IAAM;wCAAC,KAAK,SAAA,CAAU,KAAK,CAAC;qCAAA;4BAAE;wBACtD;oBACF,CAAC;oBACD;oBACA,IAAI,OAAM,gBAAe;wBA/GnC,IAAAC;wBAgHY,MAAM,gBAAgB,MAAM,MAAM,OAAA,CAAQ;4BACxC,QAAQ;gCAAC,KAAK;6BAAA;4BACd;4BACA;4BACA;wBACF,CAAC;wBAED,MAAMC,aAAY,cAAc,UAAA,CAAW,CAAC,CAAA;wBAC5C,MAAMC,SAAAA,CAAQF,OAAA,cAAc,KAAA,KAAd,OAAAA,OAAuB;4BAAE,QAAQ;wBAAI;wBAEnD,YAAY,aAAA,CACV,0BAA0B;4BACxB;4BACA,YAAY;gCACV,iBAAiB;oCACf,QAAQ,IACN,cAAc,UAAA,CAAW,GAAA,CAAI,CAAAC,aAC3B,KAAK,SAAA,CAAUA,UAAS;gCAE9B;gCACA,mBAAmBC,OAAM,MAAA;4BAC3B;wBACF,CAAC;wBAGH,OAAO;4BACL,WAAAD;4BACA,OAAAC;4BACA,UAAU,cAAc,QAAA;wBAC1B;oBACF;gBACF,CAAC;YAGH,KAAK,aAAA,CACH,0BAA0B;gBACxB;gBACA,YAAY;oBACV,gBAAgB;wBAAE,QAAQ,IAAM,KAAK,SAAA,CAAU,SAAS;oBAAE;oBAC1D,mBAAmB,MAAM,MAAA;gBAC3B;YACF,CAAC;YAGH,OAAO,IAAI,mBAAmB;gBAC5B;gBACA;gBACA;gBACA;YACF,CAAC;QACH;IACF,CAAC;AACH;AAEA,IAAM,qBAAN,MAA8D;IAM5D,YAAY,OAAA,CAKT;QACD,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;QACzB,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;IAC1B;AACF;;AC/KO,SAAS,WAAc,KAAA,EAAY,SAAA,EAA0B;IAClE,IAAI,aAAa,GAAG;QAClB,MAAM,IAAI,MAAM,kCAAkC;IACpD;IAEA,MAAM,SAAS,CAAC,CAAA;IAChB,IAAA,IAAS,IAAI,GAAG,IAAI,MAAM,MAAA,EAAQ,KAAK,UAAW;QAChD,OAAO,IAAA,CAAK,MAAM,KAAA,CAAM,GAAG,IAAI,SAAS,CAAC;IAC3C;IAEA,OAAO;AACT;;ACQA,eAAsB,UAAiB,EACrC,KAAA,EACA,MAAA,EACA,mBAAmB,QAAA,EACnB,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACA,eAAA,EACA,wBAAwB,SAAA,EAC1B,EA+CoC;IAClC,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAE1E,MAAM,0BAA0B,2BAA2B;QACzD;QACA;QACA;QACA,UAAU;YAAE;QAAW;IACzB,CAAC;IAED,MAAM,SAAS,UAAU,SAAS;IAElC,OAAO,WAAW;QAChB,MAAM;QACN,YAAY,0BAA0B;YACpC;YACA,YAAY;gBACV,GAAG,sBAAsB;oBAAE,aAAa;oBAAgB;gBAAU,CAAC,CAAA;gBACnE,GAAG,uBAAA;gBAAA,6DAAA;gBAEH,aAAa;oBACX,OAAO,IAAM,OAAO,GAAA,CAAI,CAAA,QAAS,KAAK,SAAA,CAAU,KAAK,CAAC;gBACxD;YACF;QACF,CAAC;QACD;QACA,IAAI,OAAM,SAAQ;YAChB,MAAM,CAAC,sBAAsB,qBAAqB,CAAA,GAAI,MAAM,QAAQ,GAAA,CAAI;gBACtE,MAAM,oBAAA;gBACN,MAAM,qBAAA;aACP;YAID,IAAI,wBAAwB,QAAQ,yBAAyB,UAAU;gBACrE,MAAM,EAAE,YAAAC,WAAAA,EAAY,KAAA,EAAO,QAAA,CAAS,CAAA,GAAI,MAAM,MAAM,MAAM;oBAExD,OAAO,WAAW;wBAChB,MAAM;wBACN,YAAY,0BAA0B;4BACpC;4BACA,YAAY;gCACV,GAAG,sBAAsB;oCACvB,aAAa;oCACb;gCACF,CAAC,CAAA;gCACD,GAAG,uBAAA;gCAAA,6DAAA;gCAEH,aAAa;oCACX,OAAO,IAAM,OAAO,GAAA,CAAI,CAAA,QAAS,KAAK,SAAA,CAAU,KAAK,CAAC;gCACxD;4BACF;wBACF,CAAC;wBACD;wBACA,IAAI,OAAM,gBAAe;4BAzIrC,IAAAC;4BA0Ic,MAAM,gBAAgB,MAAM,MAAM,OAAA,CAAQ;gCACxC;gCACA;gCACA;gCACA;4BACF,CAAC;4BAED,MAAMD,cAAa,cAAc,UAAA;4BACjC,MAAME,SAAAA,CAAQD,OAAA,cAAc,KAAA,KAAd,OAAAA,OAAuB;gCAAE,QAAQ;4BAAI;4BAEnD,YAAY,aAAA,CACV,0BAA0B;gCACxB;gCACA,YAAY;oCACV,iBAAiB;wCACf,QAAQ,IACND,YAAW,GAAA,CAAI,CAAA,YAAa,KAAK,SAAA,CAAU,SAAS,CAAC;oCACzD;oCACA,mBAAmBE,OAAM,MAAA;gCAC3B;4BACF,CAAC;4BAGH,OAAO;gCACL,YAAAF;gCACA,OAAAE;gCACA,UAAU,cAAc,QAAA;4BAC1B;wBACF;oBACF,CAAC;gBACH,CAAC;gBAED,KAAK,aAAA,CACH,0BAA0B;oBACxB;oBACA,YAAY;wBACV,iBAAiB;4BACf,QAAQ,IACNF,YAAW,GAAA,CAAI,CAAA,YAAa,KAAK,SAAA,CAAU,SAAS,CAAC;wBACzD;wBACA,mBAAmB,MAAM,MAAA;oBAC3B;gBACF,CAAC;gBAGH,OAAO,IAAI,uBAAuB;oBAChC;oBACA,YAAAA;oBACA;oBACA,WAAW;wBAAC,QAAQ;qBAAA;gBACtB,CAAC;YACH;YAGA,MAAM,cAAc,WAAW,QAAQ,oBAAoB;YAG3D,MAAM,aAA+B,CAAC,CAAA;YACtC,MAAM,YAMF,CAAC,CAAA;YACL,IAAI,SAAS;YAEb,MAAM,iBAAiB,WACrB,aACA,wBAAwB,mBAAmB;YAG7C,KAAA,MAAW,iBAAiB,eAAgB;gBAC1C,MAAM,UAAU,MAAM,QAAQ,GAAA,CAC5B,cAAc,GAAA,CAAI,CAAA,UAAS;oBACzB,OAAO,MAAM,MAAM;wBAEjB,OAAO,WAAW;4BAChB,MAAM;4BACN,YAAY,0BAA0B;gCACpC;gCACA,YAAY;oCACV,GAAG,sBAAsB;wCACvB,aAAa;wCACb;oCACF,CAAC,CAAA;oCACD,GAAG,uBAAA;oCAAA,6DAAA;oCAEH,aAAa;wCACX,OAAO,IAAM,MAAM,GAAA,CAAI,CAAA,QAAS,KAAK,SAAA,CAAU,KAAK,CAAC;oCACvD;gCACF;4BACF,CAAC;4BACD;4BACA,IAAI,OAAM,gBAAe;gCAxOzC,IAAAC;gCAyOkB,MAAM,gBAAgB,MAAM,MAAM,OAAA,CAAQ;oCACxC,QAAQ;oCACR;oCACA;oCACA;gCACF,CAAC;gCAED,MAAMD,cAAa,cAAc,UAAA;gCACjC,MAAM,QAAA,CAAQC,OAAA,cAAc,KAAA,KAAd,OAAAA,OAAuB;oCAAE,QAAQ;gCAAI;gCAEnD,YAAY,aAAA,CACV,0BAA0B;oCACxB;oCACA,YAAY;wCACV,iBAAiB;4CACf,QAAQ,IACND,YAAW,GAAA,CAAI,CAAA,YACb,KAAK,SAAA,CAAU,SAAS;wCAE9B;wCACA,mBAAmB,MAAM,MAAA;oCAC3B;gCACF,CAAC;gCAGH,OAAO;oCACL,YAAAA;oCACA;oCACA,UAAU,cAAc,QAAA;gCAC1B;4BACF;wBACF,CAAC;oBACH,CAAC;gBACH,CAAC;gBAGH,KAAA,MAAW,UAAU,QAAS;oBAC5B,WAAW,IAAA,CAAK,GAAG,OAAO,UAAU;oBACpC,UAAU,IAAA,CAAK,OAAO,QAAQ;oBAC9B,UAAU,OAAO,KAAA,CAAM,MAAA;gBACzB;YACF;YAEA,KAAK,aAAA,CACH,0BAA0B;gBACxB;gBACA,YAAY;oBACV,iBAAiB;wBACf,QAAQ,IACN,WAAW,GAAA,CAAI,CAAA,YAAa,KAAK,SAAA,CAAU,SAAS,CAAC;oBACzD;oBACA,mBAAmB;gBACrB;YACF,CAAC;YAGH,OAAO,IAAI,uBAAuB;gBAChC;gBACA;gBACA,OAAO;oBAAE;gBAAO;gBAChB;YACF,CAAC;QACH;IACF,CAAC;AACH;AAEA,IAAM,yBAAN,MAAsE;IAMpE,YAAY,OAAA,CAKT;QACD,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,UAAA,GAAa,QAAQ,UAAA;QAC1B,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;IAC3B;AACF;;AC1TO,IAAM,2BAA2B;IACtC;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM,EAAI;SAAA;QAC9B,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM,GAAI;SAAA;QACxB,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM,EAAI;SAAA;QACxB,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,CAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YACX;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;SACpE;QACA,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YACX;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;YAAM;SACpE;QACA,cAAc;IAChB;CACF;AAEO,IAAM,2BAA2B;IACtC;QACE,WAAW;QACX,aAAa;YAAC;YAAM,GAAI;SAAA;QACxB,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,EAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,CAAI;SAAA;QACpC,cAAc;IAChB;IACA;QACE,WAAW;QACX,aAAa;YAAC;YAAM;YAAM;YAAM,GAAI;SAAA;QACpC,cAAc;IAChB;CACF;AAEA,IAAM,WAAW,CAAC,SAA8B;IAC9C,MAAM,QACJ,OAAO,SAAS,iMAAW,6BAAA,EAA0B,IAAI,IAAI;IAC/D,MAAM,UAAA,CACF,KAAA,CAAM,CAAC,CAAA,GAAI,GAAA,KAAS,KAAA,CACpB,KAAA,CAAM,CAAC,CAAA,GAAI,GAAA,KAAS,KAAA,CACpB,KAAA,CAAM,CAAC,CAAA,GAAI,GAAA,KAAS,IACrB,KAAA,CAAM,CAAC,CAAA,GAAI;IAGd,OAAO,MAAM,KAAA,CAAM,UAAU,EAAE;AACjC;AAEA,SAAS,sBAAsB,IAAA,EAAgD;IAC7E,MAAM,SACH,OAAO,SAAS,YAAY,KAAK,UAAA,CAAW,MAAM,KAClD,OAAO,SAAS,YACf,KAAK,MAAA,GAAS,MACd,IAAA,CAAK,CAAC,CAAA,KAAM,MAAA,MAAA;IACZ,IAAA,CAAK,CAAC,CAAA,KAAM,MAAA,MAAA;IACZ,IAAA,CAAK,CAAC,CAAA,KAAM;IAEhB,OAAO,SAAS,SAAS,IAAI,IAAI;AACnC;AASO,SAAS,gBAAgB,EAC9B,IAAA,EACA,UAAA,EACF,EAGyD;IACvD,MAAM,gBAAgB,sBAAsB,IAAI;IAEhD,KAAA,MAAW,aAAa,WAAY;QAClC,IACE,OAAO,kBAAkB,WACrB,cAAc,UAAA,CAAW,UAAU,YAAY,IAC/C,cAAc,MAAA,IAAU,UAAU,WAAA,CAAY,MAAA,IAC9C,UAAU,WAAA,CAAY,KAAA,CACpB,CAAC,MAAM,QAAU,aAAA,CAAc,KAAK,CAAA,KAAM,OAEhD;YACA,OAAO,UAAU,SAAA;QACnB;IACF;IAEA,OAAO,KAAA;AACT;;ACnHO,IAAM,uBAAN,MAAoD;IAMzD,YAAY,EACV,IAAA,EACA,SAAA,EACF,CAGG;QACD,MAAM,eAAe,gBAAgB;QACrC,IAAA,CAAK,UAAA,GAAa,eAAe,KAAA,IAAY;QAC7C,IAAA,CAAK,cAAA,GAAiB,eAAe,OAAO,KAAA;QAC5C,IAAA,CAAK,SAAA,GAAY;IACnB;IAAA,yEAAA;IAGA,IAAI,SAAS;QACX,IAAI,IAAA,CAAK,UAAA,IAAc,MAAM;YAC3B,IAAA,CAAK,UAAA,0LAAa,4BAAA,EAA0B,IAAA,CAAK,cAAe;QAClE;QACA,OAAO,IAAA,CAAK,UAAA;IACd;IAAA,yEAAA;IAGA,IAAI,aAAa;QACf,IAAI,IAAA,CAAK,cAAA,IAAkB,MAAM;YAC/B,IAAA,CAAK,cAAA,0LAAiBG,4BAAAA,EAA0B,IAAA,CAAK,UAAW;QAClE;QACA,OAAO,IAAA,CAAK,cAAA;IACd;AACF;AAEO,IAAM,+BAAN,cAA2C,qBAAqB;IAGrE,YAAY,OAAA,CAA2D;QACrE,KAAA,CAAM,OAAO;QAHf,IAAA,CAAS,IAAA,GAAO;IAIhB;AACF;;ACpCA,eAAsB,cAAc,EAClC,KAAA,EACA,MAAA,EACA,IAAI,CAAA,EACJ,gBAAA,EACA,IAAA,EACA,WAAA,EACA,IAAA,EACA,eAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACF,EAqEiC;IAlHjC,IAAAC,MAAA;IAmHE,MAAM,EAAE,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAI9D,MAAM,8BAAA,CACJA,OAAA,oBAAA,OAAA,mBAAqB,MAAM,4BAA4B,KAAK,CAAA,KAA5D,OAAAA,OAAkE;IAGpE,MAAM,YAAY,KAAK,IAAA,CAAK,IAAI,2BAA2B;IAC3D,MAAM,kBAAkB,MAAM,IAAA,CAAK;QAAE,QAAQ;IAAU,GAAG,CAAC,GAAG,MAAM;QAClE,IAAI,IAAI,YAAY,GAAG;YACrB,OAAO;QACT;QAEA,MAAM,YAAY,IAAI;QACtB,OAAO,cAAc,IAAI,8BAA8B;IACzD,CAAC;IAED,MAAM,UAAU,MAAM,QAAQ,GAAA,CAC5B,gBAAgB,GAAA,CAAI,OAAM,iBACxB,MAAM,IACJ,MAAM,UAAA,CAAW;gBACf;gBACA,GAAG;gBACH;gBACA;gBACA;gBACA;gBACA;gBACA,iBAAiB,mBAAA,OAAA,kBAAmB,CAAC;YACvC,CAAC;IAMP,MAAM,SAAsC,CAAC,CAAA;IAC7C,MAAM,WAA0C,CAAC,CAAA;IACjD,MAAM,YAA+C,CAAC,CAAA;IACtD,MAAM,mBAAiD,CAAC;IACxD,KAAA,MAAW,UAAU,QAAS;QAC5B,OAAO,IAAA,IACF,OAAO,MAAA,CAAO,GAAA,CACf,CAAA,UAAM;YA9Jd,IAAAA;YA+JU,OAAA,IAAI,qBAAqB;gBACvB,MAAM;gBACN,WAAA,CACEA,OAAA,gBAAgB;oBACd,MAAM;oBACN,YAAY;gBACd,CAAC,CAAA,KAHD,OAAAA,OAGM;YACV,CAAC;QAAA;QAGP,SAAS,IAAA,CAAK,GAAG,OAAO,QAAQ;QAEhC,IAAI,OAAO,gBAAA,EAAkB;YAC3B,KAAA,MAAW,CAAC,cAAc,QAAQ,CAAA,IAAK,OAAO,OAAA,CAE3C,OAAO,gBAAgB,EAAG;gBAC3B,CAAA,KAAA,gBAAA,CAAA,aAAA,KAAA,OAAA,KAAA,gBAAA,CAAA,aAAA,GAAmC;oBAAE,QAAQ,CAAC,CAAA;gBAAE;gBAChD,gBAAA,CAAiB,YAAY,CAAA,CAAE,MAAA,CAAO,IAAA,IACjC,OAAO,gBAAA,CAAiB,YAAY,CAAA,CAAE,MAAA;YAE7C;QACF;QAEA,UAAU,IAAA,CAAK,OAAO,QAAQ;IAChC;IAEA,IAAI,CAAC,OAAO,MAAA,EAAQ;QAClB,MAAM,IAAI,sBAAsB;YAAE;QAAU,CAAC;IAC/C;IAEA,OAAO,IAAI,2BAA2B;QACpC;QACA;QACA;QACA;IACF,CAAC;AACH;AAEA,IAAM,6BAAN,MAAgE;IAM9D,YAAY,OAAA,CAKT;QACD,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;QACzB,IAAA,CAAK,gBAAA,GAAmB,QAAQ,gBAAA;IAClC;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,MAAA,CAAO,CAAC,CAAA;IACtB;AACF;AAEA,eAAe,4BAA4B,KAAA,EAAqB;IAC9D,MAAM,aAAa,MAAM,gBAAA,YAA4B;IAErD,IAAI,CAAC,YAAY;QACf,OAAO,MAAM,gBAAA;IACf;IAEA,OAAO,MAAM,gBAAA,CAAiB;QAC5B,SAAS,MAAM,OAAA;IACjB,CAAC;AACH;;;;AEpOO,SAAS,mBACd,OAAA,EACoB;IACpB,MAAM,QAAQ,QAAQ,MAAA,CACpB,CAACI,WAA4CA,SAAQ,IAAA,KAAS;IAGhE,IAAI,MAAM,MAAA,KAAW,GAAG;QACtB,OAAO,KAAA;IACT;IAEA,OAAO,MAAM,GAAA,CAAI,CAAAA,WAAWA,SAAQ,IAAI,EAAE,IAAA,CAAK,EAAE;AACnD;;;AEZA,eAAsB,SAAS,EAAE,GAAA,CAAI,CAAA,EAGlC;IALH,IAAAC;IAME,MAAM,UAAU,IAAI,QAAA,CAAS;IAC7B,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,OAAO;QAEpC,IAAI,CAAC,SAAS,EAAA,EAAI;YAChB,MAAM,IAAI,cAAc;gBACtB,KAAK;gBACL,YAAY,SAAS,MAAA;gBACrB,YAAY,SAAS,UAAA;YACvB,CAAC;QACH;QAEA,OAAO;YACL,MAAM,IAAI,WAAW,MAAM,SAAS,WAAA,CAAY,CAAC;YACjD,WAAA,CAAWA,OAAA,SAAS,OAAA,CAAQ,GAAA,CAAI,cAAc,CAAA,KAAnC,OAAAA,OAAwC,KAAA;QACrD;IACF,EAAA,OAAS,OAAO;QACd,IAAI,cAAc,UAAA,CAAW,KAAK,GAAG;YACnC,MAAM;QACR;QAEA,MAAM,IAAI,cAAc;YAAE,KAAK;YAAS,OAAO;QAAM,CAAC;IACxD;AACF;;;;;AE7BO,SAAS,aAAa,OAAA,EAG3B;IACA,IAAI;QACF,MAAM,CAAC,QAAQ,aAAa,CAAA,GAAI,QAAQ,KAAA,CAAM,GAAG;QACjD,OAAO;YACL,WAAW,OAAO,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA,CAAE,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA;YAC5C;QACF;IACF,EAAA,OAAS,OAAO;QACd,OAAO;YACL,WAAW,KAAA;YACX,eAAe,KAAA;QACjB;IACF;AACF;;ADCO,IAAM,sMAA4CK,IAAAA,CAAE,KAAA,CAAM;sLAC/DA,IAAAA,CAAE,MAAA,CAAO;sLACTA,IAAAA,CAAE,UAAA,CAAW,UAAU;sLACvBA,IAAAA,CAAE,UAAA,CAAW,WAAW;sLACxBA,IAAAA,CAAE,MAAA,CAAA,yEAAA;IAEA,CAAC,UAAiC;QAvBtC,IAAAC,MAAA;QAwBM,OAAA,CAAA,KAAA,CAAAA,OAAA,WAAW,MAAA,KAAX,OAAA,KAAA,IAAAA,KAAmB,QAAA,CAAS,MAAA,KAA5B,OAAA,KAAsC;IAAA,GACxC;QAAE,SAAS;IAAmB;CAEjC;AAEM,SAAS,oCACd,OAAA,EAIA;IAEA,IAAI,mBAAmB,YAAY;QACjC,OAAO;YAAE,MAAM;YAAS,WAAW,KAAA;QAAU;IAC/C;IAGA,IAAI,mBAAmB,aAAa;QAClC,OAAO;YAAE,MAAM,IAAI,WAAW,OAAO;YAAG,WAAW,KAAA;QAAU;IAC/D;IAIA,IAAI,OAAO,YAAY,UAAU;QAC/B,IAAI;YACF,UAAU,IAAI,IAAI,OAAO;QAC3B,EAAA,OAAS,OAAO,CAEhB;IACF;IAGA,IAAI,mBAAmB,OAAO,QAAQ,QAAA,KAAa,SAAS;QAC1D,MAAM,EAAE,WAAW,gBAAA,EAAkB,aAAA,CAAc,CAAA,GAAI,aACrD,QAAQ,QAAA,CAAS;QAGnB,IAAI,oBAAoB,QAAQ,iBAAiB,MAAM;YACrD,MAAM,8JAAIC,aAAAA,CAAW;gBACnB,MAAM;gBACN,SAAS,CAAA,mCAAA,EAAsC,QAAQ,QAAA,CAAS,CAAC,EAAA;YACnE,CAAC;QACH;QAEA,OAAO;YAAE,MAAM;YAAe,WAAW;QAAiB;IAC5D;IAEA,OAAO;QAAE,MAAM;QAAS,WAAW,KAAA;IAAU;AAC/C;AAQO,SAAS,iCAAiC,OAAA,EAA8B;IAC7E,IAAI,OAAO,YAAY,UAAU;QAC/B,OAAO;IACT;IAEA,IAAI,mBAAmB,aAAa;QAClC,8LAAOC,4BAAAA,EAA0B,IAAI,WAAW,OAAO,CAAC;IAC1D;IAEA,OAAOA,mNAAAA,EAA0B,OAAO;AAC1C;AAQO,SAAS,+BACd,OAAA,EACY;IACZ,IAAI,mBAAmB,YAAY;QACjC,OAAO;IACT;IAEA,IAAI,OAAO,YAAY,UAAU;QAC/B,IAAI;YACF,8LAAOC,4BAAAA,EAA0B,OAAO;QAC1C,EAAA,OAAS,OAAO;YACd,MAAM,IAAI,wBAAwB;gBAChC,SACE;gBACF;gBACA,OAAO;YACT,CAAC;QACH;IACF;IAEA,IAAI,mBAAmB,aAAa;QAClC,OAAO,IAAI,WAAW,OAAO;IAC/B;IAEA,MAAM,IAAI,wBAAwB;QAAE;IAAQ,CAAC;AAC/C;;AFtGA,eAAsB,6BAA6B,EACjD,MAAA,EACA,aAAA,EACA,yBAAyB,QAAA,EAC3B,EAImC;IACjC,MAAM,mBAAmB,MAAM,eAC7B,OAAO,QAAA,EACP,wBACA;IAGF,OAAO;WACD,OAAO,MAAA,IAAU,OACjB;YAAC;gBAAE,MAAM;gBAAmB,SAAS,OAAO,MAAA;YAAO,CAAC;SAAA,GACpD,CAAC,CAAA;WACF,OAAO,QAAA,CAAS,GAAA,CAAI,CAAA,UACrB,8BAA8B,SAAS,gBAAgB;KAE3D;AACF;AASO,SAAS,8BACd,OAAA,EACA,gBAAA,EAIwB;IACxB,MAAM,OAAO,QAAQ,IAAA;IACrB,OAAQ,MAAM;QACZ,KAAK;YAAU;gBACb,OAAO;oBACL,MAAM;oBACN,SAAS,QAAQ,OAAA;oBACjB,iBAAiB,QAAQ,eAAA;gBAC3B;YACF;QAEA,KAAK;YAAQ;gBACX,IAAI,OAAO,QAAQ,OAAA,KAAY,UAAU;oBACvC,OAAO;wBACL,MAAM;wBACN,SAAS;4BAAC;gCAAE,MAAM;gCAAQ,MAAM,QAAQ,OAAA;4BAAQ,CAAC;yBAAA;wBACjD,iBAAiB,QAAQ,eAAA;oBAC3B;gBACF;gBAEA,OAAO;oBACL,MAAM;oBACN,SAAS,QAAQ,OAAA,CACd,GAAA,CAAI,CAAA,OAAQ,+BAA+B,MAAM,gBAAgB,CAAC,EAElE,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,UAAU,KAAK,IAAA,KAAS,EAAE;oBAC1D,iBAAiB,QAAQ,eAAA;gBAC3B;YACF;QAEA,KAAK;YAAa;gBAChB,IAAI,OAAO,QAAQ,OAAA,KAAY,UAAU;oBACvC,OAAO;wBACL,MAAM;wBACN,SAAS;4BAAC;gCAAE,MAAM;gCAAQ,MAAM,QAAQ,OAAA;4BAAQ,CAAC;yBAAA;wBACjD,iBAAiB,QAAQ,eAAA;oBAC3B;gBACF;gBAEA,OAAO;oBACL,MAAM;oBACN,SAAS,QAAQ,OAAA,CACd,MAAA,CAAA,2BAAA;oBAEC,CAAA,OAAQ,KAAK,IAAA,KAAS,UAAU,KAAK,IAAA,KAAS,IAE/C,GAAA,CAAI,CAAA,SAAQ;wBACX,MAAM,kBAAkB,KAAK,eAAA;wBAE7B,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,MAAM,EAAE,IAAA,EAAM,SAAA,CAAU,CAAA,GAAI,oCAC1B,KAAK,IAAA;oCAEP,OAAO;wCACL,MAAM;wCACN;wCACA,UAAU,KAAK,QAAA;wCACf,WAAW,aAAA,OAAA,YAAa,KAAK,SAAA;wCAC7B;oCACF;gCACF;4BACA,KAAK;gCAAa;oCAChB,OAAO;wCACL,MAAM;wCACN,MAAM,KAAK,IAAA;wCACX;oCACF;gCACF;4BACA,KAAK;gCAAQ;oCACX,OAAO;wCACL,MAAM;wCACN,MAAM,KAAK,IAAA;wCACX;oCACF;gCACF;4BACA,KAAK;gCAAa;oCAChB,OAAO;wCACL,MAAM;wCACN,YAAY,KAAK,UAAA;wCACjB,UAAU,KAAK,QAAA;wCACf,MAAM,KAAK,IAAA;wCACX;oCACF;gCACF;wBACF;oBACF,CAAC;oBACH,iBAAiB,QAAQ,eAAA;gBAC3B;YACF;QAEA,KAAK;YAAQ;gBACX,OAAO;oBACL,MAAM;oBACN,SAAS,QAAQ,OAAA,CAAQ,GAAA,CAAI,CAAA,OAAA,CAAS;4BACpC,MAAM;4BACN,YAAY,KAAK,UAAA;4BACjB,UAAU,KAAK,QAAA;4BACf,QAAQ,KAAK,MAAA;4BACb,SAAS,KAAK,oBAAA;4BACd,SAAS,KAAK,OAAA;4BACd,iBAAiB,KAAK,eAAA;wBACxB,CAAA,CAAE;oBACF,iBAAiB,QAAQ,eAAA;gBAC3B;YACF;QAEA;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,IAAI,wBAAwB;oBAAE,MAAM;gBAAiB,CAAC;YAC9D;IACF;AACF;AAKA,eAAe,eACb,QAAA,EACA,sBAAA,EACA,aAAA,EAGA;IACA,MAAM,OAAO,SACV,MAAA,CAAO,CAAA,UAAW,QAAQ,IAAA,KAAS,MAAM,EACzC,GAAA,CAAI,CAAA,UAAW,QAAQ,OAAO,EAC9B,MAAA,CAAO,CAAC,UACP,MAAM,OAAA,CAAQ,OAAO,GAEtB,IAAA,CAAK,EACL,MAAA,CACC,CAAC,OACC,KAAK,IAAA,KAAS,WAAW,KAAK,IAAA,KAAS,QAE1C,GAAA,CAAI,CAAA,SAAQ;QAlMjB,IAAAC;QAmMM,MAAM,YAAA,CACJA,OAAA,KAAK,SAAA,KAAL,OAAAA,OAAmB,KAAK,IAAA,KAAS,UAAU,YAAY,KAAA;QAEzD,IAAI,OAAO,KAAK,IAAA,KAAS,UAAU,KAAK,KAAA,GAAQ,KAAK,IAAA;QACrD,IAAI,OAAO,SAAS,UAAU;YAC5B,IAAI;gBACF,OAAO,IAAI,IAAI,IAAI;YACrB,EAAA,OAAS,SAAS,CAAC;QACrB;QAEA,OAAO;YAAE;YAAW;QAAK;IAC3B,CAAC,EAIA,MAAA,CACC,CAAC,OACC,KAAK,IAAA,YAAgB,OACrB,KAAK,SAAA,IAAa,QAClB,wLAAC,iBAAA,EAAe;YACd,KAAK,KAAK,IAAA,CAAK,QAAA,CAAS;YACxB,WAAW,KAAK,SAAA;YAChB;QACF,CAAC,GAEJ,GAAA,CAAI,CAAA,OAAQ,KAAK,IAAI;IAGxB,MAAM,mBAAmB,MAAM,QAAQ,GAAA,CACrC,KAAK,GAAA,CAAI,OAAM,MAAA,CAAQ;YACrB;YACA,MAAM,MAAM,uBAAuB;gBAAE;YAAI,CAAC;QAC5C,CAAA,CAAE;IAGJ,OAAO,OAAO,WAAA,CACZ,iBAAiB,GAAA,CAAI,CAAC,EAAE,GAAA,EAAK,IAAA,CAAK,CAAA,GAAM;YAAC,IAAI,QAAA,CAAS;YAAG,IAAI;SAAC;AAElE;AAUA,SAAS,+BACP,IAAA,EACA,gBAAA,EAImD;IAzPrD,IAAAA,MAAA;IA0PE,IAAI,KAAK,IAAA,KAAS,QAAQ;QACxB,OAAO;YACL,MAAM;YACN,MAAM,KAAK,IAAA;YACX,iBAAiB,KAAK,eAAA;QACxB;IACF;IAEA,IAAI;IACJ,MAAM,OAAO,KAAK,IAAA;IAClB,OAAQ,MAAM;QACZ,KAAK;YACH,eAAe,KAAK,KAAA;YACpB;QACF,KAAK;YACH,eAAe,KAAK,IAAA;YAEpB;QACF;YACE,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0B,IAAI,EAAE;IACpD;IAEA,MAAM,EAAE,MAAM,aAAA,EAAe,WAAW,kBAAA,CAAmB,CAAA,GACzD,oCAAoC,YAAY;IAElD,IAAI,YAAgC,sBAAA,OAAA,qBAAsB,KAAK,SAAA;IAC/D,IAAI,OAAkC;IAGtC,IAAI,gBAAgB,KAAK;QACvB,MAAM,iBAAiB,gBAAA,CAAiB,KAAK,QAAA,CAAS,CAAC,CAAA;QACvD,IAAI,gBAAgB;YAClB,OAAO,eAAe,IAAA;YACtB,YAAA,CAAYA,OAAA,eAAe,SAAA,KAAf,OAAAA,OAA4B;QAC1C;IACF;IAIA,OAAQ,MAAM;QACZ,KAAK;YAAS;gBAIZ,IAAI,gBAAgB,cAAc,OAAO,SAAS,UAAU;oBAC1D,YAAA,CACE,KAAA,gBAAgB;wBAAE;wBAAM,YAAY;oBAAyB,CAAC,CAAA,KAA9D,OAAA,KACA;gBACJ;gBAEA,OAAO;oBACL,MAAM;oBACN,WAAW,aAAA,OAAA,YAAa;oBAAA,YAAA;oBACxB,UAAU,KAAA;oBACV;oBACA,iBAAiB,KAAK,eAAA;gBACxB;YACF;QAEA,KAAK;YAAQ;gBAEX,IAAI,aAAa,MAAM;oBACrB,MAAM,IAAI,MAAM,CAAA,mCAAA,CAAqC;gBACvD;gBAEA,OAAO;oBACL,MAAM;oBACN;oBACA,UAAU,KAAK,QAAA;oBACf;oBACA,iBAAiB,KAAK,eAAA;gBACxB;YACF;IACF;AACF;;AI9TO,SAAS,oBAAoB,EAClC,eAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,eAAA,EACA,gBAAA,EACA,IAAA,EACA,aAAA,EACF,EAGE;IACA,IAAI,mBAAmB,MAAM;QAC3B,IAAI,CAAC,OAAO,SAAA,CAAU,eAAe,GAAG;YACtC,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,kBAAkB,GAAG;YACvB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,eAAe,MAAM;QACvB,IAAI,OAAO,gBAAgB,UAAU;YACnC,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,QAAQ,MAAM;QAChB,IAAI,OAAO,SAAS,UAAU;YAC5B,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,QAAQ,MAAM;QAChB,IAAI,OAAO,SAAS,UAAU;YAC5B,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,mBAAmB,MAAM;QAC3B,IAAI,OAAO,oBAAoB,UAAU;YACvC,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,oBAAoB,MAAM;QAC5B,IAAI,OAAO,qBAAqB,UAAU;YACxC,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,QAAQ,MAAM;QAChB,IAAI,CAAC,OAAO,SAAA,CAAU,IAAI,GAAG;YAC3B,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,OAAO;QACL;QACA;QACA;QACA;QACA;QACA;QACA;QACA;IACF;AACF;;ACvGO,IAAM,0BAA0B,OACrC;AAGK,SAAS,qBAAqB,KAAA,EAAuC;IAC1E,IAAI,OAAO,UAAU,UAAU;QAC7B,OAAO;IACT;IAEA,MAAM,iBAAkB,UAAA,CAAmB,uBAAuB,CAAA;IAIlE,OAAA,CAAQ,kBAAA,OAAA,0KAAkB,UAAA,EAAS,aAAA,CAAc,KAAK;AACxD;;;;;;;AIfO,IAAM,oMAAwCK,IAAAA,CAAE,IAAA,CAAK,IAC1DA,sLAAAA,CAAE,KAAA,CAAM;0LACNA,IAAAA,CAAE,IAAA,CAAK;0LACPA,IAAAA,CAAE,MAAA,CAAO;0LACTA,IAAAA,CAAE,MAAA,CAAO;0LACTA,IAAAA,CAAE,OAAA,CAAQ;0LACVA,IAAAA,CAAE,MAAA,mLAAOA,IAAAA,CAAE,MAAA,CAAO,GAAG,eAAe;0LACpCA,IAAAA,CAAE,KAAA,CAAM,eAAe;KACxB;;ADYI,IAAM,yBAAsDC,sLAAAA,CAAE,MAAA,mLACnEA,IAAAA,CAAE,MAAA,CAAO,qLACTA,IAAAA,CAAE,MAAA,mLAAOA,IAAAA,CAAE,MAAA,CAAO,GAAG,eAAe;;;AGpB/B,IAAM,2MAAwDE,KAAAA,CAAE,KAAA,mLACrEA,IAAAA,CAAE,KAAA,CAAM;sLACNA,IAAAA,CAAE,MAAA,CAAO;QAAE,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,MAAM;QAAG,wLAAMA,IAAAA,CAAE,MAAA,CAAO;IAAE,CAAC;sLACtDA,IAAAA,CAAE,MAAA,CAAO;QACP,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,OAAO;QACvB,wLAAMA,IAAAA,CAAE,MAAA,CAAO;QACf,6LAAWA,IAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IACjC,CAAC;CACF;;ADoBI,IAAM,mMAAsCC,IAAAA,CAAE,MAAA,CAAO;IAC1D,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,MAAM;IACtB,wLAAMA,IAAAA,CAAE,MAAA,CAAO;IACf,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAkCM,IAAM,oMAAwCA,IAAAA,CAAE,MAAA,CAAO;IAC5D,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,OAAO;IACvB,yLAAOA,IAAAA,CAAE,KAAA,CAAM;QAAC;0LAAmBA,IAAAA,CAAE,UAAA,CAAW,GAAG,CAAC;KAAC;IACrD,6LAAWA,IAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAC/B,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAuCM,IAAM,iBAAsCA,sLAAAA,CAAE,MAAA,CAAO;IAC1D,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,MAAM;IACtB,wLAAMA,IAAAA,CAAE,KAAA,CAAM;QAAC;0LAAmBA,IAAAA,CAAE,UAAA,CAAW,GAAG,CAAC;KAAC;IACpD,4LAAUA,IAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAC9B,6LAAWA,IAAAA,CAAE,MAAA,CAAO;IACpB,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAwBM,IAAM,wMAAgDA,IAAAA,CAAE,MAAA,CAAO;IACpE,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,WAAW;IAC3B,wLAAMA,IAAAA,CAAE,MAAA,CAAO;IACf,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAkCM,IAAM,uMAA8CA,IAAAA,CAAE,MAAA,CAAO;IAClE,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,WAAW;IAC3B,8LAAYA,IAAAA,CAAE,MAAA,CAAO;IACrB,4LAAUA,IAAAA,CAAE,MAAA,CAAO;IACnB,wLAAMA,IAAAA,CAAE,OAAA,CAAQ;IAChB,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AA4CM,IAAM,yMAAkDA,IAAAA,CAAE,MAAA,CAAO;IACtE,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,aAAa;IAC7B,8LAAYA,IAAAA,CAAE,MAAA,CAAO;IACrB,2LAAUA,KAAAA,CAAE,MAAA,CAAO;IACnB,0LAAQA,IAAAA,CAAE,OAAA,CAAQ;IAClB,SAAS,wBAAwB,QAAA,CAAS;IAC1C,2LAASA,IAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAC9B,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;;AHpMM,IAAM,6MAA0DC,IAAAA,CAAE,MAAA,CACvE;IACE,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,QAAQ;IACxB,2LAASA,IAAAA,CAAE,MAAA,CAAO;IAClB,iBAAiB,uBAAuB,QAAA,CAAS;AACnD;AAOK,IAAM,0BAA0B;AAuBhC,IAAM,2MAAsDA,IAAAA,CAAE,MAAA,CAAO;IAC1E,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,MAAM;IACtB,SAASA,sLAAAA,CAAE,KAAA,CAAM;0LACfA,IAAAA,CAAE,MAAA,CAAO;0LACTA,IAAAA,CAAE,KAAA,mLAAMA,IAAAA,CAAE,KAAA,CAAM;YAAC;YAAgB;YAAiB,cAAc;SAAC,CAAC;KACnE;IACD,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAMM,IAAM,wBAAwB;AA4B9B,IAAM,gNACXA,IAAAA,CAAE,MAAA,CAAO;IACP,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,WAAW;IAC3B,2LAASA,IAAAA,CAAE,KAAA,CAAM;0LACfA,IAAAA,CAAE,MAAA,CAAO;0LACTA,IAAAA,CAAE,KAAA,mLACAA,IAAAA,CAAE,KAAA,CAAM;YACN;YACA;YACA;YACA;SACD;KAEJ;IACD,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAMI,IAAM,6BAA6B;AA+BnC,IAAM,2MAAsDA,IAAAA,CAAE,MAAA,CAAO;IAC1E,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,MAAM;IACtB,2LAASA,IAAAA,CAAE,KAAA,CAAM,oBAAoB;IACrC,iBAAiB,uBAAuB,QAAA,CAAS;AACnD,CAAC;AAMM,IAAM,wBAAwB;AAuB9B,IAAM,qBAA8CA,sLAAAA,CAAE,KAAA,CAAM;IACjE;IACA;IACA;IACA;CACD;AAMM,IAAM,oBAA4C;;ADvMzD,eAAsB,kBACpB,MAAA,EAC6B;IAC7B,IAAI,OAAO,MAAA,IAAU,QAAQ,OAAO,QAAA,IAAY,MAAM;QACpD,MAAM,6JAAIC,sBAAAA,CAAmB;YAC3B;YACA,SAAS;QACX,CAAC;IACH;IAEA,IAAI,OAAO,MAAA,IAAU,QAAQ,OAAO,QAAA,IAAY,MAAM;QACpD,MAAM,6JAAIA,sBAAAA,CAAmB;YAC3B;YACA,SAAS;QACX,CAAC;IACH;IAGA,IAAI,OAAO,MAAA,IAAU,QAAQ,OAAO,OAAO,MAAA,KAAW,UAAU;QAC9D,MAAM,8JAAIA,qBAAAA,CAAmB;YAC3B;YACA,SAAS;QACX,CAAC;IACH;IAEA,IAAI;IAEJ,IAAI,OAAO,MAAA,IAAU,QAAQ,OAAO,OAAO,MAAA,KAAW,UAAU;QAC9D,WAAW;YAAC;gBAAE,MAAM;gBAAQ,SAAS,OAAO,MAAA;YAAO,CAAC;SAAA;IACtD,OAAA,IAAW,OAAO,MAAA,IAAU,QAAQ,MAAM,OAAA,CAAQ,OAAO,MAAM,GAAG;QAChE,WAAW,OAAO,MAAA;IACpB,OAAA,IAAW,OAAO,QAAA,IAAY,MAAM;QAClC,WAAW,OAAO,QAAA;IACpB,OAAO;QACL,MAAM,8JAAIA,qBAAAA,CAAmB;YAC3B;YACA,SAAS;QACX,CAAC;IACH;IAEA,IAAI,SAAS,MAAA,KAAW,GAAG;QACzB,MAAM,8JAAIA,qBAAAA,CAAmB;YAC3B;YACA,SAAS;QACX,CAAC;IACH;IAEA,MAAM,mBAAmB,6LAAM,oBAAA,EAAkB;QAC/C,OAAO;QACP,0LAAQC,IAAAA,CAAE,KAAA,CAAM,kBAAkB;IACpC,CAAC;IAED,IAAI,CAAC,iBAAiB,OAAA,EAAS;QAC7B,MAAM,IAAID,+KAAAA,CAAmB;YAC3B;YACA,SACE;YAEF,OAAO,iBAAiB,KAAA;QAC1B,CAAC;IACH;IAEA,OAAO;QACL;QACA,QAAQ,OAAO,MAAA;IACjB;AACF;;;AM9EO,SAAS,iBAAiB,KAAA,EAAyB;IACxD,6JACE,6BAAA,CAA2B,UAAA,CAAW,KAAK,8JAC3C,4BAAA,CAA0B,UAAA,CAAW,KAAK,GAC1C;QACA,OAAO,8JAAIE,aAAAA,CAAW;YACpB,MAAM;YACN,SACE;YAGF,OAAO;QACT,CAAC;IACH;IAEA,OAAO;AACT;;ACVO,SAAS,sBAAsB,MAAA,EAAuC;IAC3E,OAAO,KAAK,SAAA,CACV,OAAO,GAAA,CAAI,CAAC,UAAA,CAAqC;YAC/C,GAAG,OAAA;YACH,SACE,OAAO,QAAQ,OAAA,KAAY,WACvB,QAAQ,OAAA,GACR,QAAQ,OAAA,CAAQ,GAAA,CAAI,CAAA,OAClB,KAAK,IAAA,KAAS,SACV;oBACE,GAAG,IAAA;oBACH,MACE,KAAK,IAAA,YAAgB,aACjB,iCAAiC,KAAK,IAAI,IAC1C,KAAK,IAAA;gBACb,IACA;QAEd,CAAA,CAAE;AAEN;;;;AE9BO,SAAS,0BACd,MAAA,EACwB;IACxB,MAAM,SAAS,OAAO,WAAA,CAAY,IAAI,gBAAsB,CAAC;IAE5D,MAAA,CAAkC,OAAO,aAAa,CAAA,GAAI,MAAM;QAC/D,MAAM,SAAS,OAAO,SAAA,CAAU;QAChC,OAAO;YACL,MAAM,OAAmC;gBACvC,MAAM,EAAE,IAAA,EAAM,KAAA,CAAM,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;gBAC1C,OAAO,OAAO;oBAAE,MAAM;oBAAM,OAAO,KAAA;gBAAU,IAAI;oBAAE,MAAM;oBAAO;gBAAM;YACxE;QACF;IACF;IAEA,OAAO;AACT;;AD8CA,IAAM,yBAAsE;IAC1E,MAAM;IACN,YAAY,KAAA;IAEZ,MAAM,uBAAsB,EAAE,KAAA,EAAO,SAAA,CAAU,CAAA,EAAG;QAChD,OAAO;YAAE,SAAS;YAAM,OAAO;gBAAE,SAAS;gBAAO;YAAU;QAAE;IAC/D;IAEA,MAAM,qBACJ,KAAA,EACA,OAAA,EAMsC;QACtC,OAAO,UAAU,KAAA,IACb;YACE,SAAS;YACT,OAAO,IAAI,uBAAuB;gBAChC,SAAS;gBACT,MAAM,QAAQ,IAAA;gBACd,UAAU,QAAQ,QAAA;gBAClB,OAAO,QAAQ,KAAA;gBACf,cAAc,QAAQ,YAAA;YACxB,CAAC;QACH,IACA;YAAE,SAAS;YAAM;QAAM;IAC7B;IAEA,sBAAsB;QACpB,MAAM,8JAAII,gCAAAA,CAA8B;YACtC,eAAe;QACjB,CAAC;IACH;AACF;AAEA,IAAM,uBAAuB,CAC3B,SAAA,CACwD;QACxD,MAAM;QACN,YAAY,OAAO,UAAA;QAEnB,MAAM,uBAAsB,EAAE,KAAA,EAAO,SAAA,CAAU,CAAA,EAAG;YAChD,OAAO;gBACL,SAAS;gBACT,OAAO;oBAAA,oDAAA;oBAEL,SAAS;oBACT;gBACF;YACF;QACF;QAEA,MAAM,qBACJ,KAAA,EACmC;YACnC,8LAAOC,oBAAAA,EAAkB;gBAAE;gBAAO;YAAO,CAAC;QAC5C;QAEA,sBAAsB;YACpB,MAAM,8JAAID,gCAAAA,CAA8B;gBACtC,eAAe;YACjB,CAAC;QACH;IACF,CAAA;AAEA,IAAM,sBAAsB,CAC1B,WACuE;IAEvE,MAAM,EAAE,OAAA,EAAS,GAAG,WAAW,CAAA,GAAI,OAAO,UAAA;IAE1C,OAAO;QACL,MAAM;QAAA,2EAAA;QAAA,yCAAA;QAAA,kGAAA;QAKN,YAAY;YACV,SAAS;YACT,MAAM;YACN,YAAY;gBACV,UAAU;oBAAE,MAAM;oBAAS,OAAO;gBAAW;YAC/C;YACA,UAAU;gBAAC,UAAU;aAAA;YACrB,sBAAsB;QACxB;QAEA,MAAM,uBAAsB,EAC1B,KAAA,EACA,YAAA,EACA,YAAA,EACA,YAAA,EACF,EAAG;YA/JP,IAAAE;YAiKM,IAAI,CAAC,6KAAA,EAAa,KAAK,KAAK,+JAAC,cAAA,EAAY,MAAM,QAAQ,GAAG;gBACxD,OAAO;oBACL,SAAS;oBACT,OAAO,8JAAIC,sBAAAA,CAAoB;wBAC7B;wBACA,OAAO;oBACT,CAAC;gBACH;YACF;YAEA,MAAM,aAAa,MAAM,QAAA;YACzB,MAAM,cAA8B,CAAC,CAAA;YAErC,IAAA,IAAS,IAAI,GAAG,IAAI,WAAW,MAAA,EAAQ,IAAK;gBAC1C,MAAM,UAAU,UAAA,CAAW,CAAC,CAAA;gBAC5B,MAAM,SAAS,6LAAMF,oBAAAA,EAAkB;oBAAE,OAAO;oBAAS;gBAAO,CAAC;gBAMjE,IAAI,MAAM,WAAW,MAAA,GAAS,KAAK,CAAC,cAAc;oBAChD;gBACF;gBAEA,IAAI,CAAC,OAAO,OAAA,EAAS;oBACnB,OAAO;gBACT;gBAEA,YAAY,IAAA,CAAK,OAAO,KAAK;YAC/B;YAGA,MAAM,wBAAA,CAAwBC,OAAA,gBAAA,OAAA,KAAA,IAAA,aAAc,MAAA,KAAd,OAAAA,OAAwB;YAEtD,IAAI,YAAY;YAEhB,IAAI,cAAc;gBAChB,aAAa;YACf;YAEA,IAAI,wBAAwB,GAAG;gBAC7B,aAAa;YACf;YAEA,aAAa,YACV,KAAA,CAAM,qBAAqB,EAC3B,GAAA,CAAI,CAAA,UAAW,KAAK,SAAA,CAAU,OAAO,CAAC,EACtC,IAAA,CAAK,GAAG;YAEX,IAAI,cAAc;gBAChB,aAAa;YACf;YAEA,OAAO;gBACL,SAAS;gBACT,OAAO;oBACL,SAAS;oBACT;gBACF;YACF;QACF;QAEA,MAAM,qBACJ,KAAA,EAC2C;YAE3C,IAAI,CAAC,6KAAA,EAAa,KAAK,KAAK,+JAAC,cAAA,EAAY,MAAM,QAAQ,GAAG;gBACxD,OAAO;oBACL,SAAS;oBACT,OAAO,8JAAIC,sBAAAA,CAAoB;wBAC7B;wBACA,OAAO;oBACT,CAAC;gBACH;YACF;YAEA,MAAM,aAAa,MAAM,QAAA;YAGzB,KAAA,MAAW,WAAW,WAAY;gBAChC,MAAM,SAAS,6LAAMF,oBAAAA,EAAkB;oBAAE,OAAO;oBAAS;gBAAO,CAAC;gBACjE,IAAI,CAAC,OAAO,OAAA,EAAS;oBACnB,OAAO;gBACT;YACF;YAEA,OAAO;gBAAE,SAAS;gBAAM,OAAO;YAA6B;QAC9D;QAEA,qBACE,cAAA,EACA;YACA,IAAI,oBAAoB;YAExB,OAAO,0BACL,eAAe,WAAA,CACb,IAAI,gBAAsD;gBACxD,WAAU,KAAA,EAAO,UAAA,EAAY;oBAC3B,OAAQ,MAAM,IAAA,EAAM;wBAClB,KAAK;4BAAU;gCACb,MAAM,QAAQ,MAAM,MAAA;gCAGpB,MAEE,oBAAoB,MAAM,MAAA,EAC1B,oBACA;oCACA,WAAW,OAAA,CAAQ,KAAA,CAAM,iBAAiB,CAAC;gCAC7C;gCAEA;4BACF;wBAEA,KAAK;wBACL,KAAK;wBACL,KAAK;4BACH;wBAEF;4BAAS;gCACP,MAAM,mBAA0B;gCAChC,MAAM,IAAI,MACR,CAAA,wBAAA,EAA2B,gBAAgB,EAAA;4BAE/C;oBACF;gBACF;YACF,CAAC;QAGP;IACF;AACF;AAEA,IAAM,qBAAqB,CACzB,eACwC;IACxC,OAAO;QACL,MAAM;QAAA,gEAAA;QAAA,8CAAA;QAAA,uFAAA;QAKN,YAAY;YACV,SAAS;YACT,MAAM;YACN,YAAY;gBACV,QAAQ;oBAAE,MAAM;oBAAU,MAAM;gBAAW;YAC7C;YACA,UAAU;gBAAC,QAAQ;aAAA;YACnB,sBAAsB;QACxB;QAEA,MAAM,qBACJ,KAAA,EACiC;YAEjC,IAAI,+JAAC,eAAA,EAAa,KAAK,KAAK,OAAO,MAAM,MAAA,KAAW,UAAU;gBAC5D,OAAO;oBACL,SAAS;oBACT,OAAO,8JAAIE,sBAAAA,CAAoB;wBAC7B;wBACA,OACE;oBACJ,CAAC;gBACH;YACF;YAEA,MAAM,SAAS,MAAM,MAAA;YAErB,OAAO,WAAW,QAAA,CAAS,MAAc,IACrC;gBAAE,SAAS;gBAAM,OAAO;YAAe,IACvC;gBACE,SAAS;gBACT,OAAO,8JAAIA,sBAAAA,CAAoB;oBAC7B;oBACA,OAAO;gBACT,CAAC;YACH;QACN;QAEA,MAAM,uBAAsB,EAAE,KAAA,EAAO,SAAA,CAAU,CAAA,EAAG;YAChD,IAAI,+JAAC,eAAA,EAAa,KAAK,KAAK,OAAO,MAAM,MAAA,KAAW,UAAU;gBAC5D,OAAO;oBACL,SAAS;oBACT,OAAO,IAAIA,gLAAAA,CAAoB;wBAC7B;wBACA,OACE;oBACJ,CAAC;gBACH;YACF;YAEA,MAAM,SAAS,MAAM,MAAA;YACrB,MAAM,qBAAqB,WAAW,MAAA,CAAO,CAAA,YAC3C,UAAU,UAAA,CAAW,MAAM;YAG7B,IAAI,MAAM,MAAA,CAAO,MAAA,KAAW,KAAK,mBAAmB,MAAA,KAAW,GAAG;gBAChE,OAAO;oBACL,SAAS;oBACT,OAAO,8JAAIA,sBAAAA,CAAoB;wBAC7B;wBACA,OAAO;oBACT,CAAC;gBACH;YACF;YAEA,OAAO;gBACL,SAAS;gBACT,OAAO;oBACL,SACE,mBAAmB,MAAA,GAAS,IAAI,SAAS,kBAAA,CAAmB,CAAC,CAAA;oBAC/D;gBACF;YACF;QACF;QAEA,sBAAsB;YAEpB,MAAM,8JAAIH,gCAAAA,CAA8B;gBACtC,eAAe;YACjB,CAAC;QACH;IACF;AACF;AAEO,SAAS,kBAA0B,EACxC,MAAA,EACA,MAAA,EACA,UAAA,EACF,EAOkC;IAChC,OAAQ,QAAQ;QACd,KAAK;YACH,OAAO,4MAAqB,WAAA,EAAS,MAAO,CAAC;QAC/C,KAAK;YACH,OAAO,2MAAoB,WAAA,EAAS,MAAO,CAAC;QAC9C,KAAK;YACH,OAAO,mBAAmB,UAA4B;QACxD,KAAK;YACH,OAAO;QACT;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,IAAI,MAAM,CAAA,oBAAA,EAAuB,gBAAgB,EAAE;YAC3D;IACF;AACF;;AE1ZO,SAAS,8BAA8B,EAC5C,MAAA,EACA,MAAA,EACA,UAAA,EACA,iBAAA,EACA,UAAA,EACF,EASG;IACD,IACE,UAAU,QACV,WAAW,YACX,WAAW,WACX,WAAW,UACX,WAAW,aACX;QACA,MAAM,IAAI,qBAAqB;YAC7B,WAAW;YACX,OAAO;YACP,SAAS;QACX,CAAC;IACH;IAEA,IAAI,WAAW,aAAa;QAC1B,IAAI,UAAU,MAAM;YAClB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,qBAAqB,MAAM;YAC7B,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,WAAW,UAAU;QACvB,IAAI,UAAU,MAAM;YAClB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,WAAW,SAAS;QACtB,IAAI,UAAU,MAAM;YAClB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;IACF;IAEA,IAAI,WAAW,QAAQ;QACrB,IAAI,UAAU,MAAM;YAClB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,qBAAqB,MAAM;YAC7B,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,qBAAqB;gBAC7B,WAAW;gBACX,OAAO;gBACP,SAAS;YACX,CAAC;QACH;QAEA,KAAA,MAAW,SAAS,WAAY;YAC9B,IAAI,OAAO,UAAU,UAAU;gBAC7B,MAAM,IAAI,qBAAqB;oBAC7B,WAAW;oBACX;oBACA,SAAS;gBACX,CAAC;YACH;QACF;IACF;AACF;;AlBxGA,IAAM,sBAAqB,0MAAA,EAAkB;IAAE,QAAQ;IAAS,MAAM;AAAG,CAAC;AA6E1E,eAAsB,eAWpB,OAAA,EAiFuC;IACvC,MAAM,EACJ,OAAO,QAAA,EACP,SAAS,QAAA,EACT,MAAA,EACA,MAAA,EACA,QAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACA,yBAAyB,UAAA,EACzB,wBAAwB,SAAA,EACxB,eAAA,EACA,WAAW,EACT,YAAAI,cAAa,kBAAA,EACb,cAAc,IAAM,aAAA,GAAA,IAAI,KAAK,CAAA,EAC/B,GAAI,CAAC,CAAA,EACL,GAAG,UACL,GAAI;IAEJ,MAAM,QAAQ,qBAAqB,QAAQ;IAE3C,MAAM,aAAa,UAAU,UAAU,QAAQ,IAAA,GAAO,KAAA;IACtD,MAAM,EACJ,QAAQ,WAAA,EACR,iBAAA,EACA,UAAA,EACF,GAAI,YAAY,UAAU,UAAU,CAAC;IAErC,8BAA8B;QAC5B;QACA,QAAQ;QACR;QACA;QACA;IACF,CAAC;IAED,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAE1E,MAAM,iBAAiB,kBAAkB;QACvC;QACA,QAAQ;QACR;IACF,CAAC;IAED,MAAM,eAAe,oBAAoB,QAAQ;IAEjD,MAAM,0BAA0B,2BAA2B;QACzD;QACA;QACA;QACA,UAAU;YAAE,GAAG,YAAA;YAAc;QAAW;IAC1C,CAAC;IAED,MAAM,SAAS,UAAU,SAAS;IAElC,IAAI;QACF,OAAO,MAAM,WAAW;YACtB,MAAM;YACN,YAAY,0BAA0B;gBACpC;gBACA,YAAY;oBACV,GAAG,sBAAsB;wBACvB,aAAa;wBACb;oBACF,CAAC,CAAA;oBACD,GAAG,uBAAA;oBAAA,6DAAA;oBAEH,aAAa;wBACX,OAAO,IAAM,KAAK,SAAA,CAAU;gCAAE;gCAAQ;gCAAQ;4BAAS,CAAC;oBAC1D;oBACA,aACE,eAAe,UAAA,IAAc,OACzB;wBAAE,OAAO,IAAM,KAAK,SAAA,CAAU,eAAe,UAAU;oBAAE,IACzD,KAAA;oBACN,kBAAkB;oBAClB,yBAAyB;oBACzB,sBAAsB,eAAe,IAAA;gBACvC;YACF,CAAC;YACD;YACA,IAAI,OAAM,SAAQ;gBAtSxB,IAAAC;gBAuSQ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBAEJ,MAAM,qBAAqB,MAAM,kBAAkB;oBACjD;oBACA;oBACA;gBACF,CAAC;gBAED,MAAM,iBAAiB,MAAM,6BAA6B;oBACxD,QAAQ;oBACR,eAAe,MAAM,MAAM,aAAA;gBAC7B,CAAC;gBAED,MAAM,iBAAiB,MAAM,MAAM,IACjC,WAAW;wBACT,MAAM;wBACN,YAAY,0BAA0B;4BACpC;4BACA,YAAY;gCACV,GAAG,sBAAsB;oCACvB,aAAa;oCACb;gCACF,CAAC,CAAA;gCACD,GAAG,uBAAA;gCACH,sBAAsB;oCACpB,OAAO,IAAM,sBAAsB,cAAc;gCACnD;gCAAA,2CAAA;gCAGA,iBAAiB,MAAM,QAAA;gCACvB,wBAAwB,MAAM,OAAA;gCAC9B,oCACE,aAAa,gBAAA;gCACf,6BAA6B,aAAa,eAAA;gCAC1C,mCAAmC,aAAa,eAAA;gCAChD,8BAA8B,aAAa,WAAA;gCAC3C,wBAAwB,aAAa,IAAA;gCACrC,wBAAwB,aAAa,IAAA;4BACvC;wBACF,CAAC;wBACD;wBACA,IAAI,OAAMC,UAAQ;4BAtV9B,IAAAD,MAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;4BAuVc,MAAME,UAAS,MAAM,MAAM,UAAA,CAAW;gCACpC,gBAAgB;oCACd,MAAM;oCACN,QAAQ,eAAe,UAAA;oCACvB,MAAM;oCACN,aAAa;gCACf;gCACA,GAAG,oBAAoB,QAAQ,CAAA;gCAC/B,QAAQ;gCACR;gCACA;gCACA;4BACF,CAAC;4BAED,MAAM,eAAe;gCACnB,IAAA,CAAI,KAAA,CAAAF,OAAAE,QAAO,QAAA,KAAP,OAAA,KAAA,IAAAF,KAAiB,EAAA,KAAjB,OAAA,KAAuBD,YAAW;gCACtC,WAAA,CAAW,KAAA,CAAA,KAAAG,QAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,SAAA,KAAjB,OAAA,KAA8B,YAAY;gCACrD,SAAA,CAAS,KAAA,CAAA,KAAAA,QAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,OAAA,KAAjB,OAAA,KAA4B,MAAM,OAAA;gCAC3C,SAAA,CAAS,KAAAA,QAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,OAAA;gCAC1B,MAAA,CAAM,KAAAA,QAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,IAAA;4BACzB;4BAEA,MAAMC,QAAO,mBAAmBD,QAAO,OAAO;4BAE9C,IAAIC,UAAS,KAAA,GAAW;gCACtB,MAAM,IAAI,uBAAuB;oCAC/B,SACE;oCACF,UAAU;oCACV,OAAOD,QAAO,KAAA;oCACd,cAAcA,QAAO,YAAA;gCACvB,CAAC;4BACH;4BAGAD,MAAK,aAAA,CACH,0BAA0B;gCACxB;gCACA,YAAY;oCACV,4BAA4BC,QAAO,YAAA;oCACnC,sBAAsB;wCAAE,QAAQ,IAAMC;oCAAK;oCAC3C,kBAAkB,aAAa,EAAA;oCAC/B,qBAAqB,aAAa,OAAA;oCAClC,yBACE,aAAa,SAAA,CAAU,WAAA,CAAY;oCAAA,mEAAA;oCAGrC,yBAAyBD,QAAO,KAAA,CAAM,WAAA;oCACtC,6BAA6BA,QAAO,KAAA,CAAM,YAAA;oCAAA,2CAAA;oCAG1C,kCAAkC;wCAACA,QAAO,YAAY;qCAAA;oCACtD,sBAAsB,aAAa,EAAA;oCACnC,yBAAyB,aAAa,OAAA;oCACtC,6BAA6BA,QAAO,KAAA,CAAM,WAAA;oCAC1C,8BAA8BA,QAAO,KAAA,CAAM,YAAA;gCAC7C;4BACF,CAAC;4BAGH,OAAO;gCAAE,GAAGA,OAAAA;gCAAQ,YAAYC;gCAAM;4BAAa;wBACrD;oBACF,CAAC;gBAGH,SAAS,eAAe,UAAA;gBACxB,eAAe,eAAe,YAAA;gBAC9B,QAAQ,eAAe,KAAA;gBACvB,WAAW,eAAe,QAAA;gBAC1B,yBAAyB,eAAe,gBAAA;gBACxC,UAAA,CAAUH,OAAA,eAAe,OAAA,KAAf,OAAAA,OAA0B,CAAC;gBACrC,WAAW,eAAe,YAAA;gBAE1B,eAAe,cAAcE,OAAAA,EAAiC;oBAC5D,MAAM,cAAc,UAAME,mMAAAA,EAAc;wBAAE,MAAMF;oBAAO,CAAC;oBAExD,IAAI,CAAC,YAAY,OAAA,EAAS;wBACxB,MAAM,IAAI,uBAAuB;4BAC/B,SAAS;4BACT,OAAO,YAAY,KAAA;4BACnB,MAAMA;4BACN;4BACA;4BACA;wBACF,CAAC;oBACH;oBAEA,MAAM,mBAAmB,MAAM,eAAe,mBAAA,CAC5C,YAAY,KAAA,EACZ;wBACE,MAAMA;wBACN;wBACA;oBACF;oBAGF,IAAI,CAAC,iBAAiB,OAAA,EAAS;wBAC7B,MAAM,IAAI,uBAAuB;4BAC/B,SAAS;4BACT,OAAO,iBAAiB,KAAA;4BACxB,MAAMA;4BACN;4BACA;4BACA;wBACF,CAAC;oBACH;oBAEA,OAAO,iBAAiB,KAAA;gBAC1B;gBAEA,IAAIG;gBACJ,IAAI;oBACFA,UAAS,MAAM,cAAc,MAAM;gBACrC,EAAA,OAAS,OAAO;oBACd,IACE,cAAc,QACd,uBAAuB,UAAA,CAAW,KAAK,KAAA,CACtCC,2KAAAA,CAAe,UAAA,CAAW,MAAM,KAAK,+JACpCC,sBAAAA,CAAoB,UAAA,CAAW,MAAM,KAAK,CAAA,GAC5C;wBACA,MAAM,eAAe,MAAM,WAAW;4BACpC,MAAM;4BACN,OAAO,MAAM,KAAA;wBACf,CAAC;wBAED,IAAI,iBAAiB,MAAM;4BACzB,MAAM;wBACR;wBAEAF,UAAS,MAAM,cAAc,YAAY;oBAC3C,OAAO;wBACL,MAAM;oBACR;gBACF;gBAGA,KAAK,aAAA,CACH,0BAA0B;oBACxB;oBACA,YAAY;wBACV,4BAA4B;wBAC5B,sBAAsB;4BACpB,QAAQ,IAAM,KAAK,SAAA,CAAUA,OAAM;wBACrC;wBAAA,mEAAA;wBAGA,yBAAyB,MAAM,WAAA;wBAC/B,6BAA6B,MAAM,YAAA;oBACrC;gBACF,CAAC;gBAGH,OAAO,IAAI,4BAA4B;oBACrC,QAAAA;oBACA;oBACA;oBACA;oBACA;oBACA;oBACA,kBAAkB;gBACpB,CAAC;YACH;QACF,CAAC;IACH,EAAA,OAAS,OAAO;QACd,MAAM,iBAAiB,KAAK;IAC9B;AACF;AAEA,IAAM,8BAAN,MAAwE;IAStE,YAAY,OAAA,CAQT;QACD,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,YAAA,GAAe,QAAQ,YAAA;QAC5B,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,gBAAA,GAAmB,QAAQ,gBAAA;QAChC,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,OAAA,GAAU,QAAQ,OAAA;IACzB;IAEA,eAAe,IAAA,EAA+B;QA1hBhD,IAAAL;QA2hBI,OAAO,IAAI,SAAS,KAAK,SAAA,CAAU,IAAA,CAAK,MAAM,GAAG;YAC/C,QAAA,CAAQA,OAAA,QAAA,OAAA,KAAA,IAAA,KAAM,MAAA,KAAN,OAAAA,OAAgB;YACxB,SAAS,eAAe,QAAA,OAAA,KAAA,IAAA,KAAM,OAAA,EAAS;gBACrC,gBAAgB;YAClB,CAAC;QACH,CAAC;IACH;AACF;;;AoBzhBO,SAAS,0BAId;IACA,IAAI;IACJ,IAAI;IAEJ,MAAM,UAAU,IAAI,QAAW,CAAC,KAAK,QAAQ;QAC3C,UAAU;QACV,SAAS;IACX,CAAC;IAED,OAAO;QACL;QACA;QACA;IACF;AACF;;ACnBO,SAAS,yBAKd;IACA,IAAI,qBAAuD,CAAC,CAAA;IAC5D,IAAI,aAAwD;IAC5D,IAAI,WAAW;IACf,IAAI,mBAAmB,wBAA8B;IAErD,MAAM,cAAc,YAAY;QAE9B,IAAI,YAAY,mBAAmB,MAAA,KAAW,GAAG;YAC/C,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA;YACZ;QACF;QAIA,IAAI,mBAAmB,MAAA,KAAW,GAAG;YACnC,mBAAmB,wBAA8B;YACjD,MAAM,iBAAiB,OAAA;YACvB,OAAO,YAAY;QACrB;QAEA,IAAI;YACF,MAAM,EAAE,KAAA,EAAO,IAAA,CAAK,CAAA,GAAI,MAAM,kBAAA,CAAmB,CAAC,CAAA,CAAE,IAAA,CAAK;YAEzD,IAAI,MAAM;gBAER,mBAAmB,KAAA,CAAM;gBAGzB,IAAI,mBAAmB,MAAA,GAAS,GAAG;oBACjC,MAAM,YAAY;gBACpB,OAAA,IAAW,UAAU;oBACnB,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA;gBACd;YACF,OAAO;gBAEL,cAAA,OAAA,KAAA,IAAA,WAAY,OAAA,CAAQ;YACtB;QACF,EAAA,OAAS,OAAO;YAEd,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA,CAAM;YAClB,mBAAmB,KAAA,CAAM;YAEzB,IAAI,YAAY,mBAAmB,MAAA,KAAW,GAAG;gBAC/C,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA;YACd;QACF;IACF;IAEA,OAAO;QACL,QAAQ,IAAI,eAAkB;YAC5B,OAAM,eAAA,EAAiB;gBACrB,aAAa;YACf;YACA,MAAM;YACN,MAAM,SAAS;gBACb,KAAA,MAAW,UAAU,mBAAoB;oBACvC,MAAM,OAAO,MAAA,CAAO;gBACtB;gBACA,qBAAqB,CAAC,CAAA;gBACtB,WAAW;YACb;QACF,CAAC;QACD,WAAW,CAAC,gBAAmC;YAC7C,IAAI,UAAU;gBACZ,MAAM,IAAI,MAAM,iDAAiD;YACnE;YAEA,mBAAmB,IAAA,CAAK,YAAY,SAAA,CAAU,CAAC;YAC/C,iBAAiB,OAAA,CAAQ;QAC3B;QAAA;;;KAAA,GAMA,OAAO,MAAM;YACX,WAAW;YACX,iBAAiB,OAAA,CAAQ;YAEzB,IAAI,mBAAmB,MAAA,KAAW,GAAG;gBACnC,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA;YACd;QACF;QAAA;;;KAAA,GAMA,WAAW,MAAM;YACf,WAAW;YACX,iBAAiB,OAAA,CAAQ;YAEzB,mBAAmB,OAAA,CAAQ,CAAA,SAAU,OAAO,MAAA,CAAO,CAAC;YACpD,qBAAqB,CAAC,CAAA;YACtB,cAAA,OAAA,KAAA,IAAA,WAAY,KAAA;QACd;IACF;AACF;;AC1GO,IAAM,iBAAN,MAAwB;IAAxB,aAAA;QACL,IAAA,CAAQ,MAAA,GAGmC;YAAE,MAAM;QAAU;QAE7D,IAAA,CAAQ,QAAA,GAA6C,KAAA;QACrD,IAAA,CAAQ,OAAA,GAAkD,KAAA;IAAA;IAE1D,IAAI,UAAsB;QACxB,IAAI,IAAA,CAAK,QAAA,EAAU;YACjB,OAAO,IAAA,CAAK,QAAA;QACd;QAEA,IAAA,CAAK,QAAA,GAAW,IAAI,QAAW,CAAC,SAAS,WAAW;YAClD,IAAI,IAAA,CAAK,MAAA,CAAO,IAAA,KAAS,YAAY;gBACnC,QAAQ,IAAA,CAAK,MAAA,CAAO,KAAK;YAC3B,OAAA,IAAW,IAAA,CAAK,MAAA,CAAO,IAAA,KAAS,YAAY;gBAC1C,OAAO,IAAA,CAAK,MAAA,CAAO,KAAK;YAC1B;YAEA,IAAA,CAAK,QAAA,GAAW;YAChB,IAAA,CAAK,OAAA,GAAU;QACjB,CAAC;QAED,OAAO,IAAA,CAAK,QAAA;IACd;IAEA,QAAQ,KAAA,EAAgB;QAjC1B,IAAAS;QAkCI,IAAA,CAAK,MAAA,GAAS;YAAE,MAAM;YAAY;QAAM;QAExC,IAAI,IAAA,CAAK,QAAA,EAAU;YACjB,CAAAA,OAAA,IAAA,CAAK,QAAA,KAAL,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,IAAA,EAAgB;QAClB;IACF;IAEA,OAAO,KAAA,EAAsB;QAzC/B,IAAAA;QA0CI,IAAA,CAAK,MAAA,GAAS;YAAE,MAAM;YAAY;QAAM;QAExC,IAAI,IAAA,CAAK,QAAA,EAAU;YACjB,CAAAA,OAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,IAAA,EAAe;QACjB;IACF;AACF;;AC/CO,SAAS,MAAc;IAD9B,IAAAC,MAAA;IAEE,OAAA,CAAO,KAAA,CAAAA,OAAA,cAAA,OAAA,KAAA,IAAA,WAAY,WAAA,KAAZ,OAAA,KAAA,IAAAA,KAAyB,GAAA,EAAA,KAAzB,OAAA,KAAkC,KAAK,GAAA,CAAI;AACpD;;AJgDA,IAAMC,6MAAqBC,oBAAAA,EAAkB;IAAE,QAAQ;IAAS,MAAM;AAAG,CAAC;AA+GnE,SAAS,aAWd,OAAA,EAqGA;IACA,MAAM,EACJ,KAAA,EACA,SAAS,QAAA,EACT,MAAA,EACA,MAAA,EACA,QAAA,EACA,UAAA,EACA,WAAA,EACA,OAAA,EACA,wBAAwB,SAAA,EACxB,eAAA,EACA,UAAU,CAAC,EAAE,KAAA,CAAM,CAAA,KAA0B;QAC3C,QAAQ,KAAA,CAAM,KAAK;IACrB,CAAA,EACA,QAAA,EACA,WAAW,EACT,YAAAC,cAAaF,mBAAAA,EACb,cAAc,IAAM,aAAA,GAAA,IAAI,KAAK,CAAA,EAC7B,KAAAG,OAAM,GAAA,EACR,GAAI,CAAC,CAAA,EACL,GAAG,UACL,GAAI;IAEJ,MAAM,aACJ,UAAU,WAAW,QAAQ,IAAA,GAAO,QAAQ,IAAA,GAAO,KAAA;IAErD,MAAM,EACJ,QAAQ,WAAA,EACR,iBAAA,EACA,UAAA,EACF,GAAI,YAAY,UAAU,UAAU,CAAC;IAErC,8BAA8B;QAC5B;QACA,QAAQ;QACR;QACA;QACA;IACF,CAAC;IAED,MAAM,iBAAiB,kBAAkB;QACvC;QACA,QAAQ;QACR;IACF,CAAC;IAED,OAAO,IAAI,0BAA0B;QACnC;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,YAAAD;QACA;QACA,KAAAC;IACF,CAAC;AACH;AAEA,IAAM,4BAAN,MAEA;IAoBE,YAAY,EACV,OAAO,QAAA,EACP,OAAA,EACA,SAAA,EACA,QAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,cAAA,EACA,MAAA,EACA,MAAA,EACA,QAAA,EACA,UAAA,EACA,iBAAA,EACA,eAAA,EACA,OAAA,EACA,QAAA,EACA,YAAAD,WAAAA,EACA,WAAA,EACA,KAAAC,IAAAA,EACF,CAmBG;QAzDH,IAAA,CAAiB,OAAA,GAAU,IAAI,eAAuB;QACtD,IAAA,CAAiB,MAAA,GAAS,IAAI,eAAmC;QACjE,IAAA,CAAiB,iBAAA,GAAoB,IAAI,eAEvC;QACF,IAAA,CAAiB,SAAA,GAAY,IAAI,eAA0C;QAC3E,IAAA,CAAiB,QAAA,GACf,IAAI,eAA6C;QACnD,IAAA,CAAiB,SAAA,GACf,IAAI,eAA8C;QAiDlD,MAAM,QAAQ,qBAAqB,QAAQ;QAE3C,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;YAC3C,YAAY;QACd,CAAC;QAED,MAAM,eAAe,oBAAoB,QAAQ;QAEjD,MAAM,0BAA0B,2BAA2B;YACzD;YACA;YACA;YACA,UAAU;gBAAE,GAAG,YAAA;gBAAc;YAAW;QAC1C,CAAC;QAED,MAAM,SAAS,UAAU,SAAS;QAClC,MAAM,OAAO,IAAA;QAEb,MAAM,mBACJ,uBAAkD;QAEpD,MAAM,iBAAiB,IAAI,gBAGzB;YACA,WAAU,KAAA,EAAO,UAAA,EAAY;gBAC3B,WAAW,OAAA,CAAQ,KAAK;gBAExB,IAAI,MAAM,IAAA,KAAS,SAAS;oBAC1B,QAAQ;wBAAE,OAAO,iBAAiB,MAAM,KAAK;oBAAE,CAAC;gBAClD;YACF;QACF,CAAC;QAED,IAAA,CAAK,UAAA,GAAa,iBAAiB,MAAA,CAAO,WAAA,CAAY,cAAc;QAEpE,WAAW;YACT,MAAM;YACN,YAAY,0BAA0B;gBACpC;gBACA,YAAY;oBACV,GAAG,sBAAsB;wBACvB,aAAa;wBACb;oBACF,CAAC,CAAA;oBACD,GAAG,uBAAA;oBAAA,6DAAA;oBAEH,aAAa;wBACX,OAAO,IAAM,KAAK,SAAA,CAAU;gCAAE;gCAAQ;gCAAQ;4BAAS,CAAC;oBAC1D;oBACA,aACE,eAAe,UAAA,IAAc,OACzB;wBAAE,OAAO,IAAM,KAAK,SAAA,CAAU,eAAe,UAAU;oBAAE,IACzD,KAAA;oBACN,kBAAkB;oBAClB,yBAAyB;oBACzB,sBAAsB,eAAe,IAAA;gBACvC;YACF,CAAC;YACD;YACA,aAAa;YACb,IAAI,OAAM,aAAY;gBACpB,MAAM,qBAAqB,MAAM,kBAAkB;oBACjD;oBACA;oBACA;gBACF,CAAC;gBAED,MAAM,cAAc;oBAClB,gBAAgB;wBACd,MAAM;wBACN,QAAQ,eAAe,UAAA;wBACvB,MAAM;wBACN,aAAa;oBACf;oBACA,GAAG,oBAAoB,QAAQ,CAAA;oBAC/B,QAAQ,MAAM,6BAA6B;wBACzC,QAAQ;wBACR,eAAe,MAAM,MAAM,aAAA;oBAC7B,CAAC;oBACD;oBACA;oBACA;oBACA,kBAAkB;gBACpB;gBAEA,MAAM,cAGF;oBACF,WAAW,CAAC,OAAO,eAAe;wBAChC,OAAQ,MAAM,IAAA,EAAM;4BAClB,KAAK;gCACH,WAAW,OAAA,CAAQ,MAAM,IAAI;gCAC7B;4BACF,KAAK;4BACL,KAAK;4BACL,KAAK;gCACH,WAAW,OAAA,CAAQ,KAAK;gCACxB;wBACJ;oBACF;gBACF;gBAEA,MAAM,EACJ,QAAQ,EAAE,MAAA,EAAQ,QAAA,EAAU,OAAA,CAAQ,CAAA,EACpC,YAAA,EACA,gBAAA,EACF,GAAI,MAAM,MAAM,IACd,WAAW;wBACT,MAAM;wBACN,YAAY,0BAA0B;4BACpC;4BACA,YAAY;gCACV,GAAG,sBAAsB;oCACvB,aAAa;oCACb;gCACF,CAAC,CAAA;gCACD,GAAG,uBAAA;gCACH,sBAAsB;oCACpB,OAAO,IAAM,sBAAsB,YAAY,MAAM;gCACvD;gCAAA,2CAAA;gCAGA,iBAAiB,MAAM,QAAA;gCACvB,wBAAwB,MAAM,OAAA;gCAC9B,oCACE,aAAa,gBAAA;gCACf,6BAA6B,aAAa,eAAA;gCAC1C,mCAAmC,aAAa,eAAA;gCAChD,8BAA8B,aAAa,WAAA;gCAC3C,wBAAwB,aAAa,IAAA;gCACrC,wBAAwB,aAAa,IAAA;4BACvC;wBACF,CAAC;wBACD;wBACA,aAAa;wBACb,IAAI,OAAMC,gBAAAA,CAAiB;gCACzB,kBAAkBD,KAAI;gCACtB,cAAAC;gCACA,QAAQ,MAAM,MAAM,QAAA,CAAS,WAAW;4BAC1C,CAAA;oBACF,CAAC;gBAGH,KAAK,QAAA,CAAS,OAAA,CAAQ,WAAA,OAAA,UAAW,CAAC,CAAC;gBAGnC,IAAI;gBACJ,IAAI,QAA4B;oBAC9B,aAAa,KAAA;oBACb,cAAc,KAAA;oBACd,aAAa,KAAA;gBACf;gBACA,IAAI;gBACJ,IAAI;gBACJ,IAAIC;gBACJ,IAAI;gBAGJ,IAAI,kBAAkB;gBACtB,IAAI,YAAY;gBAChB,IAAI,eAIA;oBACF,IAAIH,YAAW;oBACf,WAAW,YAAY;oBACvB,SAAS,MAAM,OAAA;gBACjB;gBAIA,IAAI,mBAA0C,KAAA;gBAC9C,IAAI,eAAoC,KAAA;gBACxC,IAAI,eAAe;gBACnB,IAAI,eAAe;gBAEnB,MAAM,oBAAoB,OACvB,WAAA,CAAY,IAAI,gBAAgB,WAAW,CAAC,EAC5C,WAAA,CACC,IAAI,gBAGF;oBACA,MAAM,WAAU,KAAA,EAAO,UAAA,EAA2B;wBA9kBhE,IAAAI,MAAA,IAAA;wBA+kBgB,IACE,OAAO,UAAU,YACjB,MAAM,IAAA,KAAS,gBACf;4BACA,WAAW,MAAM,QAAA;4BACjB;wBACF;wBAGA,IAAI,cAAc;4BAChB,MAAM,iBAAiBH,KAAI,IAAI;4BAE/B,eAAe;4BAEf,aAAa,QAAA,CAAS,wBAAwB;gCAC5C,4BAA4B;4BAC9B,CAAC;4BAED,aAAa,aAAA,CAAc;gCACzB,4BAA4B;4BAC9B,CAAC;wBACH;wBAGA,IAAI,OAAO,UAAU,UAAU;4BAC7B,mBAAmB;4BACnB,aAAa;4BAEb,MAAM,EAAE,OAAO,iBAAA,EAAmB,OAAO,UAAA,CAAW,CAAA,GAClD,MAAM,iBAAiB,eAAe;4BAExC,IACE,sBAAsB,KAAA,KACtB,CAAC,gBAAgB,kBAAkB,iBAAiB,GACpD;gCACA,MAAM,mBACJ,MAAM,eAAe,qBAAA,CAAsB;oCACzC,OAAO;oCACP;oCACA;oCACA;oCACA,cAAc,eAAe;gCAC/B,CAAC;gCAEH,IACE,iBAAiB,OAAA,IACjB,CAAC,gBACC,cACA,iBAAiB,KAAA,CAAM,OAAA,GAEzB;oCAEA,mBAAmB;oCACnB,eAAe,iBAAiB,KAAA,CAAM,OAAA;oCAEtC,WAAW,OAAA,CAAQ;wCACjB,MAAM;wCACN,QAAQ;oCACV,CAAC;oCAED,WAAW,OAAA,CAAQ;wCACjB,MAAM;wCACN,WAAW,iBAAiB,KAAA,CAAM,SAAA;oCACpC,CAAC;oCAED,YAAY;oCACZ,eAAe;gCACjB;4BACF;4BAEA;wBACF;wBAEA,OAAQ,MAAM,IAAA,EAAM;4BAClB,KAAK;gCAAqB;oCACxB,eAAe;wCACb,IAAA,CAAIG,OAAA,MAAM,EAAA,KAAN,OAAAA,OAAY,aAAa,EAAA;wCAC7B,WAAA,CAAW,KAAA,MAAM,SAAA,KAAN,OAAA,KAAmB,aAAa,SAAA;wCAC3C,SAAA,CAAS,KAAA,MAAM,OAAA,KAAN,OAAA,KAAiB,aAAa,OAAA;oCACzC;oCACA;gCACF;4BAEA,KAAK;gCAAU;oCAEb,IAAI,cAAc,IAAI;wCACpB,WAAW,OAAA,CAAQ;4CAAE,MAAM;4CAAc;wCAAU,CAAC;oCACtD;oCAGA,eAAe,MAAM,YAAA;oCAGrB,QAAQ,MAAM,KAAA;oCACd,mBAAmB,MAAM,gBAAA;oCAEzB,WAAW,OAAA,CAAQ;wCACjB,GAAG,KAAA;wCACH;wCACA,UAAU;oCACZ,CAAC;oCAGD,KAAK,MAAA,CAAO,OAAA,CAAQ,KAAK;oCACzB,KAAK,iBAAA,CAAkB,OAAA,CAAQ,gBAAgB;oCAC/C,KAAK,SAAA,CAAU,OAAA,CAAQ;wCACrB,GAAG,YAAA;wCACH,SAAS,YAAA,OAAA,KAAA,IAAA,SAAU,OAAA;oCACrB,CAAC;oCAGD,MAAM,mBACJ,MAAM,eAAe,mBAAA,CACnB,kBACA;wCACE,MAAM;wCACN,UAAU;wCACV;oCACF;oCAGJ,IAAI,iBAAiB,OAAA,EAAS;wCAC5BD,UAAS,iBAAiB,KAAA;wCAC1B,KAAK,OAAA,CAAQ,OAAA,CAAQA,OAAM;oCAC7B,OAAO;wCACL,QAAQ,IAAI,uBAAuB;4CACjC,SACE;4CACF,OAAO,iBAAiB,KAAA;4CACxB,MAAM;4CACN,UAAU;4CACV;4CACA;wCACF,CAAC;wCACD,KAAK,OAAA,CAAQ,MAAA,CAAO,KAAK;oCAC3B;oCAEA;gCACF;4BAEA;gCAAS;oCACP,WAAW,OAAA,CAAQ,KAAK;oCACxB;gCACF;wBACF;oBACF;oBAAA,8FAAA;oBAGA,MAAM,OAAM,UAAA,EAAY;wBACtB,IAAI;4BACF,MAAM,aAAa,SAAA,OAAA,QAAS;gCAC1B,cAAc;gCACd,kBAAkB;gCAClB,aAAa;4BACf;4BAEA,aAAa,aAAA,CACX,0BAA0B;gCACxB;gCACA,YAAY;oCACV,4BAA4B;oCAC5B,sBAAsB;wCACpB,QAAQ,IAAM,KAAK,SAAA,CAAUA,OAAM;oCACrC;oCACA,kBAAkB,aAAa,EAAA;oCAC/B,qBAAqB,aAAa,OAAA;oCAClC,yBACE,aAAa,SAAA,CAAU,WAAA,CAAY;oCAErC,wBAAwB,WAAW,WAAA;oCACnC,yBAAyB,WAAW,YAAA;oCACpC,wBAAwB,WAAW,WAAA;oCACnC,4BAA4B,WAAW,eAAA;oCACvC,8BACE,WAAW,iBAAA;oCAAA,2CAAA;oCAGb,kCAAkC;wCAAC,YAAY;qCAAA;oCAC/C,sBAAsB,aAAa,EAAA;oCACnC,yBAAyB,aAAa,OAAA;oCACtC,6BAA6B,WAAW,WAAA;oCACxC,8BAA8B,WAAW,YAAA;gCAC3C;4BACF,CAAC;4BAIH,aAAa,GAAA,CAAI;4BAGjB,SAAS,aAAA,CACP,0BAA0B;gCACxB;gCACA,YAAY;oCACV,wBAAwB,WAAW,WAAA;oCACnC,yBAAyB,WAAW,YAAA;oCACpC,wBAAwB,WAAW,WAAA;oCACnC,4BAA4B,WAAW,eAAA;oCACvC,8BACE,WAAW,iBAAA;oCACb,sBAAsB;wCACpB,QAAQ,IAAM,KAAK,SAAA,CAAUA,OAAM;oCACrC;gCACF;4BACF,CAAC;4BAIH,MAAA,CAAM,YAAA,OAAA,KAAA,IAAA,SAAW;gCACf,OAAO;gCACP,QAAAA;gCACA;gCACA,UAAU;oCACR,GAAG,YAAA;oCACH,SAAS,YAAA,OAAA,KAAA,IAAA,SAAU,OAAA;gCACrB;gCACA;gCACA;4BACF,EAAA;wBACF,EAAA,OAASE,QAAO;4BACd,WAAW,OAAA,CAAQ;gCAAE,MAAM;gCAAS,OAAAA;4BAAM,CAAC;wBAC7C,SAAE;4BACA,SAAS,GAAA,CAAI;wBACf;oBACF;gBACF,CAAC;gBAGL,iBAAiB,SAAA,CAAU,iBAAiB;YAC9C;QACF,CAAC,EACE,KAAA,CAAM,CAAA,UAAS;YAEd,iBAAiB,SAAA,CACf,IAAI,eAAe;gBACjB,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAS;oBAAM,CAAC;oBAC3C,WAAW,KAAA,CAAM;gBACnB;YACF,CAAC;QAEL,CAAC,EACA,OAAA,CAAQ,MAAM;YACb,iBAAiB,KAAA,CAAM;QACzB,CAAC;QAEH,IAAA,CAAK,cAAA,GAAiB;IACxB;IAEA,IAAI,SAAS;QACX,OAAO,IAAA,CAAK,OAAA,CAAQ,OAAA;IACtB;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,MAAA,CAAO,OAAA;IACrB;IAEA,IAAI,mBAAmB;QACrB,OAAO,IAAA,CAAK,iBAAA,CAAkB,OAAA;IAChC;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,OAAA;IACxB;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,QAAA,CAAS,OAAA;IACvB;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,OAAA;IACxB;IAEA,IAAI,sBAAoD;QACtD,OAAO,0BACL,IAAA,CAAK,UAAA,CAAW,WAAA,CACd,IAAI,gBAAoD;YACtD,WAAU,KAAA,EAAO,UAAA,EAAY;gBAC3B,OAAQ,MAAM,IAAA,EAAM;oBAClB,KAAK;wBACH,WAAW,OAAA,CAAQ,MAAM,MAAM;wBAC/B;oBAEF,KAAK;oBACL,KAAK;oBACL,KAAK;wBACH;oBAEF;wBAAS;4BACP,MAAM,mBAA0B;4BAChC,MAAM,IAAI,MAAM,CAAA,wBAAA,EAA2B,gBAAgB,EAAE;wBAC/D;gBACF;YACF;QACF,CAAC;IAGP;IAEA,IAAI,gBAAgC;QAClC,OAAO,IAAA,CAAK,cAAA,CAAe,mBAAA,CAAoB,IAAA,CAAK,UAAU;IAChE;IAEA,IAAI,aAA0C;QAC5C,OAAO,0BACL,IAAA,CAAK,UAAA,CAAW,WAAA,CACd,IAAI,gBAAmD;YACrD,WAAU,KAAA,EAAO,UAAA,EAAY;gBAC3B,OAAQ,MAAM,IAAA,EAAM;oBAClB,KAAK;wBACH,WAAW,OAAA,CAAQ,MAAM,SAAS;wBAClC;oBAEF,KAAK;oBACL,KAAK;oBACL,KAAK;wBACH;oBAEF;wBAAS;4BACP,MAAM,mBAA0B;4BAChC,MAAM,IAAI,MAAM,CAAA,wBAAA,EAA2B,gBAAgB,EAAE;wBAC/D;gBACF;YACF;QACF,CAAC;IAGP;IAEA,IAAI,aAA6D;QAC/D,OAAO,0BAA0B,IAAA,CAAK,UAAU;IAClD;IAEA,yBAAyB,QAAA,EAA0B,IAAA,EAAqB;QACtE,yBAAyB;YACvB;YACA,YAAY,IAAA,CAAK,UAAA;YACjB,GAAG,IAAA;QACL,CAAC;IACH;IAEA,qBAAqB,IAAA,EAA+B;QAClD,OAAO,yBAAyB;YAC9B,YAAY,IAAA,CAAK,UAAA;YACjB,GAAG,IAAA;QACL,CAAC;IACH;AACF;;AKp6BO,IAAM,yBAAN,wKAAqCC,aAAAA,CAAW;IAGrD,YAAY,OAAA,CAA4D;QACtE,KAAA,CAAM;YACJ,MAAM;YACN,SAAS;QACX,CAAC;QAED,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;IAC3B;AACF;;ACFO,IAAM,4BAAN,cACG,qBAEV;IAGE,YAAY,EACV,IAAA,EACA,SAAA,EACF,CAGG;QACD,KAAA,CAAM;YAAE;YAAM;QAAU,CAAC;QACzB,IAAI,SAAS;QAGb,IAAI,WAAW;YACb,MAAM,iBAAiB,UAAU,KAAA,CAAM,GAAG;YAE1C,IAAI,eAAe,MAAA,KAAW,GAAG;gBAE/B,IAAI,cAAc,cAAc;oBAC9B,SAAS,cAAA,CAAe,CAAC,CAAA;gBAC3B;YACF;QACF;QAEA,IAAI,CAAC,QAAQ;YAEX,MAAM,IAAI,MACR;QAEJ;QAEA,IAAA,CAAK,MAAA,GAAS;IAChB;AACF;;ACnBA,eAAsB,eAAe,EACnC,KAAA,EACA,MAAAC,KAAAA,EACA,KAAA,EACA,YAAA,EACA,YAAA,EACA,KAAA,EACA,kBAAkB,CAAC,CAAA,EACnB,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACF,EA8D0B;IA1G1B,IAAAC;IA2GE,MAAM,EAAE,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAE9D,MAAM,SAAS,MAAM,MAAM,IACzB,MAAM,UAAA,CAAW;YACf,MAAAD;YACA;YACA;YACA;YACA;YACA;YACA;YACA;QACF,CAAC;IAGH,IAAI,CAAC,OAAO,KAAA,IAAS,OAAO,KAAA,CAAM,MAAA,KAAW,GAAG;QAC9C,MAAM,IAAI,uBAAuB;YAAE,WAAW;gBAAC,OAAO,QAAQ;aAAA;QAAE,CAAC;IACnE;IAEA,OAAO,IAAI,oBAAoB;QAC7B,OAAO,IAAI,0BAA0B;YACnC,MAAM,OAAO,KAAA;YACb,WAAA,CACEC,OAAA,gBAAgB;gBACd,MAAM,OAAO,KAAA;gBACb,YAAY;YACd,CAAC,CAAA,KAHD,OAAAA,OAGM;QACV,CAAC;QACD,UAAU,OAAO,QAAA;QACjB,WAAW;YAAC,OAAO,QAAQ;SAAA;QAC3B,kBAAkB,OAAO,gBAAA;IAC3B,CAAC;AACH;AAEA,IAAM,sBAAN,MAAkD;IAMhD,YAAY,OAAA,CAKT;QAxJL,IAAAA;QAyJI,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;QACzB,IAAA,CAAK,gBAAA,GAAA,CAAmBA,OAAA,QAAQ,gBAAA,KAAR,OAAAA,OAA4B,CAAC;IACvD;AACF;;;AE9JO,SAAS,QAAW,KAAA,EAAiC;IAC1D,OAAO,UAAU,KAAA,IAAY,CAAC,CAAA,GAAI,MAAM,OAAA,CAAQ,KAAK,IAAI,QAAQ;QAAC,KAAK;KAAA;AACzE;;;AEFO,SAAS,iBACdG,OAAAA,EACmC;IACnC,OAAOA,WAAU,QAAQ,OAAO,IAAA,CAAKA,OAAM,EAAE,MAAA,GAAS;AACxD;;ADMO,SAAS,0BAAiD,EAC/D,KAAA,EACA,UAAA,EACA,WAAA,EACF,EASE;IACA,IAAI,CAAC,iBAAiB,KAAK,GAAG;QAC5B,OAAO;YACL,OAAO,KAAA;YACP,YAAY,KAAA;QACd;IACF;IAGA,MAAM,gBACJ,eAAe,OACX,OAAO,OAAA,CAAQ,KAAK,EAAE,MAAA,CAAO,CAAC,CAACC,MAAI,CAAA,GACjC,YAAY,QAAA,CAASA,MAAmB,KAE1C,OAAO,OAAA,CAAQ,KAAK;IAE1B,OAAO;QACL,OAAO,cAAc,GAAA,CAAI,CAAC,CAACA,QAAMC,KAAI,CAAA,KAAM;YACzC,MAAM,WAAWA,MAAK,IAAA;YACtB,OAAQ,UAAU;gBAChB,KAAK,KAAA;gBACL,KAAK;oBACH,OAAO;wBACL,MAAM;wBACN,MAAAD;wBACA,aAAaC,MAAK,WAAA;wBAClB,mMAAYC,WAAAA,EAASD,MAAK,UAAU,EAAE,UAAA;oBACxC;gBACF,KAAK;oBACH,OAAO;wBACL,MAAM;wBACN,MAAAD;wBACA,IAAIC,MAAK,EAAA;wBACT,MAAMA,MAAK,IAAA;oBACb;gBACF;oBAAS;wBACP,MAAM,kBAAyB;wBAC/B,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0B,eAAe,EAAE;oBAC7D;YACF;QACF,CAAC;QACD,YACE,cAAc,OACV;YAAE,MAAM;QAAO,IACf,OAAO,eAAe,WACpB;YAAE,MAAM;QAAW,IACnB;YAAE,MAAM;YAAiB,UAAU,WAAW,QAAA;QAAmB;IAC3E;AACF;;AErDO,SAAS,sBACd,MAAA,EACA,MAAA,EACoB;IACpB,OAAO;QACL,aAAa,eAAe,OAAO,WAAA,EAAa,OAAO,WAAW;QAClE,cAAc,eAAe,OAAO,YAAA,EAAc,OAAO,YAAY;QACrE,aAAa,eAAe,OAAO,WAAA,EAAa,OAAO,WAAW;QAClE,iBAAiB,eACf,OAAO,eAAA,EACP,OAAO,eAAA;QAET,mBAAmB,eACjB,OAAO,iBAAA,EACP,OAAO,iBAAA;IAEX;AACF;AAEA,SAAS,eACP,WAAA,EACA,WAAA,EACoB;IACpB,OAAO,eAAe,QAAQ,eAAe,OACzC,KAAA,IAAA,CACC,eAAA,OAAA,cAAe,CAAA,IAAA,CAAM,eAAA,OAAA,cAAe,CAAA;AAC3C;;ACrCO,SAAS,UAAiC,EAC/C,OAAA,EACA,SAAA,EACA,WAAA,EACF,EAI8B;IAC5B,OAAO;WACF,QAAQ,GAAA,CAAI,CAAA,SAAQ;YACrB,OAAQ,KAAK,IAAA,EAAM;gBACjB,KAAK;gBACL,KAAK;gBACL,KAAK;oBACH,OAAO;gBAET,KAAK;oBAAQ;wBACX,OAAO;4BACL,MAAM;4BACN,MAAM,IAAI,qBAAqB,IAAI;wBACrC;oBACF;gBAEA,KAAK;oBAAa;wBAChB,OAAO,UAAU,IAAA,CACf,CAAA,WAAY,SAAS,UAAA,KAAe,KAAK,UAAA;oBAE7C;YACF;QACF,CAAC;WACE;KACL;AACF;;AC1BA,eAAsB,cAAqC,EACzD,QAAA,EACA,KAAA,EACA,cAAA,EACA,MAAA,EACA,QAAA,EACF,EAMkC;IAChC,IAAI,SAAS,MAAM;QACjB,MAAM,IAAI,gBAAgB;YAAE,UAAU,SAAS,QAAA;QAAS,CAAC;IAC3D;IAEA,IAAI;QACF,OAAO,MAAM,gBAAgB;YAAE;YAAU;QAAM,CAAC;IAClD,EAAA,OAAS,OAAO;QACd,IACE,kBAAkB,QAClB,CAAA,CACE,gBAAgB,UAAA,CAAW,KAAK,KAChC,0BAA0B,UAAA,CAAW,KAAK,CAAA,GAE5C;YACA,MAAM;QACR;QAEA,IAAI,mBAAmD;QAEvD,IAAI;YACF,mBAAmB,MAAM,eAAe;gBACtC;gBACA;gBACA,iBAAiB,CAAC,EAAE,QAAA,CAAS,CAAA,KAAM;oBACjC,MAAM,EAAE,UAAA,CAAW,CAAA,GAAI,KAAA,CAAM,QAAQ,CAAA;oBACrC,OAAOK,kMAAAA,EAAS,UAAU,EAAE,UAAA;gBAC9B;gBACA;gBACA;gBACA;YACF,CAAC;QACH,EAAA,OAAS,aAAa;YACpB,MAAM,IAAI,oBAAoB;gBAC5B,OAAO;gBACP,eAAe;YACjB,CAAC;QACH;QAGA,IAAI,oBAAoB,MAAM;YAC5B,MAAM;QACR;QAEA,OAAO,MAAM,gBAAgB;YAAE,UAAU;YAAkB;QAAM,CAAC;IACpE;AACF;AAEA,eAAe,gBAAuC,EACpD,QAAA,EACA,KAAA,EACF,EAGkC;IAChC,MAAM,WAAW,SAAS,QAAA;IAE1B,MAAMC,QAAO,KAAA,CAAM,QAAQ,CAAA;IAE3B,IAAIA,SAAQ,MAAM;QAChB,MAAM,IAAI,gBAAgB;YACxB,UAAU,SAAS,QAAA;YACnB,gBAAgB,OAAO,IAAA,CAAK,KAAK;QACnC,CAAC;IACH;IAEA,MAAM,SAASD,kMAAAA,EAASC,MAAK,UAAU;IAIvC,MAAM,cACJ,SAAS,IAAA,CAAK,IAAA,CAAK,MAAM,KACrB,6LAAMC,oBAAAA,EAAkB;QAAE,OAAO,CAAC;QAAG;IAAO,CAAC,IAC7C,6LAAMC,gBAAAA,EAAc;QAAE,MAAM,SAAS,IAAA;QAAM;IAAO,CAAC;IAEzD,IAAI,YAAY,OAAA,KAAY,OAAO;QACjC,MAAM,IAAI,0BAA0B;YAClC;YACA,UAAU,SAAS,IAAA;YACnB,OAAO,YAAY,KAAA;QACrB,CAAC;IACH;IAEA,OAAO;QACL,MAAM;QACN,YAAY,SAAS,UAAA;QACrB;QACA,MAAM,eAAA,OAAA,KAAA,IAAA,YAAa,KAAA;IACrB;AACF;;ACTO,IAAM,oBAAN,MAEP;IASE,YAAY,EACV,OAAA,EACA,YAAA,EACA,KAAA,EACA,QAAA,EACA,OAAA,EACA,QAAA,EACA,gBAAA,EACF,CAQG;QACD,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,YAAA,GAAe;QACpB,IAAA,CAAK,KAAA,GAAQ;QACb,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,gBAAA,GAAmB;IAC1B;IAEA,IAAI,OAAO;QACT,OAAO,IAAA,CAAK,OAAA,CACT,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,MAAM,EACnC,GAAA,CAAI,CAAA,OAAQ,KAAK,IAAI,EACrB,IAAA,CAAK,EAAE;IACZ;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,WAAW;IAC9D;IAEA,IAAI,gBAAgB;QAClB,OAAO,IAAA,CAAK,SAAA,CAAU,MAAA,KAAW,IAC7B,KAAA,IACA,IAAA,CAAK,SAAA,CAAU,GAAA,CAAI,CAAA,OAAQ,KAAK,IAAI,EAAE,IAAA,CAAK,EAAE;IACnD;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,OAAA,CACT,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,MAAM,EACnC,GAAA,CAAI,CAAA,OAAQ,KAAK,IAAI;IAC1B;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,QAAQ;IAC3D;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,WAAW;IAC9D;IAEA,IAAI,cAAc;QAChB,OAAO,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,aAAa;IAChE;AACF;;AC1KO,SAAS,YAAY,SAAA,EAAuC;IACjE,OAAO,CAAC,EAAE,KAAA,CAAM,CAAA,GAAM,MAAM,MAAA,KAAW;AACzC;AAEO,SAAS,YAAY,QAAA,EAAsC;IAChE,OAAO,CAAC,EAAE,KAAA,CAAM,CAAA,KAAG;QAZrB,IAAAC,MAAA,IAAA;QAaI,OAAA,CAAA,KAAA,CAAA,KAAA,CAAAA,OAAA,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,KAAtB,OAAA,KAAA,IAAAA,KAAyB,SAAA,KAAzB,OAAA,KAAA,IAAA,GAAoC,IAAA,CAClC,CAAA,WAAY,SAAS,QAAA,KAAa,SAAA,KADpC,OAAA,KAEK;IAAA;AACT;AAEA,eAAsB,mBAA0C,EAC9D,cAAA,EACA,KAAA,EACF,EAGqB;IACnB,OAAA,CACE,MAAM,QAAQ,GAAA,CAAI,eAAe,GAAA,CAAI,CAAA,YAAa,UAAU;YAAE;QAAM,CAAC,CAAC,CAAC,CAAA,EACvE,IAAA,CAAK,CAAA,SAAU,MAAM;AACzB;;ACfO,SAAS,mBAA0C,EACxD,SAAS,YAAA,EACT,KAAA,EACF,EAGoD;IAClD,MAAM,mBAAoE,CAAC,CAAA;IAE3E,MAAM,UAA4B,aAC/B,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,iBAAiB,KAAK,IAAA,KAAS,QAAQ,EACpE,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,UAAU,KAAK,IAAA,CAAK,MAAA,GAAS,CAAC,EAC3D,GAAA,CAAI,CAAA,SAAQ;QACX,OAAQ,KAAK,IAAA,EAAM;YACjB,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;oBACL,MAAM;oBACN,MAAM,KAAK,IAAA;oBACX,iBAAiB,KAAK,gBAAA;gBACxB;YACF,KAAK;gBACH,OAAO;oBACL,MAAM;oBACN,MAAM,KAAK,IAAA,CAAK,MAAA;oBAChB,WAAW,KAAK,IAAA,CAAK,SAAA;gBACvB;YACF,KAAK;gBACH,OAAO;QACX;IACF,CAAC;IAEH,IAAI,QAAQ,MAAA,GAAS,GAAG;QACtB,iBAAiB,IAAA,CAAK;YACpB,MAAM;YACN;QACF,CAAC;IACH;IAEA,MAAM,oBAAiC,aACpC,MAAA,CAAO,CAAA,OAAQ,KAAK,IAAA,KAAS,aAAa,EAC1C,GAAA,CAAI,CAAC,eAA+B;QACnC,MAAMC,QAAO,KAAA,CAAM,WAAW,QAAQ,CAAA;QACtC,OAAA,CAAOA,SAAA,OAAA,KAAA,IAAAA,MAAM,gCAAA,KAAoC,OAC7C;YACE,MAAM;YACN,YAAY,WAAW,UAAA;YACvB,UAAU,WAAW,QAAA;YACrB,QAAQA,MAAK,gCAAA,CAAiC,WAAW,MAAM;YAC/D,sBAAsBA,MAAK,gCAAA,CACzB,WAAW,MAAA;QAEf,IACA;YACE,MAAM;YACN,YAAY,WAAW,UAAA;YACvB,UAAU,WAAW,QAAA;YACrB,QAAQ,WAAW,MAAA;QACrB;IACN,CAAC;IAEH,IAAI,kBAAkB,MAAA,GAAS,GAAG;QAChC,iBAAiB,IAAA,CAAK;YACpB,MAAM;YACN,SAAS;QACX,CAAC;IACH;IAEA,OAAO;AACT;;ATnCA,IAAMC,6MAAqBC,oBAAAA,EAAkB;IAC3C,QAAQ;IACR,MAAM;AACR,CAAC;AAyDD,eAAsB,aAIpB,EACA,OAAO,QAAA,EACP,KAAA,EACA,UAAA,EACA,MAAA,EACA,MAAA,EACA,QAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACA,WAAW,YAAY,CAAC,CAAA,EACxB,qBAAqB,MAAA,EACrB,wBAAwB,SAAA,EACxB,eAAA,EACA,wBAAA,EACA,cAAc,wBAAA,EACd,wBAAA,EACA,cAAc,wBAAA,EACd,6BAA6B,cAAA,EAC7B,WAAW,EACT,YAAAC,cAAaF,mBAAAA,EACb,cAAc,IAAM,aAAA,GAAA,IAAI,KAAK,CAAA,EAC/B,GAAI,CAAC,CAAA,EACL,YAAA,EACA,GAAG,UACL,EAkFiD;IAC/C,MAAM,QAAQ,qBAAqB,QAAQ;IAC3C,MAAM,iBAAiB,QAAQ,QAAQ;IACvC,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAE1E,MAAM,eAAe,oBAAoB,QAAQ;IAEjD,MAAM,0BAA0B,2BAA2B;QACzD;QACA;QACA;QACA,UAAU;YAAE,GAAG,YAAA;YAAc;QAAW;IAC1C,CAAC;IAED,MAAM,gBAAgB,MAAM,kBAAkB;QAC5C;QACA;QACA;IACF,CAAC;IAED,MAAM,SAAS,UAAU,SAAS;IAElC,IAAI;QACF,OAAO,MAAM,WAAW;YACtB,MAAM;YACN,YAAY,0BAA0B;gBACpC;gBACA,YAAY;oBACV,GAAG,sBAAsB;wBACvB,aAAa;wBACb;oBACF,CAAC,CAAA;oBACD,GAAG,uBAAA;oBAAA,SAAA;oBAEH,qBAAqB,MAAM,QAAA;oBAC3B,eAAe,MAAM,OAAA;oBAAA,6DAAA;oBAErB,aAAa;wBACX,OAAO,IAAM,KAAK,SAAA,CAAU;gCAAE;gCAAQ;gCAAQ;4BAAS,CAAC;oBAC1D;gBACF;YACF,CAAC;YACD;YACA,IAAI,OAAM,SAAQ;gBAtQxB,IAAAG,MAAA,IAAA,IAAA,IAAA;gBAuQQ,MAAMC,gBAAe,oBAAoB,QAAQ;gBAEjD,IAAI;gBAGJ,IAAI,mBAAyC,CAAC,CAAA;gBAC9C,IAAI,qBAA6C,CAAC,CAAA;gBAClD,MAAM,mBAA2C,CAAC,CAAA;gBAClD,MAAM,QAAoD,CAAC,CAAA;gBAE3D,GAAG;oBACD,MAAM,oBAAoB;2BACrB,cAAc,QAAA;2BACd;qBACL;oBAEA,MAAM,oBAAoB,MAAA,CAAM,eAAA,OAAA,KAAA,IAAA,YAAc;wBAC5C;wBACA;wBACA,YAAY,MAAM,MAAA;oBACpB,EAAA;oBAEA,MAAM,iBAAiB,MAAM,6BAA6B;wBACxD,QAAQ;4BACN,QAAA,CAAQD,OAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,MAAA,KAAnB,OAAAA,OAA6B,cAAc,MAAA;4BACnD,UAAU;wBACZ;wBACA,eAAe,MAAM,MAAM,aAAA;oBAC7B,CAAC;oBAED,MAAM,YAAY,qBAAA,CAChB,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,KAAA,KAAnB,OAAA,KAA4B;oBAG9B,MAAM,EAAE,YAAY,cAAA,EAAgB,OAAO,SAAA,CAAU,CAAA,GACnD,0BAA0B;wBACxB;wBACA,YAAA,CAAY,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,UAAA,KAAnB,OAAA,KAAiC;wBAC7C,aAAA,CAAa,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,WAAA,KAAnB,OAAA,KAAkC;oBACjD,CAAC;oBAEH,uBAAuB,MAAM,MAAM,MAAG;wBAhThD,IAAAA;wBAiTY,OAAA,WAAW;4BACT,MAAM;4BACN,YAAY,0BAA0B;gCACpC;gCACA,YAAY;oCACV,GAAG,sBAAsB;wCACvB,aAAa;wCACb;oCACF,CAAC,CAAA;oCACD,GAAG,uBAAA;oCAAA,SAAA;oCAEH,qBAAqB,UAAU,QAAA;oCAC/B,eAAe,UAAU,OAAA;oCAAA,UAAA;oCAEzB,sBAAsB;wCACpB,OAAO,IAAM,sBAAsB,cAAc;oCACnD;oCACA,mBAAmB;wCAAA,0CAAA;wCAEjB,OAAO,IAAM,aAAA,OAAA,KAAA,IAAA,UAAW,GAAA,CAAI,CAAAE,QAAQ,KAAK,SAAA,CAAUA,KAAI;oCACzD;oCACA,wBAAwB;wCACtB,OAAO,IACL,kBAAkB,OACd,KAAK,SAAA,CAAU,cAAc,IAC7B,KAAA;oCACR;oCAAA,2CAAA;oCAGA,iBAAiB,UAAU,QAAA;oCAC3B,wBAAwB,UAAU,OAAA;oCAClC,oCAAoC,SAAS,gBAAA;oCAC7C,6BAA6B,SAAS,eAAA;oCACtC,mCAAmC,SAAS,eAAA;oCAC5C,iCAAiC,SAAS,aAAA;oCAC1C,8BAAA,CACEF,OAAA,SAAS,WAAA,KAAT,OAAAA,OAAwB,KAAA;oCAC1B,wBAAwB,SAAS,IAAA;oCACjC,wBAAwB,SAAS,IAAA;gCACnC;4BACF,CAAC;4BACD;4BACA,IAAI,OAAMG,UAAQ;gCA3VhC,IAAAH,MAAAI,KAAAC,KAAAC,KAAAC,KAAA,IAAA,IAAA;gCA4VgB,MAAM,SAAS,MAAM,UAAU,UAAA,CAAW;oCACxC,GAAGN,aAAAA;oCACH,OAAO;oCACP,YAAY;oCACZ,gBAAgB,UAAA,OAAA,KAAA,IAAA,OAAQ,cAAA;oCACxB,QAAQ;oCACR;oCACA;oCACA;gCACF,CAAC;gCAGD,MAAM,eAAe;oCACnB,IAAA,CAAIG,MAAAA,CAAAJ,OAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAAA,KAAiB,EAAA,KAAjB,OAAAI,MAAuBL,YAAW;oCACtC,WAAA,CAAWO,MAAAA,CAAAD,MAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAAA,IAAiB,SAAA,KAAjB,OAAAC,MAA8B,YAAY;oCACrD,SAAA,CAAS,KAAA,CAAAC,MAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAAA,IAAiB,OAAA,KAAjB,OAAA,KAA4B,UAAU,OAAA;oCAC/C,SAAA,CAAS,KAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,OAAA;oCAC1B,MAAA,CAAM,KAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,IAAA;gCACzB;gCAGAJ,MAAK,aAAA,CACH,0BAA0B;oCACxB;oCACA,YAAY;wCACV,4BAA4B,OAAO,YAAA;wCACnC,oBAAoB;4CAClB,QAAQ,IAAM,mBAAmB,OAAO,OAAO;wCACjD;wCACA,yBAAyB;4CACvB,QAAQ,MAAM;gDACZ,MAAM,YAAY,YAAY,OAAO,OAAO;gDAC5C,OAAO,aAAa,OAChB,KAAA,IACA,KAAK,SAAA,CAAU,SAAS;4CAC9B;wCACF;wCACA,kBAAkB,aAAa,EAAA;wCAC/B,qBAAqB,aAAa,OAAA;wCAClC,yBACE,aAAa,SAAA,CAAU,WAAA,CAAY;wCAAA,mEAAA;wCAGrC,yBAAyB,OAAO,KAAA,CAAM,WAAA;wCACtC,6BAA6B,OAAO,KAAA,CAAM,YAAA;wCAAA,2CAAA;wCAG1C,kCAAkC;4CAAC,OAAO,YAAY;yCAAA;wCACtD,sBAAsB,aAAa,EAAA;wCACnC,yBAAyB,aAAa,OAAA;wCACtC,6BAA6B,OAAO,KAAA,CAAM,WAAA;wCAC1C,8BAA8B,OAAO,KAAA,CAAM,YAAA;oCAC7C;gCACF,CAAC;gCAGH,OAAO;oCAAE,GAAG,MAAA;oCAAQ,UAAU;gCAAa;4BAC7C;wBACF,CAAC;oBAAA;oBAIH,mBAAmB,MAAM,QAAQ,GAAA,CAC/B,qBAAqB,OAAA,CAClB,MAAA,CACC,CAAC,OACC,KAAK,IAAA,KAAS,aAEjB,GAAA,CAAI,CAAA,WACH,cAAc;4BACZ;4BACA;4BACA;4BACA;4BACA,UAAU;wBACZ,CAAC;oBAKP,qBACE,SAAS,OACL,CAAC,CAAA,GACD,MAAM,aAAa;wBACjB,WAAW;wBACX;wBACA;wBACA;wBACA,UAAU;wBACV;oBACF,CAAC;oBAGP,MAAM,cAAc,UAAU;wBAC5B,SAAS,qBAAqB,OAAA;wBAC9B,WAAW;wBACX,aAAa;oBACf,CAAC;oBAGD,iBAAiB,IAAA,IACZ,mBAAmB;wBACpB,SAAS;wBACT,OAAO,SAAA,OAAA,QAAU,CAAC;oBACpB,CAAC;oBAIH,MAAM,oBAAuC,IAAI,kBAAkB;wBACjE,SAAS;wBACT,cAAc,qBAAqB,YAAA;wBACnC,OAAO,qBAAqB,KAAA;wBAC5B,UAAU,qBAAqB,QAAA;wBAC/B,kBAAkB,qBAAqB,gBAAA;wBACvC,SAAA,CAAS,KAAA,qBAAqB,OAAA,KAArB,OAAA,KAAgC,CAAC;wBAC1C,UAAU;4BACR,GAAG,qBAAqB,QAAA;4BAAA,iEAAA;4BAExB,UAAU,gBAAgB,gBAAgB;wBAC5C;oBACF,CAAC;oBAED,MAAM,IAAA,CAAK,iBAAiB;oBAC5B,MAAA,CAAM,gBAAA,OAAA,KAAA,IAAA,aAAe,kBAAA;gBACvB,QAAA,wBAAA;gBAEE,iBAAiB,MAAA,GAAS,KAAA,uCAAA;gBAE1B,mBAAmB,MAAA,KAAW,iBAAiB,MAAA,IAAA,0CAAA;gBAE/C,CAAE,MAAM,mBAAmB;oBAAE;oBAAgB;gBAAM,CAAC,EAAA;gBAItD,KAAK,aAAA,CACH,0BAA0B;oBACxB;oBACA,YAAY;wBACV,4BAA4B,qBAAqB,YAAA;wBACjD,oBAAoB;4BAClB,QAAQ,IAAM,mBAAmB,qBAAqB,OAAO;wBAC/D;wBACA,yBAAyB;4BACvB,QAAQ,MAAM;gCACZ,MAAM,YAAY,YAAY,qBAAqB,OAAO;gCAC1D,OAAO,aAAa,OAChB,KAAA,IACA,KAAK,SAAA,CAAU,SAAS;4BAC9B;wBACF;wBAAA,mEAAA;wBAGA,yBAAyB,qBAAqB,KAAA,CAAM,WAAA;wBACpD,6BACE,qBAAqB,KAAA,CAAM,YAAA;oBAC/B;gBACF,CAAC;gBAGH,MAAM,WAAW,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA;gBAEvC,OAAO,IAAI,0BAA0B;oBACnC;oBACA,gBAAgB,MAAA,CAAM,UAAA,OAAA,KAAA,IAAA,OAAQ,WAAA,CAC5B;wBAAE,MAAM,SAAS,IAAA;oBAAK,GACtB;wBACE,UAAU,SAAS,QAAA;wBACnB,OAAO,SAAS,KAAA;wBAChB,cAAc,SAAS,YAAA;oBACzB,EAAA;gBAEJ,CAAC;YACH;QACF,CAAC;IACH,EAAA,OAAS,OAAO;QACd,MAAM,iBAAiB,KAAK;IAC9B;AACF;AAEA,eAAe,aAAoC,EACjD,SAAA,EACA,KAAA,EACA,MAAA,EACA,SAAA,EACA,QAAA,EACA,WAAA,EACF,EAOoC;IAClC,MAAM,cAAc,MAAM,QAAQ,GAAA,CAChC,UAAU,GAAA,CAAI,OAAO,EAAE,UAAA,EAAY,QAAA,EAAU,IAAA,CAAK,CAAA,KAAM;QACtD,MAAMD,QAAO,KAAA,CAAM,QAAQ,CAAA;QAE3B,IAAA,CAAIA,SAAA,OAAA,KAAA,IAAAA,MAAM,eAAA,KAAmB,MAAM;YACjC,MAAMA,MAAK,eAAA,CAAgB;gBACzB;gBACA;gBACA;gBACA;YACF,CAAC;QACH;QAEA,IAAA,CAAIA,SAAA,OAAA,KAAA,IAAAA,MAAM,OAAA,KAAW,MAAM;YACzB,OAAO,KAAA;QACT;QAEA,MAAM,SAAS,MAAM,WAAW;YAC9B,MAAM;YACN,YAAY,0BAA0B;gBACpC;gBACA,YAAY;oBACV,GAAG,sBAAsB;wBACvB,aAAa;wBACb;oBACF,CAAC,CAAA;oBACD,oBAAoB;oBACpB,kBAAkB;oBAClB,oBAAoB;wBAClB,QAAQ,IAAM,KAAK,SAAA,CAAU,IAAI;oBACnC;gBACF;YACF,CAAC;YACD;YACA,IAAI,OAAM,SAAQ;gBAChB,IAAI;oBACF,MAAMM,UAAS,MAAMN,MAAK,OAAA,CAAS,MAAM;wBACvC;wBACA;wBACA;oBACF,CAAC;oBAED,IAAI;wBACF,KAAK,aAAA,CACH,0BAA0B;4BACxB;4BACA,YAAY;gCACV,sBAAsB;oCACpB,QAAQ,IAAM,KAAK,SAAA,CAAUM,OAAM;gCACrC;4BACF;wBACF,CAAC;oBAEL,EAAA,OAAS,SAAS,CAKlB;oBAEA,OAAOA;gBACT,EAAA,OAAS,OAAO;oBACd,MAAM,IAAI,mBAAmB;wBAC3B;wBACA;wBACA,UAAU;wBACV,OAAO;oBACT,CAAC;gBACH;YACF;QACF,CAAC;QAED,OAAO;YACL,MAAM;YACN;YACA;YACA;YACA;QACF;IACF,CAAC;IAGH,OAAO,YAAY,MAAA,CACjB,CAAC,SAAiD,UAAU;AAEhE;AAEA,IAAM,4BAAN,MAEA;IAKE,YAAY,OAAA,CAGT;QACD,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;QACrB,IAAA,CAAK,cAAA,GAAiB,QAAQ,cAAA;IAChC;IAEA,IAAY,YAAY;QACtB,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,KAAA,CAAM,MAAA,GAAS,CAAC,CAAA;IACzC;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,OAAA;IACxB;IAEA,IAAI,OAAO;QACT,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA;IACxB;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,SAAA,CAAU,KAAA;IACxB;IAEA,IAAI,gBAAgB;QAClB,OAAO,IAAA,CAAK,SAAA,CAAU,aAAA;IACxB;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,SAAA,CAAU,SAAA;IACxB;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,SAAA,CAAU,SAAA;IACxB;IAEA,IAAI,cAAc;QAChB,OAAO,IAAA,CAAK,SAAA,CAAU,WAAA;IACxB;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,OAAA;IACxB;IAEA,IAAI,eAAe;QACjB,OAAO,IAAA,CAAK,SAAA,CAAU,YAAA;IACxB;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,QAAA;IACxB;IAEA,IAAI,mBAAmB;QACrB,OAAO,IAAA,CAAK,SAAA,CAAU,gBAAA;IACxB;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,QAAA;IACxB;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,OAAA;IACxB;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,SAAA,CAAU,KAAA;IACxB;IAEA,IAAI,aAAa;QACf,OAAO,IAAA,CAAK,KAAA,CAAM,MAAA,CAChB,CAAC,YAAY,SAAS;YACpB,OAAO,sBAAsB,YAAY,KAAK,KAAK;QACrD,GACA;YACE,aAAa,KAAA;YACb,cAAc,KAAA;YACd,aAAa,KAAA;YACb,iBAAiB,KAAA;YACjB,mBAAmB,KAAA;QACrB;IAEJ;IAEA,IAAI,sBAAsB;QACxB,IAAI,IAAA,CAAK,cAAA,IAAkB,MAAM;YAC/B,MAAM,IAAI,uBAAuB;QACnC;QAEA,OAAO,IAAA,CAAK,cAAA;IACd;AACF;AAEA,SAAS,YAAY,OAAA,EAAwC;IAC3D,MAAM,QAAQ,QAAQ,MAAA,CACpB,CAAC,OAA0C,KAAK,IAAA,KAAS;IAG3D,IAAI,MAAM,MAAA,KAAW,GAAG;QACtB,OAAO,KAAA;IACT;IAEA,OAAO,MAAM,GAAA,CAAI,CAAA,WAAA,CAAa;YAC5B,cAAc,SAAS,YAAA;YACvB,YAAY,SAAS,UAAA;YACrB,UAAU,SAAS,QAAA;YACnB,MAAM,SAAS,IAAA;QACjB,CAAA,CAAE;AACJ;;AUvuBA,IAAA,iBAAA,CAAA;AAAA,SAAA,gBAAA;IAAA,QAAA,IAAA;IAAA,MAAA,IAAA;AAAA;;AAmCO,IAAM,OAAO,IAAA,CAA+B;QACjD,MAAM;QAEN,gBAAgB;YAAE,MAAM;QAAO;QAE/B,MAAM,cAAa,EAAE,MAAAI,KAAAA,CAAK,CAAA,EAAqB;YAC7C,OAAO;gBAAE,SAASA;YAAK;QACzB;QAEA,MAAM,aAAY,EAAE,MAAAA,KAAAA,CAAK,CAAA,EAAqB;YAC5C,OAAOA;QACT;IACF,CAAA;AAEO,IAAM,SAAS,CAAS,EAC7B,QAAQ,WAAA,EACV,KAK2C;IACzC,MAAM,gMAASC,WAAAA,EAAS,WAAW;IAEnC,OAAO;QACL,MAAM;QAEN,gBAAgB;YACd,MAAM;YACN,QAAQ,OAAO,UAAA;QACjB;QAEA,MAAM,cAAa,EAAE,MAAAD,KAAAA,CAAK,CAAA,EAAqB;YAC7C,MAAM,SAAS,MAAM,iBAAiBA,KAAI;YAE1C,OAAQ,OAAO,KAAA,EAAO;gBACpB,KAAK;gBACL,KAAK;oBACH,OAAO,KAAA;gBAET,KAAK;gBACL,KAAK;oBACH,OAAO;wBAAA,oDAAA;wBAEL,SAAS,OAAO,KAAA;oBAClB;gBAEF;oBAAS;wBACP,MAAM,mBAA0B,OAAO,KAAA;wBACvC,MAAM,IAAI,MAAM,CAAA,yBAAA,EAA4B,gBAAgB,EAAE;oBAChE;YACF;QACF;QAEA,MAAM,aACJ,EAAE,MAAAA,KAAAA,CAAK,CAAA,EACP,OAAA,EAKA;YACA,MAAM,cAAc,6LAAME,gBAAAA,EAAc;gBAAE,MAAAF;YAAK,CAAC;YAEhD,IAAI,CAAC,YAAY,OAAA,EAAS;gBACxB,MAAM,IAAI,uBAAuB;oBAC/B,SAAS;oBACT,OAAO,YAAY,KAAA;oBACnB,MAAAA;oBACA,UAAU,QAAQ,QAAA;oBAClB,OAAO,QAAQ,KAAA;oBACf,cAAc,QAAQ,YAAA;gBACxB,CAAC;YACH;YAEA,MAAM,mBAAmB,6LAAMG,oBAAAA,EAAkB;gBAC/C,OAAO,YAAY,KAAA;gBACnB;YACF,CAAC;YAED,IAAI,CAAC,iBAAiB,OAAA,EAAS;gBAC7B,MAAM,IAAI,uBAAuB;oBAC/B,SAAS;oBACT,OAAO,iBAAiB,KAAA;oBACxB,MAAAH;oBACA,UAAU,QAAQ,QAAA;oBAClB,OAAO,QAAQ,KAAA;oBACf,cAAc,QAAQ,YAAA;gBACxB,CAAC;YACH;YAEA,OAAO,iBAAiB,KAAA;QAC1B;IACF;AACF;;;AC5HA,IAAM,mBAAmB;IACvB,MAAM;IACN,MAAM;AACR;AAmBO,SAAS,aAAoC,EAClD,YAAY,EAAA,EACZ,WAAW,MAAA,EACX,WAAW,EAAE,OAAAK,SAAQ,2LAAA,CAAc,CAAA,GAAI,CAAC,CAAA,EAC1C,GASI,CAAC,CAAA,EAE+D;IAClE,IAAI;IAEJ,IAAI,OAAO,aAAa,YAAY;QAClC,cAAc,CAAA,WAAU;YACtB,MAAM,QAAQ,SAAS,MAAM;YAE7B,IAAI,SAAS,MAAM;gBACjB,OAAO;YACT;YAEA,IAAI,CAAC,MAAM,MAAA,EAAQ;gBACjB,MAAM,IAAI,MAAM,CAAA,iDAAA,CAAmD;YACrE;YAEA,IAAI,CAAC,OAAO,UAAA,CAAW,KAAK,GAAG;gBAC7B,MAAM,IAAI,MACR,CAAA,iFAAA,EAAoF,KAAK,CAAA,0BAAA,EAA6B,MAAM,CAAA,CAAA,CAAA;YAEhI;YAEA,OAAO;QACT;IACF,OAAO;QACL,MAAM,gBACJ,OAAO,aAAa,WAAW,gBAAA,CAAiB,QAAQ,CAAA,GAAI;QAE9D,IAAI,iBAAiB,MAAM;YACzB,MAAM,8JAAID,uBAAAA,CAAqB;gBAC7B,UAAU;gBACV,SAAS,CAAA,yDAAA,EAA4D,QAAQ,EAAA;YAC/E,CAAC;QACH;QAEA,cAAc,CAAA,WAAU;YACtB,MAAM,QAAQ,cAAc,IAAA,CAAK,MAAM;YAEvC,IAAI,CAAC,OAAO;gBACV,OAAO;YACT;YAEA,OAAO,OAAO,KAAA,CAAM,GAAG,MAAM,KAAK,IAAA,CAAI,SAAA,OAAA,KAAA,IAAA,KAAA,CAAQ,EAAA;QAChD;IACF;IAEA,OAAO,MAAM;QACX,IAAI,SAAS;QAEb,OAAO,IAAI,gBAA8D;YACvE,MAAM,WAAU,KAAA,EAAO,UAAA,EAAY;gBACjC,IAAI,MAAM,IAAA,KAAS,QAAQ;oBACzB,IAAI,OAAO,MAAA,GAAS,GAAG;wBACrB,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAQ,MAAM;wBAAO,CAAC;wBACjD,SAAS;oBACX;oBAEA,WAAW,OAAA,CAAQ,KAAK;oBACxB;gBACF;gBAEA,UAAU,MAAM,IAAA;gBAEhB,IAAI;gBAEJ,MAAA,CAAQ,QAAQ,YAAY,MAAM,CAAA,KAAM,KAAM;oBAC5C,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAQ,MAAM;oBAAM,CAAC;oBAChD,SAAS,OAAO,KAAA,CAAM,MAAM,MAAM;oBAElC,MAAMC,OAAM,SAAS;gBACvB;YACF;QACF,CAAC;IACH;AACF;;;AE5DO,SAAS,uBAA8C,EAC5D,KAAA,EACA,eAAA,EACA,MAAA,EACA,SAAA,EACA,MAAA,EACA,QAAA,EACA,WAAA,EACA,cAAA,EACF,EASuD;IAErD,IAAI,8BAEO;IACX,MAAM,oBAAoB,IAAI,eAE5B;QACA,OAAM,UAAA,EAAY;YAChB,8BAA8B;QAChC;IACF,CAAC;IAGD,MAAM,kBAA2C,CAAC;IAGlD,MAAM,yBAAyB,aAAA,GAAA,IAAI,IAAY;IAE/C,IAAI,WAAW;IACf,IAAI,cAEY,KAAA;IAEhB,SAAS,eAAe;QAEtB,IAAI,YAAY,uBAAuB,IAAA,KAAS,GAAG;YAIjD,IAAI,eAAe,MAAM;gBACvB,4BAA6B,OAAA,CAAQ,WAAW;YAClD;YAEA,4BAA6B,KAAA,CAAM;QACrC;IACF;IAGA,MAAM,gBAAgB,IAAI,gBAGxB;QACA,MAAM,WACJ,KAAA,EACA,UAAA,EAGA;YACA,MAAM,YAAY,MAAM,IAAA;YAExB,OAAQ,WAAW;gBAEjB,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;oBAAS;wBACZ,WAAW,OAAA,CAAQ,KAAK;wBACxB;oBACF;gBAGA,KAAK;oBAAO;wBACV,WAAW,OAAA,CAAQ,KAAK;wBACxB;oBACF;gBAEA,KAAK;oBAAQ;wBACX,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,MAAM,IAAI,6BAA6B;gCACrC,MAAM,MAAM,IAAA;gCACZ,WAAW,MAAM,SAAA;4BACnB,CAAC;wBACH,CAAC;wBACD;oBACF;gBAGA,KAAK;oBAAmB;wBACtB,IAAI,CAAC,eAAA,CAAgB,MAAM,UAAU,CAAA,EAAG;4BACtC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,UAAA;gCAClB,UAAU,MAAM,QAAA;4BAClB,CAAC;4BAED,eAAA,CAAgB,MAAM,UAAU,CAAA,GAAI;wBACtC;wBAEA,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,YAAY,MAAM,UAAA;4BAClB,UAAU,MAAM,QAAA;4BAChB,eAAe,MAAM,aAAA;wBACvB,CAAC;wBAED;oBACF;gBAGA,KAAK;oBAAa;wBAChB,IAAI;4BACF,MAAM,WAAW,MAAM,cAAc;gCACnC,UAAU;gCACV;gCACA;gCACA;gCACA;4BACF,CAAC;4BAED,WAAW,OAAA,CAAQ,QAAQ;4BAE3B,MAAME,QAAO,KAAA,CAAO,SAAS,QAAQ,CAAA;4BAErC,IAAIA,MAAK,eAAA,IAAmB,MAAM;gCAChC,MAAMA,MAAK,eAAA,CAAgB;oCACzB,MAAM,SAAS,IAAA;oCACf,YAAY,SAAS,UAAA;oCACrB;oCACA;gCACF,CAAC;4BACH;4BAEA,IAAIA,MAAK,OAAA,IAAW,MAAM;gCACxB,MAAM,kBAAkB,oMAAA,CAAW;gCACnC,uBAAuB,GAAA,CAAI,eAAe;gCAK1C,WAAW;oCACT,MAAM;oCACN,YAAY,0BAA0B;wCACpC;wCACA,YAAY;4CACV,GAAG,sBAAsB;gDACvB,aAAa;gDACb;4CACF,CAAC,CAAA;4CACD,oBAAoB,SAAS,QAAA;4CAC7B,kBAAkB,SAAS,UAAA;4CAC3B,oBAAoB;gDAClB,QAAQ,IAAM,KAAK,SAAA,CAAU,SAAS,IAAI;4CAC5C;wCACF;oCACF,CAAC;oCACD;oCACA,IAAI,OAAM,OACRA,MAAK,OAAA,CAAS,SAAS,IAAA,EAAM;4CAC3B,YAAY,SAAS,UAAA;4CACrB;4CACA;wCACF,CAAC,EAAE,IAAA,CACD,CAAC,WAAgB;4CACf,4BAA6B,OAAA,CAAQ;gDACnC,GAAG,QAAA;gDACH,MAAM;gDACN;4CACF,CAAQ;4CAER,uBAAuB,MAAA,CAAO,eAAe;4CAE7C,aAAa;4CAGb,IAAI;gDACF,KAAK,aAAA,CACH,0BAA0B;oDACxB;oDACA,YAAY;wDACV,sBAAsB;4DACpB,QAAQ,IAAM,KAAK,SAAA,CAAU,MAAM;wDACrC;oDACF;gDACF,CAAC;4CAEL,EAAA,OAAS,SAAS,CAKlB;wCACF,GACA,CAAC,UAAe;4CACd,4BAA6B,OAAA,CAAQ;gDACnC,MAAM;gDACN,OAAO,IAAI,mBAAmB;oDAC5B,YAAY,SAAS,UAAA;oDACrB,UAAU,SAAS,QAAA;oDACnB,UAAU,SAAS,IAAA;oDACnB,OAAO;gDACT,CAAC;4CACH,CAAC;4CAED,uBAAuB,MAAA,CAAO,eAAe;4CAC7C,aAAa;wCACf;gCAEN,CAAC;4BACH;wBACF,EAAA,OAAS,OAAO;4BACd,4BAA6B,OAAA,CAAQ;gCACnC,MAAM;gCACN;4BACF,CAAC;wBACH;wBAEA;oBACF;gBAEA;oBAAS;wBACP,MAAM,mBAA0B;wBAChC,MAAM,IAAI,MAAM,CAAA,sBAAA,EAAyB,gBAAgB,EAAE;oBAC7D;YACF;QACF;QAEA,QAAQ;YACN,WAAW;YACX,aAAa;QACf;IACF,CAAC;IAGD,OAAO,IAAI,eAAmD;QAC5D,MAAM,OAAM,UAAA,EAAY;YAGtB,OAAO,QAAQ,GAAA,CAAI;gBACjB,gBAAgB,WAAA,CAAY,aAAa,EAAE,MAAA,CACzC,IAAI,eAAe;oBACjB,OAAM,KAAA,EAAO;wBACX,WAAW,OAAA,CAAQ,KAAK;oBAC1B;oBACA,QAAQ,EAER;gBACF,CAAC;gBAEH,kBAAkB,MAAA,CAChB,IAAI,eAAe;oBACjB,OAAM,KAAA,EAAO;wBACX,WAAW,OAAA,CAAQ,KAAK;oBAC1B;oBACA,QAAQ;wBACN,WAAW,KAAA,CAAM;oBACnB;gBACF,CAAC;aAEJ;QACH;IACF,CAAC;AACH;;AD9PA,IAAMC,6MAAqBC,oBAAAA,EAAkB;IAC3C,QAAQ;IACR,MAAM;AACR,CAAC;AAuHM,SAAS,WAId,EACA,KAAA,EACA,KAAA,EACA,UAAA,EACA,MAAA,EACA,MAAA,EACA,QAAA,EACA,UAAA,EACA,WAAA,EACA,OAAA,EACA,WAAW,YAAY,CAAC,CAAA,EACxB,qBAAqB,MAAA,EACrB,wBAAwB,SAAA,EACxB,WAAA,EACA,eAAA,EACA,wBAAA,EACA,cAAc,wBAAA,EACd,6BAA6B,cAAA,EAC7B,wBAAwB,SAAA,EACxB,mBAAmB,KAAA,EACnB,OAAA,EACA,UAAU,CAAC,EAAE,KAAA,CAAM,CAAA,KAAM;IACvB,QAAQ,KAAA,CAAM,KAAK;AACrB,CAAA,EACA,QAAA,EACA,YAAA,EACA,WAAW,EACT,KAAAC,OAAM,GAAA,EACN,YAAAC,cAAaH,mBAAAA,EACb,cAAc,IAAM,aAAA,GAAA,IAAI,KAAK,CAAA,EAC/B,GAAI,CAAC,CAAA,EACL,GAAG,UACL,EA4H8C;IAC5C,OAAO,IAAI,wBAAuD;QAChE,OAAO,qBAAqB,KAAK;QACjC;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,YAAY,QAAQ,SAAS;QAC7B;QACA;QACA,gBAAgB,QAAQ,QAAQ;QAChC;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,KAAAE;QACA;QACA,YAAAC;IACF,CAAC;AACH;AAOA,SAAS,4BAKP,MAAA,EAIA;IACA,IAAI,CAAC,QAAQ;QACX,OAAO,IAAI,gBAGT;YACA,WAAU,KAAA,EAAO,UAAA,EAAY;gBAC3B,WAAW,OAAA,CAAQ;oBAAE,MAAM;oBAAO,eAAe,KAAA;gBAAU,CAAC;YAC9D;QACF,CAAC;IACH;IAEA,IAAIC,QAAO;IACX,IAAI,YAAY;IAChB,IAAI,oBAAoB;IAExB,SAAS,iBAAiB,EACxB,UAAA,EACA,gBAAgB,KAAA,CAAA,EAClB,EAKG;QACD,WAAW,OAAA,CAAQ;YACjB,MAAM;gBAAE,MAAM;gBAAQ,MAAM;YAAU;YACtC;QACF,CAAC;QACD,YAAY;IACd;IAEA,OAAO,IAAI,gBAGT;QACA,MAAM,WAAU,KAAA,EAAO,UAAA,EAAY;YAEjC,IAAI,MAAM,IAAA,KAAS,eAAe;gBAChC,iBAAiB;oBAAE;gBAAW,CAAC;YACjC;YAEA,IAAI,MAAM,IAAA,KAAS,QAAQ;gBACzB,WAAW,OAAA,CAAQ;oBAAE,MAAM;oBAAO,eAAe,KAAA;gBAAU,CAAC;gBAC5D;YACF;YAEAA,SAAQ,MAAM,IAAA;YACd,aAAa,MAAM,IAAA;YAGnB,MAAM,SAAS,MAAM,OAAO,YAAA,CAAa;gBAAE,MAAAA;YAAK,CAAC;YACjD,IAAI,UAAU,MAAM;gBAElB,MAAM,cAAc,KAAK,SAAA,CAAU,OAAO,OAAO;gBACjD,IAAI,gBAAgB,mBAAmB;oBACrC,iBAAiB;wBAAE;wBAAY,eAAe,OAAO,OAAA;oBAAQ,CAAC;oBAC9D,oBAAoB;gBACtB;YACF;QACF;QAEA,OAAM,UAAA,EAAY;YAEhB,IAAI,UAAU,MAAA,GAAS,GAAG;gBACxB,iBAAiB;oBAAE;gBAAW,CAAC;YACjC;QACF;IACF,CAAC;AACH;AAEA,IAAM,0BAAN,MAEA;IAyBE,YAAY,EACV,KAAA,EACA,SAAA,EACA,OAAA,EACA,QAAA,EACA,YAAY,aAAA,EACZ,WAAA,EACA,MAAA,EACA,MAAA,EACA,QAAA,EACA,KAAA,EACA,UAAA,EACA,UAAA,EACA,WAAA,EACA,cAAA,EACA,cAAA,EACA,MAAA,EACA,eAAA,EACA,WAAA,EACA,gBAAA,EACA,KAAAF,IAAAA,EACA,WAAA,EACA,YAAAC,WAAAA,EACA,OAAA,EACA,OAAA,EACA,QAAA,EACA,YAAA,EACF,CA6BG;QAhFH,IAAA,CAAiB,WAAA,GAAc,IAAI,eAEjC;QACF,IAAA,CAAiB,aAAA,GAAgB,IAAI,eAEnC;QACF,IAAA,CAAiB,MAAA,GAAS,IAAI,eAE5B;QAyEA,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,gBAAA,GAAmB;QACxB,IAAA,CAAK,UAAA,GAAaA;QAKlB,IAAI;QAEJ,IAAI,sBAE+C,KAAA;QAEnD,IAAI,kBAA6C,CAAC,CAAA;QAClD,MAAM,2BAAmD,CAAC,CAAA;QAC1D,IAAI,uBAAiD,KAAA;QACrD,IAAI,qBAAqD,KAAA;QACzD,IAAI,kBAAgD,CAAC;QACrD,IAAI,mBAAuC,CAAC,CAAA;QAC5C,MAAM,gBAAqC,CAAC,CAAA;QAE5C,IAAI;QAEJ,MAAM,iBAAiB,IAAI,gBAGzB;YACA,MAAM,WAAU,KAAA,EAAO,UAAA,EAAY;gBACjC,WAAW,OAAA,CAAQ,KAAK;gBAExB,MAAM,EAAE,IAAA,CAAK,CAAA,GAAI;gBAEjB,IACE,KAAK,IAAA,KAAS,UACd,KAAK,IAAA,KAAS,eACd,KAAK,IAAA,KAAS,YACd,KAAK,IAAA,KAAS,eACd,KAAK,IAAA,KAAS,iBACd,KAAK,IAAA,KAAS,+BACd,KAAK,IAAA,KAAS,mBACd;oBACA,MAAA,CAAM,WAAA,OAAA,KAAA,IAAA,QAAU;wBAAE,OAAO;oBAAK,EAAA;gBAChC;gBAEA,IAAI,KAAK,IAAA,KAAS,SAAS;oBACzB,MAAM,QAAQ;wBAAE,OAAO,iBAAiB,KAAK,KAAK;oBAAE,CAAC;gBACvD;gBAEA,IAAI,KAAK,IAAA,KAAS,QAAQ;oBACxB,MAAM,gBAAgB,eAAA,CAAgB,gBAAgB,MAAA,GAAS,CAAC,CAAA;oBAChE,IAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,IAAA,MAAS,QAAQ;wBAClC,cAAc,IAAA,IAAQ,KAAK,IAAA;oBAC7B,OAAO;wBACL,gBAAgB,IAAA,CAAK;4BAAE,MAAM;4BAAQ,MAAM,KAAK,IAAA;wBAAK,CAAC;oBACxD;gBACF;gBAEA,IAAI,KAAK,IAAA,KAAS,aAAa;oBAC7B,IAAI,uBAAuB,MAAM;wBAC/B,sBAAsB;4BACpB,MAAM;4BACN,MAAM,KAAK,IAAA;4BACX,kBAAkB,KAAK,gBAAA;wBACzB;wBACA,gBAAgB,IAAA,CAAK,mBAAmB;oBAC1C,OAAO;wBACL,oBAAoB,IAAA,IAAQ,KAAK,IAAA;wBACjC,oBAAoB,gBAAA,GAAmB,KAAK,gBAAA;oBAC9C;gBACF;gBAEA,IACE,KAAK,IAAA,KAAS,2BACd,uBAAuB,MACvB;oBACA,sBAAsB,KAAA;gBACxB;gBAEA,IAAI,KAAK,IAAA,KAAS,QAAQ;oBACxB,gBAAgB,IAAA,CAAK;wBAAE,MAAM;wBAAQ,MAAM,KAAK,IAAA;oBAAK,CAAC;gBACxD;gBAEA,IAAI,KAAK,IAAA,KAAS,UAAU;oBAC1B,gBAAgB,IAAA,CAAK,IAAI;gBAC3B;gBAEA,IAAI,KAAK,IAAA,KAAS,aAAa;oBAC7B,gBAAgB,IAAA,CAAK,IAAI;gBAC3B;gBAEA,IAAI,KAAK,IAAA,KAAS,eAAe;oBAC/B,gBAAgB,IAAA,CAAK,IAAI;gBAC3B;gBAEA,IAAI,KAAK,IAAA,KAAS,cAAc;oBAC9B,kBAAkB,KAAK,OAAA;oBACvB,mBAAmB,KAAK,QAAA;gBAC1B;gBAEA,IAAI,KAAK,IAAA,KAAS,eAAe;oBAC/B,MAAM,eAAe,mBAAmB;wBACtC,SAAS;wBACT,OAAO,SAAA,OAAA,QAAU,CAAC;oBACpB,CAAC;oBAGD,MAAM,oBAAuC,IAAI,kBAAkB;wBACjE,SAAS;wBACT,cAAc,KAAK,YAAA;wBACnB,OAAO,KAAK,KAAA;wBACZ,UAAU;wBACV,SAAS;wBACT,UAAU;4BACR,GAAG,KAAK,QAAA;4BACR,UAAU,CAAC;mCAAG,0BAA0B;mCAAG,YAAY;6BAAA;wBACzD;wBACA,kBAAkB,KAAK,gBAAA;oBACzB,CAAC;oBAED,MAAA,CAAM,gBAAA,OAAA,KAAA,IAAA,aAAe,kBAAA;oBAErB,cAAc,IAAA,CAAK,iBAAiB;oBAEpC,kBAAkB,CAAC,CAAA;oBACnB,sBAAsB,KAAA;oBAEtB,yBAAyB,IAAA,CAAK,GAAG,YAAY;oBAI7C,WAAW,OAAA,CAAQ;gBACrB;gBAEA,IAAI,KAAK,IAAA,KAAS,UAAU;oBAC1B,qBAAqB,KAAK,UAAA;oBAC1B,uBAAuB,KAAK,YAAA;gBAC9B;YACF;YAEA,MAAM,OAAM,UAAA,EAAY;gBACtB,IAAI;oBACF,IAAI,cAAc,MAAA,KAAW,GAAG;wBAC9B;oBACF;oBAGA,MAAM,eAAe,wBAAA,OAAA,uBAAwB;oBAC7C,MAAM,aAAa,sBAAA,OAAA,qBAAsB;wBACvC,aAAa,KAAA;wBACb,cAAc,KAAA;wBACd,aAAa,KAAA;oBACf;oBAGA,KAAK,aAAA,CAAc,OAAA,CAAQ,YAAY;oBACvC,KAAK,WAAA,CAAY,OAAA,CAAQ,UAAU;oBAGnC,KAAK,MAAA,CAAO,OAAA,CAAQ,aAAa;oBAGjC,MAAM,YAAY,aAAA,CAAc,cAAc,MAAA,GAAS,CAAC,CAAA;oBACxD,MAAA,CAAM,YAAA,OAAA,KAAA,IAAA,SAAW;wBACf;wBACA;wBACA,OAAO,UAAU,KAAA;wBACjB,SAAS,UAAU,OAAA;wBACnB,MAAM,UAAU,IAAA;wBAChB,eAAe,UAAU,aAAA;wBACzB,WAAW,UAAU,SAAA;wBACrB,OAAO,UAAU,KAAA;wBACjB,SAAS,UAAU,OAAA;wBACnB,WAAW,UAAU,SAAA;wBACrB,aAAa,UAAU,WAAA;wBACvB,SAAS,UAAU,OAAA;wBACnB,UAAU,UAAU,QAAA;wBACpB,UAAU,UAAU,QAAA;wBACpB,kBAAkB,UAAU,gBAAA;wBAC5B,OAAO;oBACT,EAAA;oBAGA,SAAS,aAAA,CACP,0BAA0B;wBACxB;wBACA,YAAY;4BACV,4BAA4B;4BAC5B,oBAAoB;gCAAE,QAAQ,IAAM,UAAU,IAAA;4BAAK;4BACnD,yBAAyB;gCACvB,QAAQ,MAAG;oCA3uB7B,IAAAE;oCA4uBoB,OAAA,CAAA,CAAAA,OAAA,UAAU,SAAA,KAAV,OAAA,KAAA,IAAAA,KAAqB,MAAA,IACjB,KAAK,SAAA,CAAU,UAAU,SAAS,IAClC,KAAA;gCAAA;4BACR;4BAEA,wBAAwB,WAAW,WAAA;4BACnC,yBAAyB,WAAW,YAAA;4BACpC,wBAAwB,WAAW,WAAA;4BACnC,4BAA4B,WAAW,eAAA;4BACvC,8BAA8B,WAAW,iBAAA;wBAC3C;oBACF,CAAC;gBAEL,EAAA,OAAS,OAAO;oBACd,WAAW,KAAA,CAAM,KAAK;gBACxB,SAAE;oBACA,SAAS,GAAA,CAAI;gBACf;YACF;QACF,CAAC;QAGD,MAAM,mBAAmB,uBAA8C;QACvE,IAAA,CAAK,SAAA,GAAY,iBAAiB,SAAA;QAClC,IAAA,CAAK,WAAA,GAAc,iBAAiB,KAAA;QAEpC,IAAI,SAAS,iBAAiB,MAAA;QAG9B,SAAS,OAAO,WAAA,CACd,IAAI,gBAA8D;YAChE,OAAM,UAAA,EAAY;gBAChB,WAAW,OAAA,CAAQ;oBAAE,MAAM;gBAAQ,CAAC;YACtC;QACF,CAAC;QAKH,KAAA,MAAW,aAAa,WAAY;YAClC,SAAS,OAAO,WAAA,CACd,UAAU;gBACR;gBACA,aAAa;oBACX,iBAAiB,SAAA,CAAU;gBAC7B;YACF,CAAC;QAEL;QAEA,IAAA,CAAK,UAAA,GAAa,OACf,WAAA,CAAY,4BAA4B,MAAM,CAAC,EAC/C,WAAA,CAAY,cAAc;QAE7B,MAAM,EAAE,UAAA,EAAY,KAAA,CAAM,CAAA,GAAI,eAAe;YAC3C,YAAY;QACd,CAAC;QAED,MAAM,SAAS,UAAU,SAAS;QAElC,MAAM,eAAe,oBAAoB,QAAQ;QAEjD,MAAM,0BAA0B,2BAA2B;YACzD;YACA;YACA;YACA,UAAU;gBAAE,GAAG,YAAA;gBAAc;YAAW;QAC1C,CAAC;QAED,MAAM,OAAO,IAAA;QAEb,WAAW;YACT,MAAM;YACN,YAAY,0BAA0B;gBACpC;gBACA,YAAY;oBACV,GAAG,sBAAsB;wBAAE,aAAa;wBAAiB;oBAAU,CAAC,CAAA;oBACpE,GAAG,uBAAA;oBAAA,6DAAA;oBAEH,aAAa;wBACX,OAAO,IAAM,KAAK,SAAA,CAAU;gCAAE;gCAAQ;gCAAQ;4BAAS,CAAC;oBAC1D;gBACF;YACF,CAAC;YACD;YACA,aAAa;YACb,IAAI,OAAM,gBAAe;gBACvB,WAAW;gBAEX,eAAe,WAAW,EACxB,WAAA,EACA,gBAAA,EACA,KAAA,EACF,EAIG;oBA70BX,IAAAA,MAAA,IAAA,IAAA;oBA80BU,MAAMC,oBAAmB,KAAK,gBAAA;oBAE9B,aAAa,IAAI,eAAqB;oBAEtC,MAAM,gBAAgB,MAAM,kBAAkB;wBAC5C;wBACA;wBACA;oBACF,CAAC;oBAED,MAAM,oBAAoB;2BACrB,cAAc,QAAA;2BACd;qBACL;oBAEA,MAAM,oBAAoB,MAAA,CAAM,eAAA,OAAA,KAAA,IAAA,YAAc;wBAC5C;wBACA,OAAO;wBACP,YAAY,cAAc,MAAA;oBAC5B,EAAA;oBAEA,MAAM,iBAAiB,MAAM,6BAA6B;wBACxD,QAAQ;4BACN,QAAA,CAAQD,OAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,MAAA,KAAnB,OAAAA,OAA6B,cAAc,MAAA;4BACnD,UAAU;wBACZ;wBACA,eAAe,MAAM,MAAM,aAAA;oBAC7B,CAAC;oBAED,MAAM,YAAY,qBAAA,CAChB,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,KAAA,KAAnB,OAAA,KAA4B;oBAG9B,MAAM,EAAE,YAAY,cAAA,EAAgB,OAAO,SAAA,CAAU,CAAA,GACnD,0BAA0B;wBACxB;wBACA,YAAA,CAAY,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,UAAA,KAAnB,OAAA,KAAiC;wBAC7C,aAAA,CAAa,KAAA,qBAAA,OAAA,KAAA,IAAA,kBAAmB,WAAA,KAAnB,OAAA,KAAkC;oBACjD,CAAC;oBAEH,MAAM,EACJ,QAAQ,EAAE,QAAAE,OAAAA,EAAQ,QAAA,EAAU,OAAA,CAAQ,CAAA,EACpC,YAAA,EACA,gBAAA,EACF,GAAI,MAAM,MAAM,IACd,WAAW;4BACT,MAAM;4BACN,YAAY,0BAA0B;gCACpC;gCACA,YAAY;oCACV,GAAG,sBAAsB;wCACvB,aAAa;wCACb;oCACF,CAAC,CAAA;oCACD,GAAG,uBAAA;oCAAA,SAAA;oCAEH,qBAAqB,UAAU,QAAA;oCAC/B,eAAe,UAAU,OAAA;oCAAA,UAAA;oCAEzB,sBAAsB;wCACpB,OAAO,IAAM,sBAAsB,cAAc;oCACnD;oCACA,mBAAmB;wCAAA,0CAAA;wCAEjB,OAAO,IAAM,aAAA,OAAA,KAAA,IAAA,UAAW,GAAA,CAAI,CAAAC,QAAQ,KAAK,SAAA,CAAUA,KAAI;oCACzD;oCACA,wBAAwB;wCACtB,OAAO,IACL,kBAAkB,OACd,KAAK,SAAA,CAAU,cAAc,IAC7B,KAAA;oCACR;oCAAA,2CAAA;oCAGA,iBAAiB,UAAU,QAAA;oCAC3B,wBAAwB,UAAU,OAAA;oCAClC,oCACE,aAAa,gBAAA;oCACf,6BAA6B,aAAa,eAAA;oCAC1C,mCACE,aAAa,eAAA;oCACf,iCAAiC,aAAa,aAAA;oCAC9C,8BAA8B,aAAa,WAAA;oCAC3C,wBAAwB,aAAa,IAAA;oCACrC,wBAAwB,aAAa,IAAA;gCACvC;4BACF,CAAC;4BACD;4BACA,aAAa;4BACb,IAAI,OAAMC,kBAAgB;gCACxB,OAAO;oCACL,kBAAkBP,KAAI;oCAAA,sBAAA;oCACtB,cAAAO;oCACA,QAAQ,MAAM,UAAU,QAAA,CAAS;wCAC/B,GAAG,YAAA;wCACH,OAAO;wCACP,YAAY;wCACZ,gBAAgB,UAAA,OAAA,KAAA,IAAA,OAAQ,cAAA;wCACxB,QAAQ;wCACR;wCACA;wCACA;wCACA,kBAAkBH;oCACpB,CAAC;gCACH;4BACF;wBACF,CAAC;oBAGH,MAAM,wBAAwB,uBAAuB;wBACnD;wBACA,iBAAiBC;wBACjB;wBACA;wBACA;wBACA,UAAU;wBACV;wBACA;oBACF,CAAC;oBAED,MAAM,cAAc,WAAA,OAAA,UAAW,CAAC;oBAChC,MAAM,gBAAwC,CAAC,CAAA;oBAC/C,MAAM,kBAA4C,CAAC,CAAA;oBACnD,IAAI;oBACJ,MAAM,cAAyC,CAAC,CAAA;oBAEhD,IAAIG,uBAE+C,KAAA;oBAEnD,IAAI,mBAAiC;oBACrC,IAAI,YAAgC;wBAClC,aAAa,KAAA;wBACb,cAAc,KAAA;wBACd,aAAa,KAAA;oBACf;oBACA,IAAI;oBACJ,IAAI,iBAAiB;oBACrB,IAAI,WAAW;oBACf,IAAI,eAAiE;wBACnE,IAAIP,YAAW;wBACf,WAAW,YAAY;wBACvB,SAAS,MAAM,OAAA;oBACjB;oBAEA,eAAe,iBAAiB,EAC9B,UAAA,EACA,KAAA,EACF,EAGG;wBACD,WAAW,OAAA,CAAQ,KAAK;wBAExB,YAAY,MAAM,IAAA;oBACpB;oBAEA,KAAK,SAAA,CACH,sBAAsB,WAAA,CACpB,IAAI,gBAGF;wBACA,MAAM,WAAU,KAAA,EAAO,UAAA,EAA2B;4BAj/BlE,IAAAE,MAAAM,KAAAC,KAAAC;4BAk/BkB,IAAI,MAAM,IAAA,KAAS,gBAAgB;gCACjC,WAAW,MAAM,QAAA;gCACjB;4BACF;4BAEA,IAAI,gBAAgB;gCAElB,MAAM,iBAAiBX,KAAI,IAAI;gCAE/B,iBAAiB;gCAEjB,aAAa,QAAA,CAAS,wBAAwB;oCAC5C,8BAA8B;gCAChC,CAAC;gCAED,aAAa,aAAA,CAAc;oCACzB,8BAA8B;gCAChC,CAAC;gCAGD,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,SAAS;oCACT,UAAU,YAAA,OAAA,WAAY,CAAC,CAAA;gCACzB,CAAC;4BACH;4BAGA,IAAI,MAAM,IAAA,KAAS,UAAU,MAAM,IAAA,CAAK,MAAA,KAAW,GAAG;gCACpD;4BACF;4BAEA,MAAM,YAAY,MAAM,IAAA;4BACxB,OAAQ,WAAW;gCACjB,KAAK;oCAAQ;wCACX,MAAM,iBAAiB;4CAAE;4CAAY;wCAAM,CAAC;wCAC5C;oCACF;gCAEA,KAAK;oCAAa;wCAChB,WAAW,OAAA,CAAQ,KAAK;wCAExB,IAAIQ,wBAAuB,MAAM;4CAC/BA,uBAAsB;gDACpB,MAAM;gDACN,MAAM,MAAM,IAAA;gDACZ,kBAAkB,MAAM,gBAAA;4CAC1B;4CACA,YAAY,IAAA,CAAKA,oBAAmB;wCACtC,OAAO;4CACLA,qBAAoB,IAAA,IAAQ,MAAM,IAAA;4CAClCA,qBAAoB,gBAAA,GAClB,MAAM,gBAAA;wCACV;wCAEA;oCACF;gCAEA,KAAK;oCAAyB;wCAC5BA,uBAAsB,KAAA;wCACtB,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA,KAAK;oCAAa;wCAChB,WAAW,OAAA,CAAQ,KAAK;wCAExB,cAAc,IAAA,CAAK,KAAK;wCACxB,YAAY,IAAA,CAAK,KAAK;wCACtB;oCACF;gCAEA,KAAK;oCAAe;wCAClB,WAAW,OAAA,CAAQ,KAAK;wCAExB,gBAAgB,IAAA,CAAK,KAAK;wCAC1B,YAAY,IAAA,CAAK,KAAK;wCACtB;oCACF;gCAEA,KAAK;oCAAqB;wCACxB,eAAe;4CACb,IAAA,CAAIL,OAAA,MAAM,EAAA,KAAN,OAAAA,OAAY,aAAa,EAAA;4CAC7B,WAAA,CAAWM,MAAA,MAAM,SAAA,KAAN,OAAAA,MAAmB,aAAa,SAAA;4CAC3C,SAAA,CAASC,MAAA,MAAM,OAAA,KAAN,OAAAA,MAAiB,aAAa,OAAA;wCACzC;wCACA;oCACF;gCAEA,KAAK;oCAAU;wCAGb,YAAY,MAAM,KAAA;wCAClB,mBAAmB,MAAM,YAAA;wCACzB,uBAAuB,MAAM,gBAAA;wCAI7B,MAAM,aAAaV,KAAI,IAAI;wCAC3B,aAAa,QAAA,CAAS,kBAAkB;wCACxC,aAAa,aAAA,CAAc;4CACzB,0BAA0B;4CAC1B,wCACG,MAAA,CAAA,CAAQW,MAAA,UAAU,YAAA,KAAV,OAAAA,MAA0B,CAAA,IAAM;wCAC7C,CAAC;wCAED;oCACF;gCAEA,KAAK;oCAAQ;wCACX,YAAY,IAAA,CAAK,KAAK;wCACtB,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA,KAAK;oCAAU;wCACb,YAAY,IAAA,CAAK,KAAK;wCACtB,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA,KAAK;oCAA6B;wCAChC,MAAML,QAAO,SAAA,OAAA,KAAA,IAAA,KAAA,CAAQ,MAAM,QAAA,CAAA;wCAE3B,IAAA,CAAIA,SAAA,OAAA,KAAA,IAAAA,MAAM,oBAAA,KAAwB,MAAM;4CACtC,MAAMA,MAAK,oBAAA,CAAqB;gDAC9B,YAAY,MAAM,UAAA;gDAClB,UAAU;gDACV;4CACF,CAAC;wCACH;wCAEA,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA,KAAK;oCAAmB;wCACtB,MAAMA,QAAO,SAAA,OAAA,KAAA,IAAA,KAAA,CAAQ,MAAM,QAAA,CAAA;wCAE3B,IAAA,CAAIA,SAAA,OAAA,KAAA,IAAAA,MAAM,oBAAA,KAAwB,MAAM;4CACtC,MAAMA,MAAK,oBAAA,CAAqB;gDAC9B,eAAe,MAAM,aAAA;gDACrB,YAAY,MAAM,UAAA;gDAClB,UAAU;gDACV;4CACF,CAAC;wCACH;wCAEA,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA,KAAK;oCAAS;wCACZ,WAAW,OAAA,CAAQ,KAAK;wCACxB,mBAAmB;wCACnB;oCACF;gCAEA,KAAK;oCAAO;wCACV,WAAW,OAAA,CAAQ,KAAK;wCACxB;oCACF;gCAEA;oCAAS;wCACP,MAAM,kBAAyB;wCAC/B,MAAM,IAAI,MAAM,CAAA,oBAAA,EAAuB,eAAe,EAAE;oCAC1D;4BACF;wBACF;wBAAA,8FAAA;wBAGA,MAAM,OAAM,UAAA,EAAY;4BACtB,MAAM,oBACJ,cAAc,MAAA,GAAS,IACnB,KAAK,SAAA,CAAU,aAAa,IAC5B,KAAA;4BAGN,IAAI;gCACF,aAAa,aAAA,CACX,0BAA0B;oCACxB;oCACA,YAAY;wCACV,4BAA4B;wCAC5B,oBAAoB;4CAAE,QAAQ,IAAM;wCAAS;wCAC7C,yBAAyB;4CACvB,QAAQ,IAAM;wCAChB;wCACA,kBAAkB,aAAa,EAAA;wCAC/B,qBAAqB,aAAa,OAAA;wCAClC,yBACE,aAAa,SAAA,CAAU,WAAA,CAAY;wCAErC,wBAAwB,UAAU,WAAA;wCAClC,yBAAyB,UAAU,YAAA;wCACnC,wBAAwB,UAAU,WAAA;wCAClC,4BAA4B,UAAU,eAAA;wCACtC,8BACE,UAAU,iBAAA;wCAAA,2CAAA;wCAGZ,kCAAkC;4CAAC,gBAAgB;yCAAA;wCACnD,sBAAsB,aAAa,EAAA;wCACnC,yBAAyB,aAAa,OAAA;wCACtC,6BAA6B,UAAU,WAAA;wCACvC,8BAA8B,UAAU,YAAA;oCAC1C;gCACF,CAAC;4BAEL,EAAA,OAAS,OAAO,CAEhB,SAAE;gCAEA,aAAa,GAAA,CAAI;4BACnB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,cAAc;gCACd,OAAO;gCACP,kBAAkB;gCAClB,UAAU;oCACR,GAAG,YAAA;oCACH,SAAS,YAAA,OAAA,KAAA,IAAA,SAAU,OAAA;gCACrB;4BACF,CAAC;4BAED,MAAM,gBAAgB,sBAAsB,OAAO,SAAS;4BAI5D,MAAM,WAAW,OAAA;4BAEjB,IACE,cAAc,MAAA,GAAS,KAAA,uCAAA;4BAEvB,gBAAgB,MAAA,KAAW,cAAc,MAAA,IAAA,0CAAA;4BAEzC,CAAE,MAAM,mBAAmB;gCACzB;gCACA,OAAO;4BACT,CAAC,GACD;gCAEA,iBAAiB,IAAA,IACZ,mBAAmB;oCACpB,SAAS;oCACT,OAAO,SAAA,OAAA,QAAU,CAAC;gCACpB,CAAC;gCAGH,MAAM,WAAW;oCACf,aAAa,cAAc;oCAC3B;oCACA,OAAO;gCACT,CAAC;4BACH,OAAO;gCACL,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,cAAc;oCACd,YAAY;gCACd,CAAC;gCAED,KAAK,WAAA,CAAY;4BACnB;wBACF;oBACF,CAAC;gBAGP;gBAGA,MAAM,WAAW;oBACf,aAAa;oBACb,kBAAkB,CAAC,CAAA;oBACnB,OAAO;wBACL,aAAa,KAAA;wBACb,cAAc,KAAA;wBACd,aAAa,KAAA;oBACf;gBACF,CAAC;YACH;QACF,CAAC,EAAE,KAAA,CAAM,CAAA,UAAS;YAEhB,KAAK,SAAA,CACH,IAAI,eAAe;gBACjB,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAS;oBAAM,CAAC;oBAC3C,WAAW,KAAA,CAAM;gBACnB;YACF,CAAC;YAEH,KAAK,WAAA,CAAY;QACnB,CAAC;IACH;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,MAAA,CAAO,OAAA;IACrB;IAEA,IAAY,YAAY;QACtB,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,CAAA,QAAS,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAC;IACzD;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,OAAO;IACjD;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,QAAQ;IAClD;IAEA,IAAI,mBAAmB;QACrB,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,gBAAgB;IAC1D;IAEA,IAAI,OAAO;QACT,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,IAAI;IAC9C;IAEA,IAAI,gBAAgB;QAClB,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,aAAa;IACvD;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,SAAS;IACnD;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,OAAO;IACjD;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,KAAK;IAC/C;IAEA,IAAI,YAAY;QACd,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,SAAS;IACnD;IAEA,IAAI,cAAc;QAChB,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,WAAW;IACrD;IAEA,IAAI,QAAQ;QACV,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,KAAK;IAC/C;IAEA,IAAI,UAAU;QACZ,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,OAAO;IACjD;IAEA,IAAI,WAAW;QACb,OAAO,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,CAAA,OAAQ,KAAK,QAAQ;IAClD;IAEA,IAAI,aAAa;QACf,OAAO,IAAA,CAAK,WAAA,CAAY,OAAA;IAC1B;IAEA,IAAI,eAAe;QACjB,OAAO,IAAA,CAAK,aAAA,CAAc,OAAA;IAC5B;IAAA;;;;;;;KAAA,GAUQ,YAAY;QAClB,MAAM,CAAC,SAAS,OAAO,CAAA,GAAI,IAAA,CAAK,UAAA,CAAW,GAAA,CAAI;QAC/C,IAAA,CAAK,UAAA,GAAa;QAClB,OAAO;IACT;IAEA,IAAI,aAA0C;QAC5C,OAAO,0BACL,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CACf,IAAI,gBAAmE;YACrE,WAAU,EAAE,IAAA,CAAK,CAAA,EAAG,UAAA,EAAY;gBAC9B,IAAI,KAAK,IAAA,KAAS,QAAQ;oBACxB,WAAW,OAAA,CAAQ,KAAK,IAAI;gBAC9B;YACF;QACF,CAAC;IAGP;IAEA,IAAI,aAAyD;QAC3D,OAAO,0BACL,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CACf,IAAI,gBAGF;YACA,WAAU,EAAE,IAAA,CAAK,CAAA,EAAG,UAAA,EAAY;gBAC9B,WAAW,OAAA,CAAQ,IAAI;YACzB;QACF,CAAC;IAGP;IAEA,MAAM,cAAc,OAAA,EAA+C;QAz4CrE,IAAAH;QA04CI,IAAI;YACF,MAAM,cAAc;gBAClB,QAAQ,IAAA,CAAK,UAAA;gBACb,SAAS,WAAA,OAAA,KAAA,IAAA,QAAS,OAAA;YACpB,CAAC;QACH,EAAA,OAAS,OAAO;YACd,CAAAA,OAAA,WAAA,OAAA,KAAA,IAAA,QAAS,OAAA,KAAT,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,SAAmB;QACrB;IACF;IAEA,IAAI,mCAAwE;QAC1E,IAAI,IAAA,CAAK,MAAA,IAAU,MAAM;YACvB,MAAM,IAAI,uBAAuB;QACnC;QAEA,OAAO,0BACL,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CACf,IAAI,gBAGF;YACA,WAAU,EAAE,aAAA,CAAc,CAAA,EAAG,UAAA,EAAY;gBACvC,IAAI,iBAAiB,MAAM;oBACzB,WAAW,OAAA,CAAQ,aAAa;gBAClC;YACF;QACF,CAAC;IAGP;IAEA,kBAAgD,EAC9C,YAAA,EACA,mBAAmB,CAAC,CAAA,EACpB,QAAA,EACA,eAAA,EACA,gBAAgB,KAAA,EAChB,cAAc,KAAA,EACd,YAAY,IAAA,EACZ,aAAa,IAAA,EACb,UAAU,IAAM,oBAAA,EAClB,GAAwC,CAAC,CAAA,EAEvC;QACA,MAAM,cAAc,gBAAA,CAAiB,iBAAiB,MAAA,GAAS,CAAC,CAAA;QAChE,MAAM,iBAAA,CAAiB,eAAA,OAAA,KAAA,IAAA,YAAa,IAAA,MAAS;QAC7C,MAAM,YAAY,iBAAiB,YAAY,EAAA,GAAK;QAEpD,MAAM,aAAa,IAAA,CAAK,UAAA,CAAW,WAAA,CACjC,IAAI,gBAGF;YACA,WAAW,OAAO,MAAM,eAAe;gBACrC,MAAM,WAAW,KAAK,IAAA;gBACtB,OAAQ,UAAU;oBAChB,KAAK;wBAAQ;4BACX,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,MAAM,KAAK,IAAA;4BACb,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAa;4BAChB,IAAI,eAAe;gCACjB,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,MAAM,KAAK,IAAA;oCACX,kBAAkB,KAAK,gBAAA;gCACzB,CAAC;4BACH;4BACA;wBACF;oBAEA,KAAK;wBAAyB;4BAC5B,IAAI,eAAe;gCACjB,WAAW,OAAA,CAAQ;oCAAE,MAAM;gCAAwB,CAAC;4BACtD;4BACA;wBACF;oBAEA,KAAK;wBAAQ;4BACX,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,WAAW,KAAK,IAAA,CAAK,SAAA;gCACrB,KAAK,CAAA,KAAA,EAAQ,KAAK,IAAA,CAAK,SAAS,CAAA,QAAA,EAAW,KAAK,IAAA,CAAK,MAAM,EAAA;4BAC7D,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAU;4BACb,IAAI,eAAe,KAAK,UAAA,KAAe,OAAO;gCAC5C,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,UAAU,KAAK,EAAA;oCACf,KAAK,KAAK,GAAA;oCACV,OAAO,KAAK,KAAA;oCACZ,kBAAkB,KAAK,gBAAA;gCACzB,CAAC;4BACH;4BAEA,IAAI,eAAe,KAAK,UAAA,KAAe,YAAY;gCACjD,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,UAAU,KAAK,EAAA;oCACf,WAAW,KAAK,SAAA;oCAChB,OAAO,KAAK,KAAA;oCACZ,UAAU,KAAK,QAAA;oCACf,kBAAkB,KAAK,gBAAA;gCACzB,CAAC;4BACH;4BACA;wBACF;oBAEA,KAAK;wBAA6B;4BAChC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,KAAK,UAAA;gCACjB,UAAU,KAAK,QAAA;4BACjB,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAmB;4BACtB,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,KAAK,UAAA;gCACjB,eAAe,KAAK,aAAA;4BACtB,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAa;4BAChB,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,KAAK,UAAA;gCACjB,UAAU,KAAK,QAAA;gCACf,MAAM,KAAK,IAAA;4BACb,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAe;4BAClB,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,KAAK,UAAA;gCACjB,QAAQ,KAAK,MAAA;4BACf,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAS;4BACZ,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,WAAW,QAAQ,KAAK,KAAK;4BAC/B,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAc;4BACjB,MAAM,WAAW,mBAAA,OAAA,KAAA,IAAA,gBAAkB;gCAAE;4BAAK;4BAC1C,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN;4BACF,CAAC;4BACD;wBACF;oBAEA,KAAK;wBAAe;4BAClB,MAAM,WAAW,mBAAA,OAAA,KAAA,IAAA,gBAAkB;gCAAE;4BAAK;4BAC1C,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN;4BACF,CAAC;4BAED;wBACF;oBAEA,KAAK;wBAAS;4BACZ,IAAI,WAAW;gCACb,MAAM,WAAW,mBAAA,OAAA,KAAA,IAAA,gBAAkB;oCAAE;gCAAK;gCAC1C,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN;oCACA;gCACF,CAAC;4BACH;4BACA;wBACF;oBAEA,KAAK;wBAAU;4BACb,IAAI,YAAY;gCACd,MAAM,WAAW,mBAAA,OAAA,KAAA,IAAA,gBAAkB;oCAAE;gCAAK;gCAC1C,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN;gCACF,CAAC;4BACH;4BACA;wBACF;oBAEA,KAAK;wBAAO;4BAGV;wBACF;oBAEA;wBAAS;4BACP,MAAM,kBAAyB;4BAC/B,MAAM,IAAI,MAAM,CAAA,oBAAA,EAAuB,eAAe,EAAE;wBAC1D;gBACF;YACF;QACF,CAAC;QAGH,OAAO,4BAAwC;YAC7C,QAAQ;YACR,cAAc,aAAA,OAAA,YAAa,IAAA,CAAK,UAAA,CAAW;YAC3C;YACA;QACF,CAAC;IACH;IAEA,8BACE,QAAA,EACA,EACE,YAAA,EACA,gBAAA,EACA,QAAA,EACA,eAAA,EACA,aAAA,EACA,WAAA,EACA,UAAA,EACA,SAAA,EACA,OAAA,EACA,GAAG,MACL,GAAuD,CAAC,CAAA,EACxD;QACA,8BAA8B;YAC5B;YACA,QAAQ,IAAA,CAAK,iBAAA,CAAkB;gBAC7B;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;YACF,CAAC;YACD,GAAG,IAAA;QACL,CAAC;IACH;IAEA,yBAAyB,QAAA,EAA0B,IAAA,EAAqB;QACtE,yBAAyB;YACvB;YACA,YAAY,IAAA,CAAK,UAAA;YACjB,GAAG,IAAA;QACL,CAAC;IACH;IAEA,0BAAwD,EACtD,YAAA,EACA,gBAAA,EACA,QAAA,EACA,eAAA,EACA,aAAA,EACA,WAAA,EACA,UAAA,EACA,SAAA,EACA,OAAA,EACA,GAAG,MACL,GAAuD,CAAC,CAAA,EAAa;QACnE,OAAO,8BAA8B;YACnC,QAAQ,IAAA,CAAK,iBAAA,CAAkB;gBAC7B;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;YACF,CAAC;YACD,GAAG,IAAA;QACL,CAAC;IACH;IAEA,qBAAqB,IAAA,EAA+B;QAClD,OAAO,yBAAyB;YAC9B,YAAY,IAAA,CAAK,UAAA;YACjB,GAAG,IAAA;QACL,CAAC;IACH;AACF;;AE5qDO,SAAS,0BAA0B,EACxC,QAAA,EACF,EAgB8B;IAC5B,OAAO;QACL,mBAAmB;QACnB,iBAAiB,OAAO,EAAE,MAAA,CAAO,CAAA,KAAM;YACrC,OAAO,aAAa,UAAU,MAAM;QACtC;IACF;AACF;;AC9BO,SAAS,uBACdS,KAAAA,EACA,YAAA,EACe;IAEf,IAAI,aAAa,MAAA,KAAW,GAAG;QAC7B,OAAO;IACT;IAGA,MAAM,cAAcA,MAAK,OAAA,CAAQ,YAAY;IAC7C,IAAI,gBAAgB,CAAA,GAAI;QACtB,OAAO;IACT;IAIA,IAAA,IAAS,IAAIA,MAAK,MAAA,GAAS,GAAG,KAAK,GAAG,IAAK;QACzC,MAAM,SAASA,MAAK,SAAA,CAAU,CAAC;QAC/B,IAAI,aAAa,UAAA,CAAW,MAAM,GAAG;YACnC,OAAO;QACT;IACF;IAEA,OAAO;AACT;;ACdO,SAAS,2BAA2B,EACzC,OAAA,EACA,YAAY,IAAA,EACZ,qBAAqB,KAAA,EACvB,EAI8B;IAC5B,MAAM,aAAa,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAA;IAC9B,MAAM,aAAa,CAAA,EAAA,EAAM,OAAO,CAAA,CAAA,CAAA;IAEhC,OAAO;QACL,mBAAmB;QACnB,cAAc,OAAO,EAAE,UAAA,CAAW,CAAA,KAAM;YACtC,MAAM,EAAE,OAAA,EAAS,GAAG,KAAK,CAAA,GAAI,MAAM,WAAW;YAE9C,MAAM,qBAA+C,CAAC,CAAA;YACtD,KAAA,MAAW,QAAQ,QAAS;gBAC1B,IAAI,KAAK,IAAA,KAAS,QAAQ;oBACxB,mBAAmB,IAAA,CAAK,IAAI;oBAC5B;gBACF;gBAEA,MAAMC,QAAO,qBAAqB,aAAa,KAAK,IAAA,GAAO,KAAK,IAAA;gBAEhE,MAAM,SAAS,IAAI,OAAO,GAAG,UAAU,CAAA,KAAA,EAAQ,UAAU,EAAA,EAAI,IAAI;gBACjE,MAAM,UAAU,MAAM,IAAA,CAAKA,MAAK,QAAA,CAAS,MAAM,CAAC;gBAEhD,IAAI,CAAC,QAAQ,MAAA,EAAQ;oBACnB,mBAAmB,IAAA,CAAK,IAAI;oBAC5B;gBACF;gBAEA,MAAM,gBAAgB,QAAQ,GAAA,CAAI,CAAA,QAAS,KAAA,CAAM,CAAC,CAAC,EAAE,IAAA,CAAK,SAAS;gBAEnE,IAAI,uBAAuBA;gBAC3B,IAAA,IAAS,IAAI,QAAQ,MAAA,GAAS,GAAG,KAAK,GAAG,IAAK;oBAC5C,MAAM,QAAQ,OAAA,CAAQ,CAAC,CAAA;oBAEvB,MAAM,cAAc,qBAAqB,KAAA,CAAM,GAAG,MAAM,KAAK;oBAC7D,MAAM,aAAa,qBAAqB,KAAA,CACtC,MAAM,KAAA,GAAS,KAAA,CAAM,CAAC,CAAA,CAAE,MAAA;oBAG1B,uBACE,cAAA,CACC,YAAY,MAAA,GAAS,KAAK,WAAW,MAAA,GAAS,IAAI,YAAY,EAAA,IAC/D;gBACJ;gBAEA,mBAAmB,IAAA,CAAK;oBACtB,MAAM;oBACN,MAAM;gBACR,CAAC;gBAED,mBAAmB,IAAA,CAAK;oBACtB,MAAM;oBACN,MAAM;gBACR,CAAC;YACH;YAEA,OAAO;gBAAE,SAAS;gBAAoB,GAAG,IAAA;YAAK;QAChD;QAEA,YAAY,OAAO,EAAE,QAAA,CAAS,CAAA,KAAM;YAClC,MAAM,EAAE,MAAA,EAAQ,GAAG,KAAK,CAAA,GAAI,MAAM,SAAS;YAE3C,IAAI,mBAAmB;YACvB,IAAI,cAAc;YAClB,IAAI,cAAc;YAClB,IAAI,cAAc;YAClB,IAAI,SAAS;YAEb,OAAO;gBACL,QAAQ,OAAO,WAAA,CACb,IAAI,gBAGF;oBACA,WAAW,CAAC,OAAO,eAAe;wBAChC,IAAI,MAAM,IAAA,KAAS,QAAQ;4BACzB,WAAW,OAAA,CAAQ,KAAK;4BACxB;wBACF;wBAEA,UAAU,MAAM,IAAA;wBAEhB,SAAS,QAAQA,KAAAA,EAAc;4BAC7B,IAAIA,MAAK,MAAA,GAAS,GAAG;gCACnB,MAAM,SACJ,eAAA,CACC,cAAc,CAAC,mBAAmB,CAAC,WAAA,IAChC,YACA;gCAEN,WAAW,OAAA,CACT,cACI;oCACE,MAAM;oCACN,MAAM,SAASA;gCACjB,IACA;oCACE,MAAM;oCACN,MAAM,SAASA;gCACjB;gCAEN,cAAc;gCAEd,IAAI,aAAa;oCACf,mBAAmB;gCACrB,OAAO;oCACL,cAAc;gCAChB;4BACF;wBACF;wBAEA,GAAG;4BACD,MAAM,UAAU,cAAc,aAAa;4BAC3C,MAAM,aAAa,uBAAuB,QAAQ,OAAO;4BAGzD,IAAI,cAAc,MAAM;gCACtB,QAAQ,MAAM;gCACd,SAAS;gCACT;4BACF;4BAGA,QAAQ,OAAO,KAAA,CAAM,GAAG,UAAU,CAAC;4BAEnC,MAAM,iBACJ,aAAa,QAAQ,MAAA,IAAU,OAAO,MAAA;4BAExC,IAAI,gBAAgB;gCAClB,SAAS,OAAO,KAAA,CAAM,aAAa,QAAQ,MAAM;gCAGjD,IAAI,aAAa;oCACf,WAAW,OAAA,CAAQ;wCAAE,MAAM;oCAAwB,CAAC;gCACtD;gCAEA,cAAc,CAAC;gCACf,cAAc;4BAChB,OAAO;gCACL,SAAS,OAAO,KAAA,CAAM,UAAU;gCAChC;4BACF;wBACF,QAAS,KAAA;oBACX;gBACF,CAAC;gBAEH,GAAG,IAAA;YACL;QACF;IACF;AACF;;ACnKO,SAAS,8BAAyD;IACvE,OAAO;QACL,mBAAmB;QACnB,YAAY,OAAO,EAAE,UAAA,CAAW,CAAA,KAAM;YACpC,MAAM,SAAS,MAAM,WAAW;YAEhC,MAAM,kBAAkB,IAAI,eAA0C;gBACpE,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN,UAAU,OAAO,QAAA;oBACnB,CAAC;oBAED,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAqB,GAAG,OAAO,QAAA;oBAAS,CAAC;oBAEpE,KAAA,MAAW,QAAQ,OAAO,OAAA,CAAS;wBACjC,WAAW,OAAA,CAAQ,IAAI;oBACzB;oBAEA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN,cAAc,OAAO,YAAA;wBACrB,OAAO,OAAO,KAAA;wBACd,kBAAkB,OAAO,gBAAA;oBAC3B,CAAC;oBAED,WAAW,KAAA,CAAM;gBACnB;YACF,CAAC;YAED,OAAO;gBACL,QAAQ;gBACR,SAAS,OAAO,OAAA;gBAChB,UAAU,OAAO,QAAA;YACnB;QACF;IACF;AACF;;AC1BO,IAAM,oBAAoB,CAAC,EAChC,KAAA,EACA,YAAY,aAAA,EACZ,OAAA,EACA,UAAA,EACF,KAKuB;IACrB,OAAO,QAAQ,aAAa,EACzB,OAAA,CAAQ,EACR,MAAA,CAAO,CAAC,cAAc,eAAe;QACpC,OAAO,OAAO;YAAE,OAAO;YAAc;YAAY;YAAS;QAAW,CAAC;IACxE,GAAG,KAAK;AACZ;AAEA,IAAM,SAAS,CAAC,EACd,KAAA,EACA,YAAY,EAAE,eAAA,EAAiB,YAAA,EAAc,UAAA,CAAW,CAAA,EACxD,OAAA,EACA,UAAA,EACF,KAKuB;IACrB,eAAe,YAAY,EACzB,MAAA,EACA,IAAA,EACF,EAGG;QACD,OAAO,kBAAkB,MAAM,gBAAgB;YAAE;YAAQ;QAAK,CAAC,IAAI;IACrE;IAEA,OAAO;QACL,sBAAsB;QAEtB,UAAU,cAAA,OAAA,aAAc,MAAM,QAAA;QAC9B,SAAS,WAAA,OAAA,UAAW,MAAM,OAAA;QAAA,8DAAA;QAG1B,IAAI,iBAAkD;YACpD,OAAO,MAAM,aAAA;QACf;QAEA,MAAM,YACJ,MAAA,EAC6D;YAC7D,MAAM,oBAAoB,MAAM,YAAY;gBAAE;gBAAQ,MAAM;YAAW,CAAC;YACxE,MAAM,aAAa,UAAY,MAAM,UAAA,CAAW,iBAAiB;YACjE,MAAM,WAAW,UAAY,MAAM,QAAA,CAAS,iBAAiB;YAC7D,OAAO,eACH,aAAa;gBACX;gBACA;gBACA,QAAQ;gBACR;YACF,CAAC,IACD,WAAW;QACjB;QAEA,MAAM,UACJ,MAAA,EAC2D;YAC3D,MAAM,oBAAoB,MAAM,YAAY;gBAAE;gBAAQ,MAAM;YAAS,CAAC;YACtE,MAAM,aAAa,UAAY,MAAM,UAAA,CAAW,iBAAiB;YACjE,MAAM,WAAW,UAAY,MAAM,QAAA,CAAS,iBAAiB;YAC7D,OAAO,aACH,WAAW;gBAAE;gBAAY;gBAAU,QAAQ;gBAAmB;YAAM,CAAC,IACrE,SAAS;QACf;IACF;AACF;;AC5EO,SAAS,eAId,EACA,cAAA,EACA,mBAAA,EACA,WAAA,EACA,gBAAA,EACF,EAWE;IACA,OAAO;QACL,eAAc,OAAA,EAA2D;YACvE,IAAI,kBAAkB,QAAQ,WAAW,gBAAgB;gBACvD,OAAO,cAAA,CAAe,OAAO,CAAA;YAC/B;YAEA,IAAI,kBAAkB;gBACpB,OAAO,iBAAiB,aAAA,CAAc,OAAO;YAC/C;YAEA,MAAM,8JAAIC,mBAAAA,CAAiB;gBAAE;gBAAS,WAAW;YAAgB,CAAC;QACpE;QAEA,oBACE,OAAA,EAC0B;YAC1B,IAAI,uBAAuB,QAAQ,WAAW,qBAAqB;gBACjE,OAAO,mBAAA,CAAoB,OAAO,CAAA;YACpC;YAEA,IAAI,kBAAkB;gBACpB,OAAO,iBAAiB,kBAAA,CAAmB,OAAO;YACpD;YAEA,MAAM,IAAIA,6KAAAA,CAAiB;gBAAE;gBAAS,WAAW;YAAqB,CAAC;QACzE;QAEA,YAAW,OAAA,EAAqD;YAC9D,IAAI,eAAe,QAAQ,WAAW,aAAa;gBACjD,OAAO,WAAA,CAAY,OAAO,CAAA;YAC5B;YAEA,IAAI,oBAAA,OAAA,KAAA,IAAA,iBAAkB,UAAA,EAAY;gBAChC,OAAO,iBAAiB,UAAA,CAAW,OAAO;YAC5C;YAEA,MAAM,6JAAIA,oBAAAA,CAAiB;gBAAE;gBAAS,WAAW;YAAa,CAAC;QACjE;IACF;AACF;AAKO,IAAM,8BAA8B;;ACnF3C,IAAMG,SAAO;AACb,IAAMC,WAAS,CAAA,gBAAA,EAAmBD,MAAI,EAAA;AACtC,IAAME,WAAS,OAAO,GAAA,CAAID,QAAM;AAJhC,IAAAE;AAMO,IAAM,sBAAN,cAAkCJ,6KAAAA,CAAiB;IAMxD,YAAY,EACV,OAAA,EACA,SAAA,EACA,UAAA,EACA,kBAAA,EACA,UAAU,CAAA,kBAAA,EAAqB,UAAU,CAAA,uBAAA,EAA0B,mBAAmB,IAAA,CAAK,CAAC,CAAA,CAAA,CAAA,EAC9F,CAMG;QACD,KAAA,CAAM;YAAE,WAAWC;YAAM;YAAS;YAAW;QAAQ,CAAC;QAlBxD,IAAA,CAAkBG,KAAAA,GAAU;QAoB1B,IAAA,CAAK,UAAA,GAAa;QAClB,IAAA,CAAK,kBAAA,GAAqB;IAC5B;IAEA,OAAO,WAAW,KAAA,EAA8C;QAC9D,iKAAOL,aAAAA,CAAW,SAAA,CAAU,OAAOG,QAAM;IAC3C;AACF;AA3BoBE,OAAAD;;AC2Cb,SAAS,uBAId,SAAA,EACA,EACE,YAAY,GAAA,EACd,GAEI,CAAC,CAAA,EAC2C;IAChD,MAAM,WAAW,IAAI,wBAA8C;QACjE;IACF,CAAC;IAED,KAAA,MAAW,CAAC,IAAI,QAAQ,CAAA,IAAK,OAAO,OAAA,CAAQ,SAAS,EAAG;QACtD,SAAS,gBAAA,CAAiB;YAAE;YAAI;QAAS,CAGxC;IACH;IAEA,OAAO;AACT;AAKO,IAAM,sCAAsC;AAEnD,IAAM,0BAAN,MAIA;IAIE,YAAY,EAAE,SAAA,CAAU,CAAA,CAA6B;QAHrD,IAAA,CAAQ,SAAA,GAAuB,CAAC;QAI9B,IAAA,CAAK,SAAA,GAAY;IACnB;IAEA,iBAA4C,EAC1C,EAAA,EACA,QAAA,EACF,EAGS;QACP,IAAA,CAAK,SAAA,CAAU,EAAE,CAAA,GAAI;IACvB;IAEQ,YAAY,EAAA,EAAwB;QAC1C,MAAM,WAAW,IAAA,CAAK,SAAA,CAAU,EAAqB,CAAA;QAErD,IAAI,YAAY,MAAM;YACpB,MAAM,IAAI,oBAAoB;gBAC5B,SAAS;gBACT,WAAW;gBACX,YAAY;gBACZ,oBAAoB,OAAO,IAAA,CAAK,IAAA,CAAK,SAAS;YAChD,CAAC;QACH;QAEA,OAAO;IACT;IAEQ,QACN,EAAA,EACA,SAAA,EACkB;QAClB,MAAM,QAAQ,GAAG,OAAA,CAAQ,IAAA,CAAK,SAAS;QAEvC,IAAI,UAAU,CAAA,GAAI;YAChB,MAAM,6JAAIG,oBAAAA,CAAiB;gBACzB,SAAS;gBACT;gBACA,SACE,CAAA,QAAA,EAAW,SAAS,CAAA,kBAAA,EAAqB,EAAE,CAAA,mCAAA,EACN,IAAA,CAAK,SAAS,CAAA,SAAA,CAAA;YACvD,CAAC;QACH;QAEA,OAAO;YAAC,GAAG,KAAA,CAAM,GAAG,KAAK;YAAG,GAAG,KAAA,CAAM,QAAQ,IAAA,CAAK,SAAA,CAAU,MAAM,CAAC;SAAA;IACrE;IAEA,cACE,EAAA,EACiB;QA1IrB,IAAAC,MAAA;QA2II,MAAM,CAAC,YAAY,OAAO,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,IAAI,eAAe;QAC9D,MAAM,QAAA,CAAQ,KAAA,CAAAA,OAAA,IAAA,CAAK,WAAA,CAAY,UAAU,CAAA,EAAE,aAAA,KAA7B,OAAA,KAAA,IAAA,GAAA,IAAA,CAAAA,MAA6C;QAE3D,IAAI,SAAS,MAAM;YACjB,MAAM,6JAAID,oBAAAA,CAAiB;gBAAE,SAAS;gBAAI,WAAW;YAAgB,CAAC;QACxE;QAEA,OAAO;IACT;IAEA,mBACE,EAAA,EAC0B;QAvJ9B,IAAAC;QAwJI,MAAM,CAAC,YAAY,OAAO,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,IAAI,oBAAoB;QACnE,MAAM,WAAW,IAAA,CAAK,WAAA,CAAY,UAAU;QAE5C,MAAM,QAAA,CAAQA,OAAA,SAAS,kBAAA,KAAT,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,UAA8B;QAE5C,IAAI,SAAS,MAAM;YACjB,MAAM,8JAAID,mBAAAA,CAAiB;gBACzB,SAAS;gBACT,WAAW;YACb,CAAC;QACH;QAEA,OAAO;IACT;IAEA,WACE,EAAA,EACc;QAzKlB,IAAAC;QA0KI,MAAM,CAAC,YAAY,OAAO,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,IAAI,YAAY;QAC3D,MAAM,WAAW,IAAA,CAAK,WAAA,CAAY,UAAU;QAE5C,MAAM,QAAA,CAAQA,OAAA,SAAS,UAAA,KAAT,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,UAAsB;QAEpC,IAAI,SAAS,MAAM;YACjB,MAAM,8JAAID,mBAAAA,CAAiB;gBAAE,SAAS;gBAAI,WAAW;YAAa,CAAC;QACrE;QAEA,OAAO;IACT;AACF;;;AEhCO,SAAS,KAAKE,KAAAA,EAAgB;IACnC,OAAOA;AACT;;;;AGnJO,IAAM,0BAA0B;AAChC,IAAM,8BAA8B;IACzC;IACA;CACF;AAiBA,IAAM,uNAAqCE,IAAAA,CACxC,MAAA,CAAO;IACN,wLAAMA,IAAAA,CAAE,MAAA,CAAO;IACf,2LAASA,IAAAA,CAAE,MAAA,CAAO;AACpB,CAAC,EACA,WAAA,CAAY;AAGR,IAAM,qMAAmBA,IAAAA,CAC7B,MAAA,CAAO;IACN,yLAAOA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,WAAA,CAAY,CAAC;AAC9C,CAAC,EACA,WAAA,CAAY;AAER,IAAM,eAAe;AAErB,IAAM,kMAAgBA,IAAAA,CAAE,MAAA,CAAO;IACpC,QAAQA,sLAAAA,CAAE,MAAA,CAAO;IACjB,0LAAQA,IAAAA,CAAE,QAAA,CAAS,gBAAgB;AACrC,CAAC;AAUD,IAAM,6MAA2BA,IAAAA,CAC9B,MAAA,CAAO;IACN,gMAAcA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,WAAA,CAAY,CAAC;IACnD,2LAASA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,WAAA,CAAY,CAAC;IAC9C,2LAASA,IAAAA,CAAE,QAAA,mLACTA,IAAAA,CACG,MAAA,CAAO;QACN,+LAAaA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,OAAA,CAAQ,CAAC;IACrC,CAAC,EACA,WAAA,CAAY;IAEjB,4LAAWA,KAAAA,CAAE,QAAA,mLACXA,IAAAA,CACG,MAAA,CAAO;QACN,6LAAWA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,OAAA,CAAQ,CAAC;QACjC,+LAAaA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,OAAA,CAAQ,CAAC;IACrC,CAAC,EACA,WAAA,CAAY;IAEjB,yLAAOA,IAAAA,CAAE,QAAA,mLACPA,IAAAA,CACG,MAAA,CAAO;QACN,+LAAaA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,OAAA,CAAQ,CAAC;IACrC,CAAC,EACA,WAAA,CAAY;AAEnB,CAAC,EACA,WAAA,CAAY;AAGR,IAAM,yBAAyB,aAAa,MAAA,CAAO;IACxD,mMAAiBA,IAAAA,CAAE,MAAA,CAAO;IAC1B,cAAc;IACd,YAAY;IACZ,gMAAcA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC;AACrC,CAAC;AASD,IAAM,wBAAwB,aAAa,MAAA,CAAO;IAChD,8LAAYA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC;AACnC,CAAC;AAED,IAAM,+LAAaA,IAAAA,CAChB,MAAA,CAAO;IACN,MAAMA,sLAAAA,CAAE,MAAA,CAAO;IACf,+LAAaA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC;IAClC,+LAAaA,IAAAA,CACV,MAAA,CAAO;QACN,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,QAAQ;QACxB,8LAAYA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,WAAA,CAAY,CAAC;IACnD,CAAC,EACA,WAAA,CAAY;AACjB,CAAC,EACA,WAAA,CAAY;AAER,IAAM,wBAAwB,sBAAsB,MAAA,CAAO;IAChE,yLAAOA,IAAAA,CAAE,KAAA,CAAM,UAAU;AAC3B,CAAC;AAGD,IAAM,sMAAoBA,IAAAA,CACvB,MAAA,CAAO;IACN,MAAMA,sLAAAA,CAAE,OAAA,CAAQ,MAAM;IACtB,wLAAMA,IAAAA,CAAE,MAAA,CAAO;AACjB,CAAC,EACA,WAAA,CAAY;AACf,IAAM,uMAAqBA,IAAAA,CACxB,MAAA,CAAO;IACN,MAAMA,sLAAAA,CAAE,OAAA,CAAQ,OAAO;IACvB,wLAAMA,IAAAA,CAAE,MAAA,CAAO,EAAE,MAAA,CAAO;IACxB,4LAAUA,IAAAA,CAAE,MAAA,CAAO;AACrB,CAAC,EACA,WAAA,CAAY;AACf,IAAM,2MAAyBA,IAAAA,CAC5B,MAAA,CAAO;IAAA;;GAAA,GAIN,uLAAKA,IAAAA,CAAE,MAAA,CAAO;IAAA;;GAAA,GAId,4LAAUA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,MAAA,CAAO,CAAC;AACjC,CAAC,EACA,WAAA,CAAY;AACf,IAAM,6BAA6B,uBAAuB,MAAA,CAAO;IAC/D,wLAAMA,IAAAA,CAAE,MAAA,CAAO;AACjB,CAAC;AACD,IAAM,6BAA6B,uBAAuB,MAAA,CAAO;IAC/D,wLAAMA,IAAAA,CAAE,MAAA,CAAO,EAAE,MAAA,CAAO;AAC1B,CAAC;AACD,IAAM,2MAAyBA,IAAAA,CAC5B,MAAA,CAAO;IACN,wLAAMA,IAAAA,CAAE,OAAA,CAAQ,UAAU;IAC1B,UAAUA,sLAAAA,CAAE,KAAA,CAAM;QAAC;QAA4B,0BAA0B;KAAC;AAC5E,CAAC,EACA,WAAA,CAAY;AAER,IAAM,uBAAuB,aAAa,MAAA,CAAO;IACtD,SAASA,sLAAAA,CAAE,KAAA,mLACTA,IAAAA,CAAE,KAAA,CAAM;QAAC;QAAmB;QAAoB,sBAAsB;KAAC;IAEzE,2LAASA,IAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ,KAAK,EAAE,QAAA,CAAS;AAC/C,CAAC,EAAE,EAAA,CACD,aAAa,MAAA,CAAO;IAClB,8LAAYA,IAAAA,CAAE,OAAA,CAAQ;AACxB,CAAC;;ADnKH,IAAM,kBAAkB;AAExB,IAAM,uBAAuBC,sLAAAA,CAC1B,MAAA,CAAO;IACN,2LAASA,IAAAA,CAAE,OAAA,CAAQ,eAAe;IAClC,sLAAIA,IAAAA,CAAE,KAAA,CAAM;QAACA,sLAAAA,CAAE,MAAA,CAAO;0LAAGA,IAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,CAAC;KAAC;AAC5C,CAAC,EACA,KAAA,CAAM,aAAa,EACnB,MAAA,CAAO;AAIV,IAAM,yMAAwBA,KAAAA,CAC3B,MAAA,CAAO;IACN,2LAASA,IAAAA,CAAE,OAAA,CAAQ,eAAe;IAClC,sLAAIA,IAAAA,CAAE,KAAA,CAAM;0LAACA,IAAAA,CAAE,MAAA,CAAO;0LAAGA,IAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,CAAC;KAAC;IAC1C,QAAQ;AACV,CAAC,EACA,MAAA,CAAO;AAIV,IAAM,uMAAqBA,IAAAA,CACxB,MAAA,CAAO;IACN,SAASA,sLAAAA,CAAE,OAAA,CAAQ,eAAe;IAClC,sLAAIA,IAAAA,CAAE,KAAA,CAAM;0LAACA,IAAAA,CAAE,MAAA,CAAO;0LAAGA,IAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,CAAC;KAAC;IAC1C,yLAAOA,IAAAA,CAAE,MAAA,CAAO;QACd,wLAAMA,IAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI;QACrB,SAASA,sLAAAA,CAAE,MAAA,CAAO;QAClB,wLAAMA,IAAAA,CAAE,QAAA,mLAASA,IAAAA,CAAE,OAAA,CAAQ,CAAC;IAC9B,CAAC;AACH,CAAC,EACA,MAAA,CAAO;AAIV,IAAM,6MAA4BA,KAAAA,CAC/B,MAAA,CAAO;IACN,2LAASA,IAAAA,CAAE,OAAA,CAAQ,eAAe;AACpC,CAAC,EACA,KAAA,kLACCA,KAAAA,CAAE,MAAA,CAAO;IACP,0LAAQA,IAAAA,CAAE,MAAA,CAAO;IACjB,0LAAQA,IAAAA,CAAE,QAAA,CAAS,gBAAgB;AACrC,CAAC,GAEF,MAAA,CAAO;AAIH,IAAM,yMAAuBA,IAAAA,CAAE,KAAA,CAAM;IAC1C;IACA;IACA;IACA;CACD;;ADrDM,IAAM,kBAAN,MAA8C;IAcnD,YAAY,EACV,GAAA,EACA,OAAA,EACF,CAGG;QAhBH,IAAA,CAAQ,SAAA,GAAY;QAiBlB,IAAA,CAAK,GAAA,GAAM,IAAI,IAAI,GAAG;QACtB,IAAA,CAAK,OAAA,GAAU;IACjB;IAEA,MAAM,QAAuB;QAC3B,OAAO,IAAI,QAAc,CAAC,SAAS,WAAW;YAC5C,IAAI,IAAA,CAAK,SAAA,EAAW;gBAClB,OAAO,QAAQ;YACjB;YAEA,IAAA,CAAK,eAAA,GAAkB,IAAI,gBAAgB;YAE3C,MAAM,sBAAsB,YAAY;gBAtC9C,IAAAC,MAAA,IAAA;gBAuCQ,IAAI;oBACF,MAAM,UAAU,IAAI,QAAQ,IAAA,CAAK,OAAO;oBACxC,QAAQ,GAAA,CAAI,UAAU,mBAAmB;oBACzC,MAAM,WAAW,MAAM,MAAM,IAAA,CAAK,GAAA,CAAI,IAAA,EAAM;wBAC1C;wBACA,QAAA,CAAQA,OAAA,IAAA,CAAK,eAAA,KAAL,OAAA,KAAA,IAAAA,KAAsB,MAAA;oBAChC,CAAC;oBAED,IAAI,CAAC,SAAS,EAAA,IAAM,CAAC,SAAS,IAAA,EAAM;wBAClC,MAAM,QAAQ,IAAI,eAAe;4BAC/B,SAAS,CAAA,yBAAA,EAA4B,SAAS,MAAM,CAAA,CAAA,EAAI,SAAS,UAAU,EAAA;wBAC7E,CAAC;wBACD,CAAA,KAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA,EAAe;wBACf,OAAO,OAAO,KAAK;oBACrB;oBAEA,MAAM,SAAS,SAAS,IAAA,CACrB,WAAA,CAAY,IAAI,kBAAkB,CAAC,EACnC,WAAA,KAAY,mNAAA,CAA8B,CAAC;oBAE9C,MAAM,SAAS,OAAO,SAAA,CAAU;oBAEhC,MAAM,gBAAgB,YAAY;wBA7D5C,IAAAA,MAAAC,KAAAC;wBA8DY,IAAI;4BACF,MAAO,KAAM;gCACX,MAAM,EAAE,IAAA,EAAM,KAAA,CAAM,CAAA,GAAI,MAAM,OAAO,IAAA,CAAK;gCAE1C,IAAI,MAAM;oCACR,IAAI,IAAA,CAAK,SAAA,EAAW;wCAClB,IAAA,CAAK,SAAA,GAAY;wCACjB,MAAM,IAAI,eAAe;4CACvB,SACE;wCACJ,CAAC;oCACH;oCACA;gCACF;gCAEA,MAAM,EAAE,KAAA,EAAO,IAAA,CAAK,CAAA,GAAI;gCAExB,IAAI,UAAU,YAAY;oCACxB,IAAA,CAAK,QAAA,GAAW,IAAI,IAAI,MAAM,IAAA,CAAK,GAAG;oCAEtC,IAAI,IAAA,CAAK,QAAA,CAAS,MAAA,KAAW,IAAA,CAAK,GAAA,CAAI,MAAA,EAAQ;wCAC5C,MAAM,IAAI,eAAe;4CACvB,SAAS,CAAA,2EAAA,EAA8E,IAAA,CAAK,QAAA,CAAS,MAAM,EAAA;wCAC7G,CAAC;oCACH;oCAEA,IAAA,CAAK,SAAA,GAAY;oCACjB,QAAQ;gCACV,OAAA,IAAW,UAAU,WAAW;oCAC9B,IAAI;wCACF,MAAM,UAAU,qBAAqB,KAAA,CACnC,KAAK,KAAA,CAAM,IAAI;wCAEjB,CAAAF,OAAA,IAAA,CAAK,SAAA,KAAL,OAAA,KAAA,IAAAA,KAAA,IAAA,CAAA,IAAA,EAAiB;oCACnB,EAAA,OAAS,OAAO;wCACd,MAAM,IAAI,IAAI,eAAe;4CAC3B,SACE;4CACF,OAAO;wCACT,CAAC;wCACD,CAAAC,MAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAAA,IAAA,IAAA,CAAA,IAAA,EAAe;oCAEjB;gCACF;4BACF;wBACF,EAAA,OAAS,OAAO;4BACd,IAAI,iBAAiB,SAAS,MAAM,IAAA,KAAS,cAAc;gCACzD;4BACF;4BAEA,CAAAC,MAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAAA,IAAA,IAAA,CAAA,IAAA,EAAe;4BACf,OAAO,KAAK;wBACd;oBACF;oBAEA,IAAA,CAAK,aAAA,GAAgB;wBACnB,OAAO,IAAM,OAAO,MAAA,CAAO;oBAC7B;oBAEA,cAAc;gBAChB,EAAA,OAAS,OAAO;oBACd,IAAI,iBAAiB,SAAS,MAAM,IAAA,KAAS,cAAc;wBACzD;oBACF;oBAEA,CAAA,KAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA,EAAe;oBACf,OAAO,KAAK;gBACd;YACF;YAEA,oBAAoB;QACtB,CAAC;IACH;IAEA,MAAM,QAAuB;QAxI/B,IAAAF,MAAA,IAAA;QAyII,IAAA,CAAK,SAAA,GAAY;QACjB,CAAAA,OAAA,IAAA,CAAK,aAAA,KAAL,OAAA,KAAA,IAAAA,KAAoB,KAAA;QACpB,CAAA,KAAA,IAAA,CAAK,eAAA,KAAL,OAAA,KAAA,IAAA,GAAsB,KAAA;QACtB,CAAA,KAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA;IACF;IAEA,MAAM,KAAK,OAAA,EAAwC;QA/IrD,IAAAA,MAAA,IAAA;QAgJI,IAAI,CAAC,IAAA,CAAK,QAAA,IAAY,CAAC,IAAA,CAAK,SAAA,EAAW;YACrC,MAAM,IAAI,eAAe;gBACvB,SAAS;YACX,CAAC;QACH;QAEA,IAAI;YACF,MAAM,UAAU,IAAI,QAAQ,IAAA,CAAK,OAAO;YACxC,QAAQ,GAAA,CAAI,gBAAgB,kBAAkB;YAC9C,MAAM,OAAO;gBACX,QAAQ;gBACR;gBACA,MAAM,KAAK,SAAA,CAAU,OAAO;gBAC5B,QAAA,CAAQA,OAAA,IAAA,CAAK,eAAA,KAAL,OAAA,KAAA,IAAAA,KAAsB,MAAA;YAChC;YAEA,MAAM,WAAW,MAAM,MAAM,IAAA,CAAK,QAAA,EAAU,IAAI;YAEhD,IAAI,CAAC,SAAS,EAAA,EAAI;gBAChB,MAAMG,QAAO,MAAM,SAAS,IAAA,CAAK,EAAE,KAAA,CAAM,IAAM,IAAI;gBACnD,MAAM,QAAQ,IAAI,eAAe;oBAC/B,SAAS,CAAA,mDAAA,EAAsD,SAAS,MAAM,CAAA,GAAA,EAAMA,KAAI,EAAA;gBAC1F,CAAC;gBACD,CAAA,KAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA,EAAe;gBACf;YACF;QACF,EAAA,OAAS,OAAO;YACd,CAAA,KAAA,IAAA,CAAK,OAAA,KAAL,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAA,EAAe;YACf;QACF;IACF;AACF;;AGxHO,SAAS,mBAAmB,MAAA,EAA0C;IAC3E,IAAI,OAAO,IAAA,KAAS,OAAO;QACzB,MAAM,IAAI,eAAe;YACvB,SACE;QACJ,CAAC;IACH;IAEA,OAAO,IAAI,gBAAgB,MAAM;AACnC;AAEO,SAAS,qBACd,SAAA,EAC2B;IAC3B,OACE,WAAW,aACX,OAAO,UAAU,KAAA,KAAU,cAC3B,UAAU,aACV,OAAO,UAAU,IAAA,KAAS,cAC1B,WAAW,aACX,OAAO,UAAU,KAAA,KAAU;AAE/B;;AL1CA,IAAM,iBAAiB;AAWvB,eAAsB,gBACpB,MAAA,EACoB;IACpB,MAAM,SAAS,IAAI,UAAU,MAAM;IACnC,MAAM,OAAO,IAAA,CAAK;IAClB,OAAO;AACT;AAmBA,IAAM,YAAN,MAAgB;IAYd,YAAY,EACV,WAAW,eAAA,EACX,MAAAC,SAAO,mBAAA,EACP,eAAA,EACF,CAAoB;QAZpB,IAAA,CAAQ,gBAAA,GAAmB;QAC3B,IAAA,CAAQ,gBAAA,GAGJ,aAAA,GAAA,IAAI,IAAI;QACZ,IAAA,CAAQ,kBAAA,GAAyC,CAAC;QAClD,IAAA,CAAQ,QAAA,GAAW;QAOjB,IAAA,CAAK,eAAA,GAAkB;QAEvB,IAAI,qBAAqB,eAAe,GAAG;YACzC,IAAA,CAAK,SAAA,GAAY;QACnB,OAAO;YACL,IAAA,CAAK,SAAA,GAAY,mBAAmB,eAAe;QACrD;QAEA,IAAA,CAAK,SAAA,CAAU,OAAA,GAAU,IAAM,IAAA,CAAK,OAAA,CAAQ;QAC5C,IAAA,CAAK,SAAA,CAAU,OAAA,GAAU,CAAC,QAAiB,IAAA,CAAK,OAAA,CAAQ,KAAK;QAC7D,IAAA,CAAK,SAAA,CAAU,SAAA,GAAY,CAAA,YAAW;YACpC,IAAI,YAAY,SAAS;gBAIvB,IAAA,CAAK,OAAA,CACH,IAAI,eAAe;oBACjB,SAAS;gBACX,CAAC;gBAEH;YACF;YAEA,IAAA,CAAK,UAAA,CAAW,OAAO;QACzB;QAEA,IAAA,CAAK,UAAA,GAAa;YAChB,MAAAA;YACA,SAAS;QACX;IACF;IAEA,MAAM,OAAsB;QAC1B,IAAI;YACF,MAAM,IAAA,CAAK,SAAA,CAAU,KAAA,CAAM;YAC3B,IAAA,CAAK,QAAA,GAAW;YAEhB,MAAM,SAAS,MAAM,IAAA,CAAK,OAAA,CAAQ;gBAChC,SAAS;oBACP,QAAQ;oBACR,QAAQ;wBACN,iBAAiB;wBACjB,cAAc,CAAC;wBACf,YAAY,IAAA,CAAK,UAAA;oBACnB;gBACF;gBACA,cAAc;YAChB,CAAC;YAED,IAAI,WAAW,KAAA,GAAW;gBACxB,MAAM,IAAI,eAAe;oBACvB,SAAS;gBACX,CAAC;YACH;YAEA,IAAI,CAAC,4BAA4B,QAAA,CAAS,OAAO,eAAe,GAAG;gBACjE,MAAM,IAAI,eAAe;oBACvB,SAAS,CAAA,4CAAA,EAA+C,OAAO,eAAe,EAAA;gBAChF,CAAC;YACH;YAEA,IAAA,CAAK,kBAAA,GAAqB,OAAO,YAAA;YAGjC,MAAM,IAAA,CAAK,YAAA,CAAa;gBACtB,QAAQ;YACV,CAAC;YAED,OAAO,IAAA;QACT,EAAA,OAAS,OAAO;YACd,MAAM,IAAA,CAAK,KAAA,CAAM;YACjB,MAAM;QACR;IACF;IAEA,MAAM,QAAuB;QAnK/B,IAAAC;QAoKI,IAAI,IAAA,CAAK,QAAA,EAAU;QACnB,MAAA,CAAA,CAAMA,OAAA,IAAA,CAAK,SAAA,KAAL,OAAA,KAAA,IAAAA,KAAgB,KAAA,EAAA;QACtB,IAAA,CAAK,OAAA,CAAQ;IACf;IAEQ,iBAAiB,MAAA,EAAsB;QAC7C,OAAQ,QAAQ;YACd,KAAK;gBACH;YACF,KAAK;YACL,KAAK;gBACH,IAAI,CAAC,IAAA,CAAK,kBAAA,CAAmB,KAAA,EAAO;oBAClC,MAAM,IAAI,eAAe;wBACvB,SAAS,CAAA,6BAAA,CAAA;oBACX,CAAC;gBACH;gBACA;YACF;gBACE,MAAM,IAAI,eAAe;oBACvB,SAAS,CAAA,oBAAA,EAAuB,MAAM,EAAA;gBACxC,CAAC;QACL;IACF;IAEA,MAAc,QAAmC,EAC/C,OAAA,EACA,YAAA,EACA,OAAA,EACF,EAIwB;QACtB,OAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;YACtC,IAAI,IAAA,CAAK,QAAA,EAAU;gBACjB,OAAO,OACL,IAAI,eAAe;oBACjB,SAAS;gBACX,CAAC;YAEL;YAEA,IAAA,CAAK,gBAAA,CAAiB,QAAQ,MAAM;YAEpC,MAAM,SAAS,WAAA,OAAA,KAAA,IAAA,QAAS,MAAA;YACxB,UAAA,OAAA,KAAA,IAAA,OAAQ,cAAA;YAER,MAAM,YAAY,IAAA,CAAK,gBAAA;YACvB,MAAM,iBAAiC;gBACrC,GAAG,OAAA;gBACH,SAAS;gBACT,IAAI;YACN;YAEA,MAAM,UAAU,MAAM;gBACpB,IAAA,CAAK,gBAAA,CAAiB,MAAA,CAAO,SAAS;YACxC;YAEA,IAAA,CAAK,gBAAA,CAAiB,GAAA,CAAI,WAAW,CAAA,aAAY;gBAC/C,IAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,OAAA,EAAS;oBACnB,OAAO,OACL,IAAI,eAAe;wBACjB,SAAS;wBACT,OAAO,OAAO,MAAA;oBAChB,CAAC;gBAEL;gBAEA,IAAI,oBAAoB,OAAO;oBAC7B,OAAO,OAAO,QAAQ;gBACxB;gBAEA,IAAI;oBACF,MAAM,SAAS,aAAa,KAAA,CAAM,SAAS,MAAM;oBACjD,QAAQ,MAAM;gBAChB,EAAA,OAAS,OAAO;oBACd,MAAM,aAAa,IAAI,eAAe;wBACpC,SAAS;wBACT,OAAO;oBACT,CAAC;oBACD,OAAO,UAAU;gBACnB;YACF,CAAC;YAED,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,cAAc,EAAE,KAAA,CAAM,CAAA,UAAS;gBACjD,QAAQ;gBACR,OAAO,KAAK;YACd,CAAC;QACH,CAAC;IACH;IAEA,MAAc,UAAU,EACtB,MAAA,EACA,OAAA,EACF,GAGI,CAAC,CAAA,EAA6B;QAChC,IAAI;YACF,OAAO,IAAA,CAAK,OAAA,CAAQ;gBAClB,SAAS;oBAAE,QAAQ;oBAAc;gBAAO;gBACxC,cAAc;gBACd;YACF,CAAC;QACH,EAAA,OAAS,OAAO;YACd,MAAM;QACR;IACF;IAEA,MAAc,SAAS,EACrB,MAAAD,MAAAA,EACA,IAAA,EACA,OAAA,EACF,EAI4B;QAC1B,IAAI;YACF,OAAO,IAAA,CAAK,OAAA,CAAQ;gBAClB,SAAS;oBAAE,QAAQ;oBAAc,QAAQ;wBAAE,MAAAA;wBAAM,WAAW;oBAAK;gBAAE;gBACnE,cAAc;gBACd,SAAS;oBACP,QAAQ,WAAA,OAAA,KAAA,IAAA,QAAS,WAAA;gBACnB;YACF,CAAC;QACH,EAAA,OAAS,OAAO;YACd,MAAM;QACR;IACF;IAEA,MAAc,aAAa,YAAA,EAA2C;QACpE,MAAM,sBAA2C;YAC/C,GAAG,YAAA;YACH,SAAS;QACX;QACA,MAAM,IAAA,CAAK,SAAA,CAAU,IAAA,CAAK,mBAAmB;IAC/C;IAAA;;;GAAA,GAMA,MAAM,MAAsD,EAC1D,UAAU,WAAA,EACZ,GAEI,CAAC,CAAA,EAAsC;QAvT7C,IAAAC;QAwTI,MAAM,QAA8B,CAAC;QAErC,IAAI;YACF,MAAM,kBAAkB,MAAM,IAAA,CAAK,SAAA,CAAU;YAE7C,KAAA,MAAW,EAAE,MAAAD,MAAAA,EAAM,WAAA,EAAa,WAAA,CAAY,CAAA,IAAK,gBAAgB,KAAA,CAAO;gBACtE,IAAI,YAAY,eAAe,CAAA,CAAEA,UAAQ,OAAA,GAAU;oBACjD;gBACF;gBAEA,MAAM,aACJ,YAAY,qMACR,aAAA,EAAW;oBACT,GAAG,WAAA;oBACH,YAAA,CAAYC,OAAA,YAAY,UAAA,KAAZ,OAAAA,OAA0B,CAAC;oBACvC,sBAAsB;gBACxB,CAAgB,IAChB,OAAA,CAAQD,MAAI,CAAA,CAAE,UAAA;gBAEpB,MAAM,OAAO,IAAA;gBACb,MAAM,kBAAkB,KAAK;oBAC3B;oBACA;oBACA,SAAS,OACP,MACA,YAC4B;wBAlVxC,IAAAC;wBAmVY,CAAAA,OAAA,WAAA,OAAA,KAAA,IAAA,QAAS,WAAA,KAAT,OAAA,KAAA,IAAAA,KAAsB,cAAA;wBAEtB,OAAO,KAAK,QAAA,CAAS;4BACnB,MAAAD;4BACA;4BACA;wBACF,CAAC;oBACH;gBACF,CAAC;gBAED,KAAA,CAAMA,MAAI,CAAA,GAAI;YAChB;YAEA,OAAO;QACT,EAAA,OAAS,OAAO;YACd,MAAM;QACR;IACF;IAEQ,UAAgB;QACtB,IAAI,IAAA,CAAK,QAAA,EAAU;QAEnB,IAAA,CAAK,QAAA,GAAW;QAChB,MAAM,QAAQ,IAAI,eAAe;YAC/B,SAAS;QACX,CAAC;QAED,KAAA,MAAW,WAAW,IAAA,CAAK,gBAAA,CAAiB,MAAA,CAAO,EAAG;YACpD,QAAQ,KAAK;QACf;QAEA,IAAA,CAAK,gBAAA,CAAiB,KAAA,CAAM;IAC9B;IAEQ,QAAQ,KAAA,EAAsB;QACpC,IAAI,IAAA,CAAK,eAAA,EAAiB;YACxB,IAAA,CAAK,eAAA,CAAgB,KAAK;QAC5B;IACF;IAEQ,WAAW,QAAA,EAAgD;QACjE,MAAM,YAAY,OAAO,SAAS,EAAE;QACpC,MAAM,UAAU,IAAA,CAAK,gBAAA,CAAiB,GAAA,CAAI,SAAS;QAEnD,IAAI,YAAY,KAAA,GAAW;YACzB,MAAM,IAAI,eAAe;gBACvB,SAAS,CAAA,+DAAA,EAAkE,KAAK,SAAA,CAC9E,WACD;YACH,CAAC;QACH;QAEA,IAAA,CAAK,gBAAA,CAAiB,MAAA,CAAO,SAAS;QAEtC,QACE,YAAY,WACR,WACA,IAAI,eAAe;YACjB,SAAS,SAAS,KAAA,CAAM,OAAA;YACxB,OAAO,SAAS,KAAA;QAClB,CAAC;IAET;AACF;;AM5YO,IAAM,6BAAN,wKAAyCE,aAAAA,CAAW;IAGzD,YAAY,OAAA,CAET;QACD,KAAA,CAAM;YACJ,MAAM;YACN,SAAS;QACX,CAAC;QAED,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;IAC3B;AACF;;ACSA,eAAsB,WAAW,EAC/B,KAAA,EACA,KAAA,EACA,kBAAkB,CAAC,CAAA,EACnB,YAAY,aAAA,EACZ,WAAA,EACA,OAAA,EACF,EA4CiC;IAC/B,MAAM,EAAE,KAAA,CAAM,CAAA,GAAI,eAAe;QAAE,YAAY;IAAc,CAAC;IAC9D,MAAM,YACJ,iBAAiB,MAAA,CACZ,MAAM,SAAS;QAAE,KAAK;IAAM,CAAC,CAAA,EAAG,IAAA,GACjC,+BAA+B,KAAK;IAE1C,MAAM,SAAS,MAAM,MAAM,MAAG;QAtFhC,IAAAC;QAuFI,OAAA,MAAM,UAAA,CAAW;YACf,OAAO;YACP;YACA;YACA;YACA,WAAA,CACEA,OAAA,gBAAgB;gBACd,MAAM;gBACN,YAAY;YACd,CAAC,CAAA,KAHD,OAAAA,OAGM;QACV,CAAC;IAAA;IAGH,IAAI,CAAC,OAAO,IAAA,EAAM;QAChB,MAAM,IAAI,2BAA2B;YAAE,WAAW;gBAAC,OAAO,QAAQ;aAAA;QAAE,CAAC;IACvE;IAEA,OAAO,IAAI,2BAA2B;QACpC,MAAM,OAAO,IAAA;QACb,UAAU,OAAO,QAAA;QACjB,UAAU,OAAO,QAAA;QACjB,mBAAmB,OAAO,iBAAA;QAC1B,UAAU,OAAO,QAAA;QACjB,WAAW;YAAC,OAAO,QAAQ;SAAA;QAC3B,kBAAkB,OAAO,gBAAA;IAC3B,CAAC;AACH;AAEA,IAAM,6BAAN,MAAgE;IAa9D,YAAY,OAAA,CAYT;QA5IL,IAAAA;QA6II,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;QACpB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,iBAAA,GAAoB,QAAQ,iBAAA;QACjC,IAAA,CAAK,QAAA,GAAW,QAAQ,QAAA;QACxB,IAAA,CAAK,SAAA,GAAY,QAAQ,SAAA;QACzB,IAAA,CAAK,gBAAA,GAAA,CAAmBA,OAAA,QAAQ,gBAAA,KAAR,OAAAA,OAA4B,CAAC;IACvD;AACF","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118],"debugId":null}}]
}